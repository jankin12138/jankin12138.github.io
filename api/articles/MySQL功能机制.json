{"title":"MySQL功能机制","uid":"dd59c704134a0428540392e3edcac680","slug":"MySQL功能机制","date":"2022-09-22T15:12:15.000Z","updated":"2022-10-05T18:01:22.714Z","comments":true,"path":"api/articles/MySQL功能机制.json","keywords":null,"cover":"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20220922231559.6if2jqtrik80.webp","content":"<h1 id=\"数据库表的空间回收机制\"><a href=\"#数据库表的空间回收机制\" class=\"headerlink\" title=\"数据库表的空间回收机制\"></a>数据库表的空间回收机制</h1><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>一个 InnoDB 表包含两部分，即：表结构定义和数据。因为表结构定义占用的空间很小，所以我们今天主要讨论的是表数据。</p></blockquote>\n<h2 id=\"参数-innodb-file-per-table\"><a href=\"#参数-innodb-file-per-table\" class=\"headerlink\" title=\"参数 innodb_file_per_table\"></a>参数 innodb_file_per_table</h2><p>表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的：</p>\n<ol>\n<li>这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；</li>\n<li>这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。</li>\n</ol>\n<div class=\"custom-quote tip\">\n<span class=\"custom-quote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M20.86 14.13C20 14.7 19.56 15.74 19.77 16.76C20.13 18.55 18.55 20.13 16.76 19.77C15.74 19.57 14.7 20 14.13 20.86C13.12 22.38 10.89 22.38 9.88 20.86C9.3 20 8.26 19.56 7.24 19.77C5.45 20.13 3.87 18.55 4.23 16.76C4.43 15.74 4 14.7 3.14 14.13C1.62 13.12 1.62 10.89 3.14 9.88C4 9.3 4.44 8.26 4.23 7.24C3.87 5.45 5.45 3.87 7.24 4.23C8.26 4.44 9.3 4 9.87 3.14C10.88 1.62 13.11 1.62 14.12 3.14C14.7 4 15.74 4.44 16.76 4.23C18.55 3.87 20.13 5.45 19.77 7.24C19.56 8.26 20 9.3 20.86 9.87C22.38 10.88 22.38 13.12 20.86 14.13Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M12.01 15C12.01 14.5 12.01 14.5 12.01 14.5C12.04 13.75 13 13.46 14.04 12.2C14.41 11.74 14.69 11.41 14.86 10.85C15.15 9.95 14.92 9.18 14.86 9.02C14.8 8.79 14.52 8 13.72 7.46C13.06 7.02 12.42 7 12.14 7C11.9 7 11.36 7 10.78 7.3C10.28 7.56 9.98 7.9 9.83 8.1C9.24 8.82 9.06 9.63 9 10.06\"></path>\n<path stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M11.99 18H12.01\"></path>\n</svg></span>\n<p class=\"custom-quote-title\">提示</p>\n<p><strong>将 innodb_file_per_table 设置为 ON，是推荐做法</strong></p>\n\n</div>\n<h2 id=\"数据删除流程\"><a href=\"#数据删除流程\" class=\"headerlink\" title=\"数据删除流程\"></a>数据删除流程</h2><div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20220922232737.2peildupn020.webp\"/>\n</div>\n\n<p>假设，我们要删掉 R4 这个记录，InnoDB 引擎只会把 R4 这个记录标记为删除。如果之后要再插入一个 ID 在 300 和 600 之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。</p>\n<p>InnoDB 的数据是按页存储的,所以当删除整个页的时候，整个数据也都可以被复用，但是，<strong>数据页的复用跟记录的复用是不同的。</strong></p>\n<ul>\n<li>记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了。</li>\n<li>而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。</li>\n</ul>\n<p>delete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。</p>\n<p><strong>不止是删除数据会造成空洞，插入数据也会。</strong></p>\n<p>如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。</p>\n<p>也就是说，经过<strong>大量增删改</strong>的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。</p>\n<p>因此我们就需要了解<strong>重建表</strong>。</p>\n<h2 id=\"重建表\"><a href=\"#重建表\" class=\"headerlink\" title=\"重建表\"></a>重建表</h2><details class=\"custom-details\">\n<summary>表 A需要怎么做空间收缩</summary>\n<p><p>你可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。</p>\n<p>由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。显然地，表 B 的主键索引更紧凑，数据页的利用率也更高。如果我们把表 B 作为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。</p>\n</p>\n</details>\n<div class=\"custom-quote warning\">\n<span class=\"custom-quote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M20.86 14.13C20 14.7 19.56 15.74 19.77 16.76C20.13 18.55 18.55 20.13 16.76 19.77C15.74 19.57 14.7 20 14.13 20.86C13.12 22.38 10.89 22.38 9.88 20.86C9.3 20 8.26 19.56 7.24 19.77C5.45 20.13 3.87 18.55 4.23 16.76C4.43 15.74 4 14.7 3.14 14.13C1.62 13.12 1.62 10.89 3.14 9.88C4 9.3 4.44 8.26 4.23 7.24C3.87 5.45 5.45 3.87 7.24 4.23C8.26 4.44 9.3 4 9.87 3.14C10.88 1.62 13.11 1.62 14.12 3.14C14.7 4 15.74 4.44 16.76 4.23C18.55 3.87 20.13 5.45 19.77 7.24C19.56 8.26 20 9.3 20.86 9.87C22.38 10.88 22.38 13.12 20.86 14.13Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M12 8V13\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M12 15.99V16.01\"></path>\n</svg>\n</span>\n<p class=\"custom-quote-title\">注意</p>\n<p>在 MySQL 5.5 版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表 B 不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。</p>\n\n</div>\n<p>而在<strong>MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。</strong></p>\n<ol>\n<li>建立一个临时文件，扫描表 A 主键的所有数据页；</li>\n<li>用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；</li>\n<li>生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；</li>\n<li>临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；</li>\n<li>用临时文件替换表 A 的数据文件。</li>\n</ol>\n<p>由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。</p>\n<h2 id=\"Online-和-inplace\"><a href=\"#Online-和-inplace\" class=\"headerlink\" title=\"Online 和 inplace\"></a>Online 和 inplace</h2><p>说到 Online，我还要再和你澄清一下它和另一个跟 DDL 有关的、容易混淆的概念 inplace 的区别。</p>\n<p>你可能注意到了，在 MySQL 5.5 版本之前中，我们把表 A 中的数据导出来的存放位置叫作 tmp_table。这是一个临时表，是在 server 层创建的。</p>\n<p>在MySQL 5.6 版本开始，根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。</p>\n<p>所以，我现在问你，如果你有一个 1TB 的表，现在磁盘间是 1.2TB，能不能做一个 inplace 的 DDL 呢？</p>\n<p>答案是不能。因为，tmp_file 也是要占用临时空间的。</p>\n<p>如果说这两个逻辑之间的关系是什么的话，可以概括为：</p>\n<ol>\n<li>DDL 过程如果是 Online 的，就一定是 inplace 的；</li>\n<li>反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。</li>\n</ol>\n<div class=\"custom-quote tip\">\n<span class=\"custom-quote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M20.86 14.13C20 14.7 19.56 15.74 19.77 16.76C20.13 18.55 18.55 20.13 16.76 19.77C15.74 19.57 14.7 20 14.13 20.86C13.12 22.38 10.89 22.38 9.88 20.86C9.3 20 8.26 19.56 7.24 19.77C5.45 20.13 3.87 18.55 4.23 16.76C4.43 15.74 4 14.7 3.14 14.13C1.62 13.12 1.62 10.89 3.14 9.88C4 9.3 4.44 8.26 4.23 7.24C3.87 5.45 5.45 3.87 7.24 4.23C8.26 4.44 9.3 4 9.87 3.14C10.88 1.62 13.11 1.62 14.12 3.14C14.7 4 15.74 4.44 16.76 4.23C18.55 3.87 20.13 5.45 19.77 7.24C19.56 8.26 20 9.3 20.86 9.87C22.38 10.88 22.38 13.12 20.86 14.13Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M12.01 15C12.01 14.5 12.01 14.5 12.01 14.5C12.04 13.75 13 13.46 14.04 12.2C14.41 11.74 14.69 11.41 14.86 10.85C15.15 9.95 14.92 9.18 14.86 9.02C14.8 8.79 14.52 8 13.72 7.46C13.06 7.02 12.42 7 12.14 7C11.9 7 11.36 7 10.78 7.3C10.28 7.56 9.98 7.9 9.83 8.1C9.24 8.82 9.06 9.63 9 10.06\"></path>\n<path stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M11.99 18H12.01\"></path>\n</svg></span>\n<p class=\"custom-quote-title\">提示</p>\n<p><p>optimize table、analyze table 和 alter table 这三种方式重建表的区别。</p>\n<ul>\n<li>从 MySQL 5.6 版本开始，alter table t engine &#x3D; InnoDB（也就是 recreate）默认的就是上面 Online DDL的流程了；</li>\n<li>analyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；</li>\n<li>optimize table t 等于 recreate+analyze。</li>\n</ul>\n</p>\n</div>\n<h1 id=\"count-的实现方式\"><a href=\"#count-的实现方式\" class=\"headerlink\" title=\"count(*) 的实现方式\"></a>count(*) 的实现方式</h1><p>在不同的 MySQL 引擎中，count(*) 有不同的实现方式。</p>\n<ul>\n<li>MyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；</li>\n<li>而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。</li>\n</ul>\n<div class=\"custom-quote tip\">\n<span class=\"custom-quote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M20.86 14.13C20 14.7 19.56 15.74 19.77 16.76C20.13 18.55 18.55 20.13 16.76 19.77C15.74 19.57 14.7 20 14.13 20.86C13.12 22.38 10.89 22.38 9.88 20.86C9.3 20 8.26 19.56 7.24 19.77C5.45 20.13 3.87 18.55 4.23 16.76C4.43 15.74 4 14.7 3.14 14.13C1.62 13.12 1.62 10.89 3.14 9.88C4 9.3 4.44 8.26 4.23 7.24C3.87 5.45 5.45 3.87 7.24 4.23C8.26 4.44 9.3 4 9.87 3.14C10.88 1.62 13.11 1.62 14.12 3.14C14.7 4 15.74 4.44 16.76 4.23C18.55 3.87 20.13 5.45 19.77 7.24C19.56 8.26 20 9.3 20.86 9.87C22.38 10.88 22.38 13.12 20.86 14.13Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M12.01 15C12.01 14.5 12.01 14.5 12.01 14.5C12.04 13.75 13 13.46 14.04 12.2C14.41 11.74 14.69 11.41 14.86 10.85C15.15 9.95 14.92 9.18 14.86 9.02C14.8 8.79 14.52 8 13.72 7.46C13.06 7.02 12.42 7 12.14 7C11.9 7 11.36 7 10.78 7.3C10.28 7.56 9.98 7.9 9.83 8.1C9.24 8.82 9.06 9.63 9 10.06\"></path>\n<path stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M11.99 18H12.01\"></path>\n</svg></span>\n<p class=\"custom-quote-title\">提示</p>\n<p>在这篇文章里讨论的是没有过滤条件的 count(*)，如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的。</p>\n\n</div>\n<p><strong>为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？</strong></p>\n<p>这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。这里，我用一个算 count(*) 的例子来为你解释一下。</p>\n<p>假设表 t 中现在有 10000 条记录，我们设计了三个用户并行的会话。</p>\n<ul>\n<li>会话 A 先启动事务并查询一次表的总行数；</li>\n<li>会话 B 启动事务，插入一行后记录后，查询表的总行数；</li>\n<li>会话 C 先启动一个单独的语句，插入一行记录后，查询表的总行数。</li>\n</ul>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20220923002543.2zj1372nn080.webp\"/>\n</div>\n\n<p>三个会话 A、B、C 会同时查询表 t 的总行数，但拿到的结果却不同。</p>\n<div class=\"custom-quote tip\">\n<span class=\"custom-quote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M20.86 14.13C20 14.7 19.56 15.74 19.77 16.76C20.13 18.55 18.55 20.13 16.76 19.77C15.74 19.57 14.7 20 14.13 20.86C13.12 22.38 10.89 22.38 9.88 20.86C9.3 20 8.26 19.56 7.24 19.77C5.45 20.13 3.87 18.55 4.23 16.76C4.43 15.74 4 14.7 3.14 14.13C1.62 13.12 1.62 10.89 3.14 9.88C4 9.3 4.44 8.26 4.23 7.24C3.87 5.45 5.45 3.87 7.24 4.23C8.26 4.44 9.3 4 9.87 3.14C10.88 1.62 13.11 1.62 14.12 3.14C14.7 4 15.74 4.44 16.76 4.23C18.55 3.87 20.13 5.45 19.77 7.24C19.56 8.26 20 9.3 20.86 9.87C22.38 10.88 22.38 13.12 20.86 14.13Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M12.01 15C12.01 14.5 12.01 14.5 12.01 14.5C12.04 13.75 13 13.46 14.04 12.2C14.41 11.74 14.69 11.41 14.86 10.85C15.15 9.95 14.92 9.18 14.86 9.02C14.8 8.79 14.52 8 13.72 7.46C13.06 7.02 12.42 7 12.14 7C11.9 7 11.36 7 10.78 7.3C10.28 7.56 9.98 7.9 9.83 8.1C9.24 8.82 9.06 9.63 9 10.06\"></path>\n<path stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M11.99 18H12.01\"></path>\n</svg></span>\n<p class=\"custom-quote-title\">count(*) 优化</p>\n<p><p>InnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。 <strong>在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。</strong></p>\n</p>\n</div>\n<p>如果你用过 show table status 命令的话，就会发现这个命令的输出结果里面也有一个 TABLE_ROWS 用于显示这个表当前有多少行，这个命令执行挺快的，那这个 TABLE_ROWS 能代替 count(*) 吗？</p>\n<div class=\"custom-quote danger\">\n<span class=\"custom-quote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M19.76 5.23C15.84 5.23 12 2 12 2C12 2 8.15996 5.23 4.23996 5.23C4.23996 5.23 1.86996 16.99 12 22C22.13 16.99 19.76 5.23 19.76 5.23Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M12 8V13\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M11.99 16H12\"></path>\n</svg>\n</span>\n<p class=\"custom-quote-title\">特别注意</p>\n<p>实际上，TABLE_ROWS 就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到 40% 到 50%。<strong>所以，show table status 命令显示的行数也不能直接使用。</strong></p>\n\n</div>\n<p>总的来说就是:</p>\n<ul>\n<li>MyISAM 表虽然 count(*) 很快，但是不支持事务；</li>\n<li>show table status 命令虽然返回很快，但是不准确；</li>\n<li>InnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。</li>\n</ul>\n<h2 id=\"数据行数的存储方式\"><a href=\"#数据行数的存储方式\" class=\"headerlink\" title=\"数据行数的存储方式\"></a>数据行数的存储方式</h2><p>因此如果想要计数我们需要找个地方存储行数：</p>\n<h3 id=\"1-用缓存系统保存计数\"><a href=\"#1-用缓存系统保存计数\" class=\"headerlink\" title=\"1.用缓存系统保存计数\"></a>1.用缓存系统保存计数</h3><p>你可以用一个 Redis 服务来保存这个表的总行数。这个表每被插入一行 Redis 计数就加 1，每被删除一行 Redis 计数就减 1。这种方式下，读和更新操作都很快，但你再想一下这种方式存在什么问题吗？</p>\n<p>没错，缓存系统可能会<strong>丢失更新</strong>。</p>\n<p>Redis 的数据不能永久地留在内存里，所以你会找一个地方把这个值定期地持久化存储起来。但即使这样，仍然可能丢失更新。试想如果刚刚在数据表中插入了一行，Redis 中保存的值也加了 1，然后 Redis 异常重启了，重启后你要从存储 redis 数据的地方把这个值读回来，而刚刚加 1 的这个计数操作却丢失了。</p>\n<p>当然了，这还是有解的。比如，Redis 异常重启以后，到数据库里面单独执行一次 count(*) 获取真实的行数，再把这个值写回到 Redis 里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。</p>\n<p>但实际上，<strong>将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的：</strong></p>\n<ol>\n<li>一种是，查到的 100 行结果里面有最新插入记录，而 Redis 的计数里还没加 1；</li>\n<li>另一种是，查到的 100 行结果里没有最新插入的记录，而 Redis 的计数里已经加了 1。</li>\n</ol>\n<h3 id=\"2-在数据库保存计数\"><a href=\"#2-在数据库保存计数\" class=\"headerlink\" title=\"2.在数据库保存计数\"></a>2.在数据库保存计数</h3><p>用缓存系统保存计数有丢失数据和计数不精确的问题。那么，<strong>如果我们把这个计数直接放到数据库里单独的一张计数表 C 中，又会怎么样呢？</strong></p>\n<p>首先，这解决了崩溃丢失的问题，InnoDB 是支持崩溃恢复不丢数据的。</p>\n<p>由于 InnoDB 要支持事务，从而导致 InnoDB 表不能把 count(*) 直接存起来，然后查询的时候直接返回形成的。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20220923004744.372w0lyzcm00.webp\"/>\n</div>\n\n<p>虽然会话 B 的读操作仍然是在 T3 执行的，但是因为这时候更新事务还没有提交，所以计数值加 1 这个操作对会话 B 还不可见。</p>\n<p>因此，会话 B 看到的结果里， 查计数值和“最近 100 条记录”看到的结果，逻辑上就是一致的。</p>\n<h2 id=\"不同count的用法\"><a href=\"#不同count的用法\" class=\"headerlink\" title=\"不同count的用法\"></a>不同count的用法</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>count() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。</p></blockquote>\n<p>所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。</p>\n<p>至于分析性能差别的时候，有几个原则：</p>\n<ol>\n<li>server 层要什么就给什么；</li>\n<li>InnoDB 只给必要的值；</li>\n<li>现在的优化器只优化了 count(*) 的语义为“取行数”，其他“显而易见”的优化并没有做。</li>\n</ol>\n<p><strong>对于 count(主键 id) 来说</strong>，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。</p>\n<p><strong>对于 count(1) 来说</strong>，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。</p>\n<p>单看这两个用法的差别的话，你能对比出来，count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。</p>\n<p><strong>对于 count(字段) 来说</strong>：</p>\n<ol>\n<li>如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；</li>\n<li>如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。</li>\n</ol>\n<p>也就是前面的第一条原则，server 层要什么字段，InnoDB 就返回什么字段。</p>\n<p><strong>但是 count(*) 是例外</strong>，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。</p>\n<details class=\"custom-details\">\n<summary>强烈推荐这篇参考文章</summary>\n<p><p><a href=\"https://learnsql.com/blog/difference-between-count-distinct/\">https://learnsql.com/blog/difference-between-count-distinct/</a> (这篇文章讲的非常好)</p>\n</p>\n</details>\n<h1 id=\"排序机制\"><a href=\"#排序机制\" class=\"headerlink\" title=\"排序机制\"></a>排序机制</h1><h2 id=\"全字段排序\"><a href=\"#全字段排序\" class=\"headerlink\" title=\"全字段排序\"></a>全字段排序</h2><p>通常情况下，这个语句执行流程如下所示 ：</p>\n<ol>\n<li>初始化 sort_buffer，确定放入 name、city、age 这三个字段；</li>\n<li>从索引 city 找到第一个满足 city&#x3D;’杭州’条件的主键 id，也就是图中的 ID_X；</li>\n<li>到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；</li>\n<li>从索引 city 取下一个记录的主键 id；</li>\n<li>重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；</li>\n<li>对 sort_buffer 中的数据按照字段 name 做快速排序；</li>\n<li>按照排序结果取前 1000 行返回给客户端。</li>\n</ol>\n<div class=\"custom-quote warning\">\n<span class=\"custom-quote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M20.86 14.13C20 14.7 19.56 15.74 19.77 16.76C20.13 18.55 18.55 20.13 16.76 19.77C15.74 19.57 14.7 20 14.13 20.86C13.12 22.38 10.89 22.38 9.88 20.86C9.3 20 8.26 19.56 7.24 19.77C5.45 20.13 3.87 18.55 4.23 16.76C4.43 15.74 4 14.7 3.14 14.13C1.62 13.12 1.62 10.89 3.14 9.88C4 9.3 4.44 8.26 4.23 7.24C3.87 5.45 5.45 3.87 7.24 4.23C8.26 4.44 9.3 4 9.87 3.14C10.88 1.62 13.11 1.62 14.12 3.14C14.7 4 15.74 4.44 16.76 4.23C18.55 3.87 20.13 5.45 19.77 7.24C19.56 8.26 20 9.3 20.86 9.87C22.38 10.88 22.38 13.12 20.86 14.13Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M12 8V13\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M12 15.99V16.01\"></path>\n</svg>\n</span>\n<p class=\"custom-quote-title\">注意</p>\n<p>“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。</p>\n\n</div>\n<h2 id=\"rowid-排序\"><a href=\"#rowid-排序\" class=\"headerlink\" title=\"rowid 排序\"></a>rowid 排序</h2><p>在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。</p>\n<p>max_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。</p>\n<p>city、name、age 这三个字段的定义总长度是 36，我把 max_length_for_sort_data 设置为 16，我们再来看看计算过程有什么改变。</p>\n<p>新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。</p>\n<p>整个执行流程就变成如下所示的样子：</p>\n<ol>\n<li>初始化 sort_buffer，确定放入两个字段，即 name 和 id；</li>\n<li>从索引 city 找到第一个满足 city&#x3D;’杭州’条件的主键 id，也就是图中的 ID_X；</li>\n<li>到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；</li>\n<li>从索引 city 取下一个记录的主键 id；</li>\n<li>重复步骤 3、4 直到不满足 city&#x3D;’杭州’条件为止，也就是图中的 ID_Y；</li>\n<li>对 sort_buffer 中的数据按照字段 name 进行排序；</li>\n<li>遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。</li>\n</ol>\n<h2 id=\"全字段排序-VS-rowid-排序\"><a href=\"#全字段排序-VS-rowid-排序\" class=\"headerlink\" title=\"全字段排序 VS rowid 排序\"></a>全字段排序 VS rowid 排序</h2><p>如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。</p>\n<p>如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。</p>\n<p>这也就体现了 MySQL 的一个设计思想：<strong>如果内存够，就要多利用内存，尽量减少磁盘访问。</strong></p>\n<h2 id=\"索引优化排序性能\"><a href=\"#索引优化排序性能\" class=\"headerlink\" title=\"索引优化排序性能\"></a>索引优化排序性能</h2><h3 id=\"联合索引\"><a href=\"#联合索引\" class=\"headerlink\" title=\"联合索引\"></a>联合索引</h3><p>其实，并不是所有的 order by 语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，<strong>其原因是原来的数据都是无序的。</strong></p>\n<p>我们可以在这个市民表上创建一个 city 和 name 的联合索引，对应的 SQL 语句是：</p>\n<pre class=\"line-numbers language-mysql\" data-language=\"mysql\"><code class=\"language-mysql\">alter table t add index city_user(city, name);<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p>在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足 city&#x3D;’杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是杭州，name 的值就一定是有序的。</p>\n<p>这样整个查询过程的流程就变成了：</p>\n<ol>\n<li>从索引 (city,name) 找到第一个满足 city&#x3D;’杭州’条件的主键 id；</li>\n<li>到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；</li>\n<li>从索引 (city,name) 取下一个记录主键 id；</li>\n<li>重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city&#x3D;’杭州’条件时循环结束。</li>\n</ol>\n<h3 id=\"覆盖索引\"><a href=\"#覆盖索引\" class=\"headerlink\" title=\"覆盖索引\"></a>覆盖索引</h3><p><strong>覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。</strong></p>\n<p>按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程。</p>\n<p>针对这个查询，我们可以创建一个 city、name 和 age 的联合索引，对应的 SQL 语句就是：</p>\n<pre class=\"line-numbers language-mysql\" data-language=\"mysql\"><code class=\"language-mysql\">alter table t add index city_user_age(city, name, age);<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p>这时，对于 city 字段的值相同的行来说，还是按照 name 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了：</p>\n<ol>\n<li>从索引 (city,name,age) 找到第一个满足 city&#x3D;’杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；</li>\n<li>从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；</li>\n<li>重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city&#x3D;’杭州’条件时循环结束。</li>\n</ol>\n<h2 id=\"随机消息\"><a href=\"#随机消息\" class=\"headerlink\" title=\"随机消息\"></a>随机消息</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><strong>对于 InnoDB 表来说</strong>，执行全字段排序会减少磁盘访问，因此会被优先选择。</p>\n<p><strong>对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘</strong>。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越小越好了，所以，MySQL 这时就会选择 rowid 排序。</p></blockquote>\n<p>这条语句的执行流程是这样的：</p>\n<ol>\n<li>创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。</li>\n<li>从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。</li>\n<li>现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R 排序。</li>\n<li>初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。</li>\n<li>从内存临时表中一行一行地取出 R 值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。</li>\n<li>在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。</li>\n<li>排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。</li>\n</ol>\n<h3 id=\"磁盘临时表\"><a href=\"#磁盘临时表\" class=\"headerlink\" title=\"磁盘临时表\"></a>磁盘临时表</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>tmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。</p>\n<p>磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。</p>\n<p>当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。</p></blockquote>\n<p>采用是 MySQL 5.6 版本引入的一个新的排序算法，即：优先队列排序算法。接下来，我们就看看为什么没有使用临时文件的算法，也就是归并排序算法，而是采用了优先队列排序算法。</p>\n<p>其实，我们现在的 SQL 语句，只需要取 R 值最小的 3 个 rowid。但是，如果使用归并排序算法的话，虽然最终也能得到前 3 个值，但是这个算法结束后，已经将 10000 行数据都排好序了。</p>\n<p>也就是说，后面的 9997 行也是有序的了。但，我们的查询并不需要这些数据是有序的。所以，想一下就明白了，这浪费了非常多的计算量。</p>\n<p>而优先队列算法，就可以精确地只得到三个最小值，执行流程如下：</p>\n<ol>\n<li>对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；</li>\n</ol>\n<p>（对数据结构印象模糊的同学，可以先设想成这是一个由三个元素组成的数组）</p>\n<ol>\n<li>取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；</li>\n<li>重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。</li>\n</ol>\n<h3 id=\"随机排序方法\"><a href=\"#随机排序方法\" class=\"headerlink\" title=\"随机排序方法\"></a>随机排序方法</h3><p>我们先把问题简化一下，如果只随机选择 1 个 word 值，可以怎么做呢？思路上是这样的：</p>\n<ol>\n<li>取得这个表的主键 id 的最大值 M 和最小值 N;</li>\n<li>用随机函数生成一个最大值到最小值之间的数 X &#x3D; (M-N)*rand() + N;</li>\n<li>取不小于 X 的第一个 ID 的行。</li>\n</ol>\n<p>这个方法效率很高，因为取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的 select 也可以用索引快速定位，可以认为就只扫描了 3 行。但实际上，这个算法本身并不严格满足题目的随机要求，因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。</p>\n<p>所以，为了得到严格随机的结果，你可以用下面这个流程:</p>\n<ol>\n<li>取得整个表的行数，并记为 C。</li>\n<li>取得 Y &#x3D; floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。</li>\n<li>再用 limit Y,1 取得一行。</li>\n</ol>\n<p>现在，我们再看看，如果我们按照随机算法 2 的思路，要随机取 3 个 word 值呢？你可以这么做：</p>\n<ol>\n<li>取得整个表的行数，记为 C；</li>\n<li>根据相同的随机方法得到 Y1、Y2、Y3；</li>\n<li>再执行三个 limit Y, 1 语句得到三行数据。</li>\n</ol>\n<h1 id=\"全表扫描\"><a href=\"#全表扫描\" class=\"headerlink\" title=\"全表扫描\"></a>全表扫描</h1><p>InnoDB 内存管理用的是最近最少使用 (Least Recently Used, LRU) 算法，这个算法的核心就是淘汰最久未使用的数据。</p>\n<p>下图是一个 LRU 算法的基本模型。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20221005164133.1w83oux7u3ts.webp\"/>\n</div>\n\n<p>InnoDB 管理 Buffer Pool 的 LRU 算法，是用链表来实现的。</p>\n<ol>\n<li>在图 6 的状态 1 里，链表头部是 P1，表示 P1 是最近刚刚被访问过的数据页；假设内存里只能放下这么多数据页；</li>\n<li>这时候有一个读请求访问 P3，因此变成状态 2，P3 被移到最前面；</li>\n<li>状态 3 表示，这次访问的数据页是不存在于链表中的，所以需要在 Buffer Pool 中新申请一个数据页 Px，加到链表头部。但是由于内存已经满了，不能申请新的内存。于是，会清空链表末尾 Pm 这个数据页的内存，存入 Px 的内容，然后放到链表头部。</li>\n<li>从效果上看，就是最久没有被访问的数据页 Pm，被淘汰了。</li>\n</ol>\n<p>假设按照这个算法，我们要扫描一个 200G 的表，而这个表是一个历史数据表，平时没有业务访问它。</p>\n<p>那么，按照这个算法扫描的话，就会把当前的 Buffer Pool 里的数据全部淘汰掉，存入扫描过程中访问到的数据页的内容。也就是说 Buffer Pool 里面主要放的是这个历史数据表的数据。</p>\n<p>对于一个正在做业务服务的库，这可不妙。你会看到，Buffer Pool 的内存命中率急剧下降，磁盘压力增加，SQL 语句响应变慢。</p>\n<p>所以，InnoDB 不能直接使用这个 LRU 算法。实际上，InnoDB 对 LRU 算法做了改进。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20221005164630.1abb2czawyjk.webp\"/>\n</div>\n\n<p>在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域。图中 LRU_old 指向的就是 old 区域的第一个位置，是整个链表的 5&#x2F;8 处。也就是说，靠近链表头部的 5&#x2F;8 是 young 区域，靠近链表尾部的 3&#x2F;8 是 old 区域。</p>\n<p>改进后的 LRU 算法执行流程变成了下面这样。</p>\n<ol>\n<li>图 7 中状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态 2。</li>\n<li>之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 Px，是放在 LRU_old 处。</li>\n<li>处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：<ul>\n<li>若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部；</li>\n<li>如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒。</li>\n</ul>\n</li>\n</ol>\n<p>这个策略，就是为了处理类似全表扫描的操作量身定制的。还是以刚刚的扫描 200G 的历史数据表为例，我们看看改进后的 LRU 算法的操作逻辑：</p>\n<ol>\n<li>扫描过程中，需要新插入的数据页，都被放到 old 区域 ;</li>\n<li>一个数据页里面有多条记录，这个数据页会被多次访问到，但由于是顺序扫描，这个数据页第一次被访问和最后一次被访问的时间间隔不会超过 1 秒，因此还是会被保留在 old 区域；</li>\n<li>再继续扫描后续的数据，之前的这个数据页之后也不会再被访问到，于是始终没有机会移到链表头部（也就是 young 区域），很快就会被淘汰出去。</li>\n</ol>\n<p>可以看到，这个策略最大的收益，就是在扫描这个大表的过程中，虽然也用到了 Buffer Pool，但是对 young 区域完全没有影响，从而保证了 Buffer Pool 响应正常业务的查询命中率。</p>\n<h1 id=\"join算法\"><a href=\"#join算法\" class=\"headerlink\" title=\"join算法\"></a>join算法</h1><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://blog.csdn.net/qq_41931364/article/details/121877375\">Mysql-表连接join中的NLJ、BNL算法</a></p></blockquote>\n<h2 id=\"Index-Nested-Loop-Join（NJL）\"><a href=\"#Index-Nested-Loop-Join（NJL）\" class=\"headerlink\" title=\"Index Nested-Loop Join（NJL）\"></a>Index Nested-Loop Join（NJL）</h2><p>我们来看一下这个语句：</p>\n<pre class=\"line-numbers language-mysql\" data-language=\"mysql\"><code class=\"language-mysql\">select * from t1 straight_join t2 on (t1.a&#x3D;t2.a);<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p>如果直接使用 join 语句，MySQL 优化器可能会选择表 t1 或 t2 作为驱动表，这样会影响我们分析 SQL 语句的执行过程。所以，为了便于分析执行过程中的性能问题，我改用 straight_join 让 MySQL 使用固定的连接方式执行查询，这样优化器只会按照我们指定的方式去 join。在这个语句里，t1 是驱动表，t2 是被驱动表。</p>\n<p>可以看到，在这条语句里，被驱动表 t2 的字段 a 上有索引，join 过程用上了这个索引，因此这个语句的执行流程是这样的：</p>\n<ol>\n<li>从表 t1 中读入一行数据 R；</li>\n<li>从数据行 R 中，取出 a 字段到表 t2 里去查找；</li>\n<li>取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；</li>\n<li>重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。</li>\n</ol>\n<p>这个过程是先遍历表 t1，然后根据从表 t1 中取出的每行数据中的 a 值，去表 t2 中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称 NLJ。</p>\n<p>可以看到，在这条语句里，被驱动表 t2 的字段 a 上有索引，join 过程用上了这个索引，因此这个语句的执行流程是这样的：</p>\n<ol>\n<li>从表 t1 中读入一行数据 R；</li>\n<li>从数据行 R 中，取出 a 字段到表 t2 里去查找；</li>\n<li>取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；</li>\n<li>重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。</li>\n</ol>\n<p>这个过程是先遍历表 t1，然后根据从表 t1 中取出的每行数据中的 a 值，去表 t2 中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称 NLJ。</p>\n<p>它对应的流程图如下所示：</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20221006015013.47z2j50lq3s0.webp\"/>\n</div>\n\n<p>在这个流程里：</p>\n<ol>\n<li>对驱动表 t1 做了全表扫描，这个过程需要扫描 100 行；</li>\n<li>而对于每一行 R，根据 a 字段去表 t2 查找，走的是树搜索过程。由于我们构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描 100 行；</li>\n<li>所以，整个执行流程，总扫描行数是 200。</li>\n</ol>\n<p>到这里小结一下，通过上面的分析我们得到了两个结论：</p>\n<ol>\n<li>使用 join 语句，性能比强行拆成多个单表执行 SQL 语句的性能要好；</li>\n<li>如果使用 join 语句的话，需要让小表做驱动表。</li>\n</ol>\n<p>但是，你需要注意，这个结论的前提是“<strong>可以使用被驱动表的索引</strong>”。</p>\n<h2 id=\"Block-Nested-Loop-Join（BNL）\"><a href=\"#Block-Nested-Loop-Join（BNL）\" class=\"headerlink\" title=\"Block Nested-Loop Join（BNL）\"></a>Block Nested-Loop Join（BNL）</h2><p>这时候，被驱动表上没有可用的索引，算法的流程是这样的：</p>\n<ol>\n<li>把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；</li>\n<li>扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。</li>\n</ol>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20221006015551.8ncy0cpde4c.webp\"/>\n</div>\n\n<p>可以看到，在这个过程中，对表 t1 和 t2 都做了一次全表扫描，因此总的扫描行数是 1100。由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做 100 次判断，总共需要在内存中做的判断次数是：100*1000&#x3D;10 万次。</p>\n<p>前面我们说过，如果使用 Simple Nested-Loop Join 算法进行查询，扫描行数也是 10 万行。因此，从时间复杂度上来说，这两个算法是一样的。但是，Block Nested-Loop Join 算法的这 10 万次判断是内存操作，速度上会快很多，性能也更好。</p>\n<p>接下来，我们来看一下，在这种情况下，应该选择哪个表做驱动表。</p>\n<p>假设小表的行数是 N，大表的行数是 M，那么在这个算法里：</p>\n<ol>\n<li>两个表都做一次全表扫描，所以总的扫描行数是 M+N；</li>\n<li>内存中的判断次数是 M*N。</li>\n</ol>\n<p>可以看到，调换这两个算式中的 M 和 N 没差别，因此这时候选择大表还是小表做驱动表，执行耗时是一样的。</p>\n<p>然后，你可能马上就会问了，这个例子里表 t1 才 100 行，要是表 t1 是一个大表，join_buffer 放不下怎么办呢？</p>\n<p>join_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。<strong>如果放不下表 t1 的所有数据话，策略很简单，就是分段放。</strong></p>\n<p>执行过程就变成了：</p>\n<ol>\n<li>扫描表 t1，顺序读取数据行放入 join_buffer 中，放完第 88 行 join_buffer 满了，继续第 2 步；</li>\n<li>扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回；</li>\n<li>清空 join_buffer；</li>\n<li>继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步。</li>\n</ol>\n<p>执行流程图也就变成这样：</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20221006015638.14zsm6cioo2k.webp\"/>\n</div>\n\n<p>图中的步骤 4 和 5，表示清空 join_buffer 再复用。</p>\n<p>这个流程才体现出了这个算法名字中“Block”的由来，表示“分块去 join”。</p>\n<p>可以看到，这时候由于表 t1 被分成了两次放入 join_buffer 中，导致表 t2 会被扫描两次。虽然分成两次放入 join_buffer，但是判断等值条件的次数还是不变的，依然是 (88+12)*1000&#x3D;10 万次。</p>\n<p>我们再来看下，在这种情况下驱动表的选择问题。</p>\n<p>假设，驱动表的数据行数是 N，需要分 K 段才能完成算法流程，被驱动表的数据行数是 M。</p>\n<p>注意，这里的 K 不是常数，N 越大 K 就会越大，因此把 K 表示为λ*N，显然λ的取值范围是 (0,1)。</p>\n<p>所以，在这个算法的执行过程中：</p>\n<ol>\n<li>扫描行数是 N+λ<em>N</em>M；</li>\n<li>内存判断 N*M 次。</li>\n</ol>\n<h2 id=\"Multi-Range-Read-优化（MRR）\"><a href=\"#Multi-Range-Read-优化（MRR）\" class=\"headerlink\" title=\"Multi-Range Read 优化（MRR）\"></a>Multi-Range Read 优化（MRR）</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Multi-Range Read 优化 (MRR)。这个优化的主要目的是尽量使用顺序读盘。</p></blockquote>\n<p>如果随着 a 的值递增顺序查询的话，id 的值就变成随机的，那么就会出现随机访问，性能相对较差。虽然“按行查”这个机制不能改，但是调整查询的顺序，还是能够加速的。</p>\n<p><strong>因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。</strong></p>\n<p>这，就是 MRR 优化的设计思路。此时，语句的执行流程变成了这样：</p>\n<ol>\n<li>根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;</li>\n<li>将 read_rnd_buffer 中的 id 进行递增排序；</li>\n<li>排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。</li>\n</ol>\n<p>这里，read_rnd_buffer 的大小是由 read_rnd_buffer_size 参数控制的。如果步骤 1 中，read_rnd_buffer 放满了，就会先执行完步骤 2 和 3，然后清空 read_rnd_buffer。之后继续找索引 a 的下个记录，并继续循环。</p>\n<h2 id=\"Batched-Key-Access\"><a href=\"#Batched-Key-Access\" class=\"headerlink\" title=\"Batched Key Access\"></a>Batched Key Access</h2><p>在 join_buffer 中放入的数据是 P1<del>P100，表示的是只会取查询需要的字段。当然，如果 join buffer 放不下 P1</del>P100 的所有数据，就会把这 100 行数据分成多段执行上图的流程。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20221006015852.6ko3u95hr140.webp\"/>\n</div>\n\n<h2 id=\"扩展-hash-join\"><a href=\"#扩展-hash-join\" class=\"headerlink\" title=\"扩展 -hash join\"></a>扩展 -hash join</h2><p>看到这里你可能发现了，其实上面计算 10 亿次那个操作，看上去有点儿傻。如果 join_buffer 里面维护的不是一个无序数组，而是一个哈希表的话，那么就不是 10 亿次判断，而是 100 万次 hash 查找。这样的话，整条语句的执行速度就快多了吧？</p>\n<p>确实如此。</p>\n<p>这，也正是 MySQL 的优化器和执行器一直被诟病的一个原因：不支持哈希 join。并且，MySQL 官方的 roadmap，也是迟迟没有把这个优化排上议程。</p>\n<p>实际上，这个优化思路，我们可以自己实现在业务端。实现流程大致如下：</p>\n<ol>\n<li><code>select * from t1;</code>取得表 t1 的全部 1000 行数据，在业务端存入一个 hash 结构，比如 C++ 里的 set、PHP 的数组这样的数据结构。</li>\n<li><code>select * from t2 where b&gt;=1 and b&lt;=2000;</code> 获取表 t2 中满足条件的 2000 行数据。</li>\n<li>把这 2000 行数据，一行一行地取到业务端，到 hash 结构的数据表中寻找匹配的数据。满足匹配的条件的这行数据，就作为结果集的一行。</li>\n</ol>\n<h2 id=\"小结\"><a href=\"#小结\" class=\"headerlink\" title=\"小结\"></a>小结</h2><div class=\"custom-quote tip\">\n<span class=\"custom-quote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M20.86 14.13C20 14.7 19.56 15.74 19.77 16.76C20.13 18.55 18.55 20.13 16.76 19.77C15.74 19.57 14.7 20 14.13 20.86C13.12 22.38 10.89 22.38 9.88 20.86C9.3 20 8.26 19.56 7.24 19.77C5.45 20.13 3.87 18.55 4.23 16.76C4.43 15.74 4 14.7 3.14 14.13C1.62 13.12 1.62 10.89 3.14 9.88C4 9.3 4.44 8.26 4.23 7.24C3.87 5.45 5.45 3.87 7.24 4.23C8.26 4.44 9.3 4 9.87 3.14C10.88 1.62 13.11 1.62 14.12 3.14C14.7 4 15.74 4.44 16.76 4.23C18.55 3.87 20.13 5.45 19.77 7.24C19.56 8.26 20 9.3 20.86 9.87C22.38 10.88 22.38 13.12 20.86 14.13Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M12.01 15C12.01 14.5 12.01 14.5 12.01 14.5C12.04 13.75 13 13.46 14.04 12.2C14.41 11.74 14.69 11.41 14.86 10.85C15.15 9.95 14.92 9.18 14.86 9.02C14.8 8.79 14.52 8 13.72 7.46C13.06 7.02 12.42 7 12.14 7C11.9 7 11.36 7 10.78 7.3C10.28 7.56 9.98 7.9 9.83 8.1C9.24 8.82 9.06 9.63 9 10.06\"></path>\n<path stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M11.99 18H12.01\"></path>\n</svg></span>\n<p class=\"custom-quote-title\">提示</p>\n<p><ol>\n<li>BKA 优化是 MySQL 已经内置支持的，建议你默认使用；</li>\n<li>BNL 算法效率低，建议你都尽量转成 BKA 算法。优化的方向就是给被驱动表的关联字段加上索引；</li>\n<li>基于临时表的改进方案，对于能够提前过滤出小数据的 join 语句来说，效果还是很好的；</li>\n<li>MySQL 目前的版本还不支持 hash join，但你可以配合应用端自己模拟出来，理论上效果要好于临时表的方案。</li>\n</ol>\n</p>\n</div>\n","text":"数据库表的空间回收机制 一个 InnoDB 表包含两部分，即：表结构定义和数据。因为表结构定义占用的空间很小，所以我们今天主要讨论的是表数据。 参数 innodb_file_per_table表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_fil...","link":"","photos":[],"count_time":{"symbolsCount":"15k","symbolsTime":"14 mins."},"categories":[{"name":"数据库","slug":"数据库","count":6,"path":"api/categories/数据库.json"}],"tags":[{"name":"MySQL","slug":"MySQL","count":6,"path":"api/tags/MySQL.json"},{"name":"框架学习","slug":"框架学习","count":6,"path":"api/tags/框架学习.json"},{"name":"基础概念","slug":"基础概念","count":6,"path":"api/tags/基础概念.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%BA%93%E8%A1%A8%E7%9A%84%E7%A9%BA%E9%97%B4%E5%9B%9E%E6%94%B6%E6%9C%BA%E5%88%B6\"><span class=\"toc-text\">数据库表的空间回收机制</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%8F%82%E6%95%B0-innodb-file-per-table\"><span class=\"toc-text\">参数 innodb_file_per_table</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E5%88%A0%E9%99%A4%E6%B5%81%E7%A8%8B\"><span class=\"toc-text\">数据删除流程</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%87%8D%E5%BB%BA%E8%A1%A8\"><span class=\"toc-text\">重建表</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Online-%E5%92%8C-inplace\"><span class=\"toc-text\">Online 和 inplace</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#count-%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E5%BC%8F\"><span class=\"toc-text\">count(*) 的实现方式</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E8%A1%8C%E6%95%B0%E7%9A%84%E5%AD%98%E5%82%A8%E6%96%B9%E5%BC%8F\"><span class=\"toc-text\">数据行数的存储方式</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-%E7%94%A8%E7%BC%93%E5%AD%98%E7%B3%BB%E7%BB%9F%E4%BF%9D%E5%AD%98%E8%AE%A1%E6%95%B0\"><span class=\"toc-text\">1.用缓存系统保存计数</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-%E5%9C%A8%E6%95%B0%E6%8D%AE%E5%BA%93%E4%BF%9D%E5%AD%98%E8%AE%A1%E6%95%B0\"><span class=\"toc-text\">2.在数据库保存计数</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%8D%E5%90%8Ccount%E7%9A%84%E7%94%A8%E6%B3%95\"><span class=\"toc-text\">不同count的用法</span></a></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%8E%92%E5%BA%8F%E6%9C%BA%E5%88%B6\"><span class=\"toc-text\">排序机制</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%85%A8%E5%AD%97%E6%AE%B5%E6%8E%92%E5%BA%8F\"><span class=\"toc-text\">全字段排序</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#rowid-%E6%8E%92%E5%BA%8F\"><span class=\"toc-text\">rowid 排序</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%85%A8%E5%AD%97%E6%AE%B5%E6%8E%92%E5%BA%8F-VS-rowid-%E6%8E%92%E5%BA%8F\"><span class=\"toc-text\">全字段排序 VS rowid 排序</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%B4%A2%E5%BC%95%E4%BC%98%E5%8C%96%E6%8E%92%E5%BA%8F%E6%80%A7%E8%83%BD\"><span class=\"toc-text\">索引优化排序性能</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95\"><span class=\"toc-text\">联合索引</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%A6%86%E7%9B%96%E7%B4%A2%E5%BC%95\"><span class=\"toc-text\">覆盖索引</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%9A%8F%E6%9C%BA%E6%B6%88%E6%81%AF\"><span class=\"toc-text\">随机消息</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%A3%81%E7%9B%98%E4%B8%B4%E6%97%B6%E8%A1%A8\"><span class=\"toc-text\">磁盘临时表</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%9A%8F%E6%9C%BA%E6%8E%92%E5%BA%8F%E6%96%B9%E6%B3%95\"><span class=\"toc-text\">随机排序方法</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E5%85%A8%E8%A1%A8%E6%89%AB%E6%8F%8F\"><span class=\"toc-text\">全表扫描</span></a></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#join%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">join算法</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Index-Nested-Loop-Join%EF%BC%88NJL%EF%BC%89\"><span class=\"toc-text\">Index Nested-Loop Join（NJL）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Block-Nested-Loop-Join%EF%BC%88BNL%EF%BC%89\"><span class=\"toc-text\">Block Nested-Loop Join（BNL）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Multi-Range-Read-%E4%BC%98%E5%8C%96%EF%BC%88MRR%EF%BC%89\"><span class=\"toc-text\">Multi-Range Read 优化（MRR）</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Batched-Key-Access\"><span class=\"toc-text\">Batched Key Access</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%89%A9%E5%B1%95-hash-join\"><span class=\"toc-text\">扩展 -hash join</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%B0%8F%E7%BB%93\"><span class=\"toc-text\">小结</span></a></li></ol></li></ol>","author":{"name":"依水何安","slug":"blog-author","avatar":"/img/b8d3b3c382fa44e5c92a361d33e0c616_hd.png","link":"/","description":"一个抽象的码农","socials":{"github":"https://github.com/jankin12138","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/img/bilibili.png","link":"https://space.bilibili.com/14624621?spm_id_from=333.1007.0.0"}}}},"mapped":true,"prev_post":{"title":"MySQL幻读","uid":"298ae6749824eedc891feac490554768","slug":"MySQL幻读","date":"2022-09-25T15:36:04.000Z","updated":"2022-09-25T17:14:06.447Z","comments":true,"path":"api/articles/MySQL幻读.json","keywords":null,"cover":"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20220925233721.3kvfyk9f5dw0.webp","text":" 幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。 提示 这里对“幻读”做一个说明： 在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。 上面 session B 的修改结果，被 ...","link":"","photos":[],"count_time":{"symbolsCount":819,"symbolsTime":"1 mins."},"categories":[{"name":"数据库","slug":"数据库","count":6,"path":"api/categories/数据库.json"}],"tags":[{"name":"MySQL","slug":"MySQL","count":6,"path":"api/tags/MySQL.json"},{"name":"框架学习","slug":"框架学习","count":6,"path":"api/tags/框架学习.json"},{"name":"基础概念","slug":"基础概念","count":6,"path":"api/tags/基础概念.json"}],"author":{"name":"依水何安","slug":"blog-author","avatar":"/img/b8d3b3c382fa44e5c92a361d33e0c616_hd.png","link":"/","description":"一个抽象的码农","socials":{"github":"https://github.com/jankin12138","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/img/bilibili.png","link":"https://space.bilibili.com/14624621?spm_id_from=333.1007.0.0"}}}}},"next_post":{"title":"MySQL锁设计","uid":"88440a5b541fa0a94c29d4531936445a","slug":"全局锁","date":"2022-09-17T12:22:15.000Z","updated":"2022-10-04T14:16:24.782Z","comments":true,"path":"api/articles/全局锁.json","keywords":null,"cover":"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/sky2_4k.5uuiad67q1c0.webp","text":" 根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。 全局锁顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。 当你需要让整个库处于只读状态的时...","link":"","photos":[],"count_time":{"symbolsCount":"4.5k","symbolsTime":"4 mins."},"categories":[{"name":"数据库","slug":"数据库","count":6,"path":"api/categories/数据库.json"}],"tags":[{"name":"MySQL","slug":"MySQL","count":6,"path":"api/tags/MySQL.json"},{"name":"框架学习","slug":"框架学习","count":6,"path":"api/tags/框架学习.json"},{"name":"基础概念","slug":"基础概念","count":6,"path":"api/tags/基础概念.json"}],"author":{"name":"依水何安","slug":"blog-author","avatar":"/img/b8d3b3c382fa44e5c92a361d33e0c616_hd.png","link":"/","description":"一个抽象的码农","socials":{"github":"https://github.com/jankin12138","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/img/bilibili.png","link":"https://space.bilibili.com/14624621?spm_id_from=333.1007.0.0"}}}}}}