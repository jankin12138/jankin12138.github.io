{"title":"操作系统笔记","uid":"3a69ec9c6ae67f12a8733f1c82dc14ae","slug":"操作系统笔记","date":"2022-10-24T13:03:48.000Z","updated":"2022-11-01T14:16:29.975Z","comments":true,"path":"api/articles/操作系统笔记.json","keywords":null,"cover":"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20221024210529.1hr147awjhds.webp","content":"<p>本文参考了<a href=\"https://www.xiaolincoding.com/network/\">小林coding</a>,csapp等操作系统教程，以及Websever的一些框架和思路。写了一篇个人的笔记，其中也包含了本人对于一些小问题的记录和思考，以及整体框架的梳理。</p>\n<h1 id=\"进程管理\"><a href=\"#进程管理\" class=\"headerlink\" title=\"进程管理\"></a>进程管理</h1><p>快速了解可以参考：</p>\n<iframe src=\"//player.bilibili.com/player.html?aid=756898053&bvid=BV1Wr4y1A7DS&cid=305517829&page=1\" scrolling=\"no\" border=\"0\" frameborder=\"no\" framespacing=\"0\" allowfullscreen=\"true\" style=\"width: 100%; height: 500px; max-width: 100%；align:center; padding:20px 0;\"> </iframe>\n\n<h2 id=\"进程\"><a href=\"#进程\" class=\"headerlink\" title=\"进程\"></a>进程</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个<strong>运行中的程序，就被称为「进程」（Process）</strong>。</p></blockquote>\n<p>现在我们考虑有一个会读取硬盘文件数据的程序被执行了，那么当运行到读取文件的指令时，就会去从硬盘读取数据，但是硬盘的读写速度是非常慢的，那么在这个时候，如果 CPU 傻傻的等硬盘返回数据的话，那 CPU 的利用率是非常低的。</p>\n<p>所以，当进程要从硬盘读取数据时，CPU 不需要阻塞等待数据的返回，而是去执行另外的进程。当硬盘数据返回时，CPU 会收到个中断，于是 CPU 再继续运行这个进程。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/4-进程交替运行.69ckb6e76z40.webp\"/>\n</div>\n\n<p>这种多个程序、交替执行的思想，就有 CPU 管理多个进程的初步想法。</p>\n<p>对于一个支持多进程的系统，CPU 会从一个进程快速切换至另一个进程，其间每个进程各运行几十或几百个毫秒。</p>\n<p>虽然单核的 CPU 在某一个瞬间，只能运行一个进程。但在 1 秒钟期间，它可能会运行多个进程，这样就产生并行的错觉，实际上这是并发。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/5-并发与并行.13i4r3noz15s.webp\"/>\n</div>\n\n<h3 id=\"进程的状态\"><a href=\"#进程的状态\" class=\"headerlink\" title=\"进程的状态\"></a>进程的状态</h3><p>一般说来，一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。</p>\n<p>它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。</p>\n<p>所以，<strong>在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。</strong></p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/8-进程五个状态.7bpmbwv5png0.webp\"/>\n</div>\n\n<p>上图中各个状态的意义：</p>\n<ul>\n<li>运行状态（<em>Running</em>）：该时刻进程占用 CPU；</li>\n<li>就绪状态（<em>Ready</em>）：可运行，由于其他进程处于运行状态而暂时停止运行；</li>\n<li>阻塞状态（<em>Blocked</em>）：该进程正在等待某一事件发生（如等待输入&#x2F;输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；</li>\n</ul>\n<p>当然，进程还有另外两个基本状态：</p>\n<ul>\n<li>创建状态（<em>new</em>）：进程正在被创建时的状态；</li>\n<li>结束状态（<em>Exit</em>）：进程正在从系统中消失时的状态；</li>\n</ul>\n<p>再来详细说明一下进程的状态变迁：</p>\n<ul>\n<li><em>NULL -&gt; 创建状态</em>：一个新进程被创建时的第一个状态；</li>\n<li><em>创建状态 -&gt; 就绪状态</em>：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；</li>\n<li><em>就绪态 -&gt; 运行状态</em>：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；</li>\n<li><em>运行状态 -&gt; 结束状态</em>：当进程已经运行完成或出错时，会被操作系统作结束状态处理；</li>\n<li><em>运行状态 -&gt; 就绪状态</em>：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；</li>\n<li><em>运行状态 -&gt; 阻塞状态</em>：当进程请求某个事件且必须等待时，例如请求 I&#x2F;O 事件；</li>\n<li><em>阻塞状态 -&gt; 就绪状态</em>：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；</li>\n</ul>\n<p>如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占用着物理内存就一种浪费物理内存的行为。</p>\n<p>所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。</p>\n<p>那么，就需要一个新的状态，来<strong>描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态</strong>。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。</p>\n<p>另外，挂起状态可以分为两种：</p>\n<ul>\n<li>阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；</li>\n<li>就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；</li>\n</ul>\n<p>导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：</p>\n<ul>\n<li>通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。</li>\n<li>用户希望挂起一个程序的执行，比如在 Linux 中用 <code>Ctrl+Z</code> 挂起进程；</li>\n</ul>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/10-进程七中状态.6igjpx554100.webp\"/>\n</div>\n\n<h3 id=\"进程的控制结构\"><a href=\"#进程的控制结构\" class=\"headerlink\" title=\"进程的控制结构\"></a>进程的控制结构</h3><p>在操作系统中，是用<strong>进程控制块</strong>（<em>process control block，PCB</em>）数据结构来描述进程的。</p>\n<p><strong>PCB 是进程存在的唯一标识</strong>，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。</p>\n<p><strong>进程描述信息：</strong></p>\n<ul>\n<li>进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；</li>\n<li>用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；</li>\n</ul>\n<p><strong>进程控制和管理信息：</strong></p>\n<ul>\n<li>进程当前状态，如 new、ready、running、waiting 或 blocked 等；</li>\n<li>进程优先级：进程抢占 CPU 时的优先级；</li>\n</ul>\n<p><strong>资源分配清单：</strong></p>\n<ul>\n<li>有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I&#x2F;O 设备信息。</li>\n</ul>\n<p><strong>CPU 相关信息：</strong></p>\n<ul>\n<li>CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。</li>\n</ul>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>每个 PCB 是如何组织的呢？</p></blockquote>\n<p>通常是通过<strong>链表</strong>的方式进行组织，把具有<strong>相同状态的进程链在一起，组成各种队列</strong>。比如：</p>\n<ul>\n<li>将所有处于就绪状态的进程链在一起，称为<strong>就绪队列</strong>；</li>\n<li>把所有因等待某事件而处于等待状态的进程链在一起就组成各种<strong>阻塞队列</strong>；</li>\n<li>另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。</li>\n</ul>\n<p>那么，就绪队列和阻塞队列链表的组织形式如下图：</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/12-PCB状态链表组织.4z6hpcxb8q80.webp\"/>\n</div>\n\n<p>除了链接的组织方式，还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。</p>\n<p>一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。</p>\n<h3 id=\"进程的控制\"><a href=\"#进程的控制\" class=\"headerlink\" title=\"进程的控制\"></a>进程的控制</h3><p>再来看看进程的<strong>创建、终止、阻塞、唤醒</strong>的过程，这些过程也就是进程的控制。</p>\n<p><strong>01 创建进程</strong></p>\n<p>操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。</p>\n<p>创建进程的过程如下：</p>\n<ul>\n<li>申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；</li>\n<li>为该进程分配运行时所必需的资源，比如内存资源；</li>\n<li>将 PCB 插入到就绪队列，等待被调度运行；</li>\n</ul>\n<p><strong>02 终止进程</strong></p>\n<p>进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 <code>kill</code> 掉）。</p>\n<p>当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。</p>\n<p>终止进程的过程如下：</p>\n<ul>\n<li>查找需要终止的进程的 PCB；</li>\n<li>如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；</li>\n<li>如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；</li>\n<li>将该进程所拥有的全部资源都归还给操作系统；</li>\n<li>将其从 PCB 所在队列中删除；</li>\n</ul>\n<p><strong>03 阻塞进程</strong></p>\n<p>当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。</p>\n<p>阻塞进程的过程如下：</p>\n<ul>\n<li>找到将要被阻塞进程标识号对应的 PCB；</li>\n<li>如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；</li>\n<li>将该 PCB 插入到阻塞队列中去；</li>\n</ul>\n<p><strong>04 唤醒进程</strong></p>\n<p>进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。</p>\n<p>如果某进程正在等待 I&#x2F;O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。</p>\n<p>唤醒进程的过程如下：</p>\n<ul>\n<li>在该事件的阻塞队列中找到相应进程的 PCB；</li>\n<li>将其从阻塞队列中移出，并置其状态为就绪状态；</li>\n<li>把该 PCB 插入到就绪队列中，等待调度程序调度；</li>\n</ul>\n<p>进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。</p>\n<h3 id=\"进程的上下文切换\"><a href=\"#进程的上下文切换\" class=\"headerlink\" title=\"进程的上下文切换\"></a>进程的上下文切换</h3><p>各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个<strong>一个进程切换到另一个进程运行，称为进程的上下文切换</strong>。</p>\n<p>大多数操作系统都是多任务，通常支持大于 CPU 数量的任务同时运行。实际上，这些任务并不是同时运行的，只是因为系统在很短的时间内，让各个任务分别在 CPU 运行，于是就造成同时运行的错觉。</p>\n<p>任务是交给 CPU 运行的，那么在每个任务运行前，CPU 需要知道任务从哪里加载，又从哪里开始运行。</p>\n<p>所以，操作系统需要事先帮 CPU 设置好 <strong>CPU 寄存器和程序计数器</strong>。</p>\n<p>CPU 寄存器是 CPU 内部一个容量小，但是速度极快的内存（缓存）。我举个例子，寄存器像是你的口袋，内存像你的书包，硬盘则是你家里的柜子，如果你的东西存放到口袋，那肯定是比你从书包或家里柜子取出来要快的多。</p>\n<p>再来，程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。</p>\n<p>所以说，CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 <strong>CPU 上下文</strong>。</p>\n<p>CPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。</p>\n<p>系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。</p>\n<p>上面说到所谓的「任务」，主要包含进程、线程和中断。所以，可以根据任务的不同，把 CPU 上下文切换分成：<strong>进程上下文切换、线程上下文切换和中断上下文切换</strong>。</p>\n<p>进程是由内核管理和调度的，所以进程的切换只能发生在内核态。</p>\n<p>所以，<strong>进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。</strong></p>\n<p>通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行</p>\n<div class=\"custom-quote warning\">\n<span class=\"custom-quote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M20.86 14.13C20 14.7 19.56 15.74 19.77 16.76C20.13 18.55 18.55 20.13 16.76 19.77C15.74 19.57 14.7 20 14.13 20.86C13.12 22.38 10.89 22.38 9.88 20.86C9.3 20 8.26 19.56 7.24 19.77C5.45 20.13 3.87 18.55 4.23 16.76C4.43 15.74 4 14.7 3.14 14.13C1.62 13.12 1.62 10.89 3.14 9.88C4 9.3 4.44 8.26 4.23 7.24C3.87 5.45 5.45 3.87 7.24 4.23C8.26 4.44 9.3 4 9.87 3.14C10.88 1.62 13.11 1.62 14.12 3.14C14.7 4 15.74 4.44 16.76 4.23C18.55 3.87 20.13 5.45 19.77 7.24C19.56 8.26 20 9.3 20.86 9.87C22.38 10.88 22.38 13.12 20.86 14.13Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M12 8V13\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M12 15.99V16.01\"></path>\n</svg>\n</span>\n<p class=\"custom-quote-title\">注意</p>\n<p>大家需要注意，进程的上下文开销是很关键的，我们希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上，而不是耗费在上下文切换。</p>\n\n</div>\n<ul>\n<li>为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；</li>\n<li>进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；</li>\n<li>当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；</li>\n<li>当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；</li>\n<li>发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；</li>\n</ul>\n<h2 id=\"线程\"><a href=\"#线程\" class=\"headerlink\" title=\"线程\"></a>线程</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>在早期的操作系统中都是以进程作为独立运行的基本单位，直到后面，计算机科学家们又提出了更小的能独立运行的基本单位，也就是<strong>线程。</strong></p></blockquote>\n<p>需要有一种新的实体，满足以下特性：</p>\n<ul>\n<li>实体之间可以并发运行；</li>\n<li>实体之间共享相同的地址空间；</li>\n</ul>\n<p>这个新的实体，就是**线程( *Thread* )**，线程之间可以并发运行且共享相同的地址空间。</p>\n<p>线程的优点：</p>\n<ul>\n<li>一个进程中可以同时存在多个线程；</li>\n<li>各个线程之间可以并发执行；</li>\n<li>各个线程之间可以共享地址空间和文件等资源；</li>\n</ul>\n<p>线程的缺点：</p>\n<ul>\n<li>当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃</li>\n</ul>\n<h3 id=\"线程与进程的比较\"><a href=\"#线程与进程的比较\" class=\"headerlink\" title=\"线程与进程的比较\"></a>线程与进程的比较</h3><p>线程与进程的比较如下：</p>\n<ul>\n<li>进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；</li>\n<li>进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；</li>\n<li>线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；</li>\n<li>线程能减少并发执行的时间和空间开销；</li>\n</ul>\n<p>对于，线程相比进程能减少开销，体现在：</p>\n<ul>\n<li>线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；</li>\n<li>线程的终止时间比进程快，因为线程释放的资源相比进程少很多；</li>\n<li>同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；</li>\n<li>由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；</li>\n</ul>\n<h3 id=\"线程的上下文切换\"><a href=\"#线程的上下文切换\" class=\"headerlink\" title=\"线程的上下文切换\"></a>线程的上下文切换</h3><p>线程与进程最大的区别在于：<strong>线程是调度的基本单位，而进程则是资源拥有的基本单位</strong>。</p>\n<p>对于线程和进程，我们可以这么理解：</p>\n<ul>\n<li>当进程只有一个线程时，可以认为进程就等于线程；</li>\n<li>当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；</li>\n</ul>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>线程上下文切换的是什么？</p></blockquote>\n<p>这还得看线程是不是属于同一个进程：</p>\n<ul>\n<li>当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；</li>\n<li><strong>当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据</strong>；</li>\n</ul>\n<p>所以，线程的上下文切换相比进程，开销要小很多。</p>\n<h3 id=\"线程的实现\"><a href=\"#线程的实现\" class=\"headerlink\" title=\"线程的实现\"></a>线程的实现</h3><p>主要有三种线程的实现方式：</p>\n<ul>\n<li><strong>用户线程（User Thread）</strong>：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；</li>\n<li><strong>内核线程（Kernel Thread）</strong>：在内核中实现的线程，是由内核管理的线程；</li>\n<li><strong>轻量级进程（LightWeight Process）</strong>：在内核中来支持用户线程；</li>\n</ul>\n<p>用户线程是基于用户态的线程管理库来实现的，那么<strong>线程控制块（*Thread Control Block, TCB*）</strong> 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。</p>\n<p>所以，<strong>用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。</strong></p>\n<h4 id=\"用户线程\"><a href=\"#用户线程\" class=\"headerlink\" title=\"用户线程\"></a>用户线程</h4><p>用户级线程的模型，也就类似前面提到的<strong>多对一</strong>的关系，即多个用户线程对应同一个内核线程。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/20-线程PCB-一对多关系.4balswrwyja0.webp\"/>\n</div>\n\n<p>用户线程的<strong>优点</strong>：</p>\n<ul>\n<li>每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；</li>\n<li>用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；</li>\n</ul>\n<p>用户线程的<strong>缺点</strong>：</p>\n<ul>\n<li><p>由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。</p>\n</li>\n<li><p>当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。</p>\n</li>\n<li><p>由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢；</p>\n</li>\n</ul>\n<h4 id=\"内核线程\"><a href=\"#内核线程\" class=\"headerlink\" title=\"内核线程\"></a>内核线程</h4><p><strong>内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。</strong></p>\n<p>内核线程的模型，也就类似前面提到的<strong>一对一</strong>的关系，即一个用户线程对应一个内核线程</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/21-线程PCB-一对一关系.2e5j85yxf0kk.webp\"/>\n</div>\n\n<p>内核线程的<strong>优点</strong>：</p>\n<ul>\n<li>在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；</li>\n<li>分配给线程，多线程的进程获得更多的 CPU 运行时间；</li>\n</ul>\n<p>内核线程的<strong>缺点</strong>：</p>\n<ul>\n<li>在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；</li>\n<li>线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大；</li>\n</ul>\n<h4 id=\"轻量级进程\"><a href=\"#轻量级进程\" class=\"headerlink\" title=\"轻量级进程\"></a><strong>轻量级进程</strong></h4><p><strong>轻量级进程（*Light-weight process，LWP*）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度</strong>。</p>\n<p>一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。</p>\n<p>在 LWP 之上也是可以使用用户线程的，那么 LWP 与用户线程的对应关系就有三种：</p>\n<ul>\n<li><code>1 : 1</code>，即一个 LWP 对应 一个用户线程；</li>\n<li><code>N : 1</code>，即一个 LWP 对应多个用户线程；</li>\n<li><code>M : N</code>，即多个 LWP 对应多个用户线程；</li>\n</ul>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/22-LWP.5gqwqxa3wjs.webp\"/>\n</div>\n\n<p><strong>1 : 1 模式</strong></p>\n<p>一个线程对应到一个 LWP 再对应到一个内核线程，如上图的进程 4，属于此模型。</p>\n<ul>\n<li>优点：实现并行，当一个 LWP 阻塞，不会影响其他 LWP；</li>\n<li>缺点：每一个用户线程，就产生一个内核线程，创建线程的开销较大。</li>\n</ul>\n<p><strong>N : 1 模式</strong></p>\n<p>多个用户线程对应一个 LWP 再对应一个内核线程，如上图的进程 2，线程管理是在用户空间完成的，此模式中用户的线程对操作系统不可见。</p>\n<ul>\n<li>优点：用户线程要开几个都没问题，且上下文切换发生用户空间，切换的效率较高；</li>\n<li>缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，是没办法充分利用 CPU 的。</li>\n</ul>\n<p><strong>M : N 模式</strong></p>\n<p>根据前面的两个模型混搭一起，就形成 <code>M:N</code> 模型，该模型提供了两级控制，首先多个用户线程对应到多个 LWP，LWP 再一一对应到内核线程，如上图的进程 3。</p>\n<ul>\n<li>优点：综合了前两种优点，大部分的线程上下文发生在用户空间，且多个线程又可以充分利用多核 CPU 的资源。</li>\n</ul>\n<h2 id=\"调度\"><a href=\"#调度\" class=\"headerlink\" title=\"调度\"></a>调度</h2><h3 id=\"调度时机\"><a href=\"#调度时机\" class=\"headerlink\" title=\"调度时机\"></a>调度时机</h3><p>在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。</p>\n<p>比如，以下状态的变化都会触发操作系统的调度：</p>\n<ul>\n<li><em>从就绪态 -&gt; 运行态</em>：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行；</li>\n<li><em>从运行态 -&gt; 阻塞态</em>：当进程发生 I&#x2F;O 事件而阻塞时，操作系统必须选择另外一个进程运行；</li>\n<li><em>从运行态 -&gt; 结束态</em>：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；</li>\n</ul>\n<p>因为，这些状态变化的时候，操作系统需要考虑是否要让新的进程给 CPU 运行，或者是否让当前进程从 CPU 上退出来而换另一个进程运行。</p>\n<p>另外，如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：</p>\n<ul>\n<li><strong>非抢占式调度算法</strong>挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。</li>\n<li><strong>抢占式调度算法</strong>挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生<strong>时钟中断</strong>，以便把 CPU 控制返回给调度程序进行调度，也就是常说的<strong>时间片机制</strong>。</li>\n</ul>\n<h3 id=\"调度原则\"><a href=\"#调度原则\" class=\"headerlink\" title=\"调度原则\"></a>调度原则</h3><p><em>原则一</em>：如果运行的程序，发生了 I&#x2F;O 事件的请求，那 CPU 使用率必然会很低，因为此时进程在阻塞等待硬盘的数据返回。这样的过程，势必会造成 CPU 突然的空闲。所以，<strong>为了提高 CPU 利用率，在这种发送 I&#x2F;O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行。</strong></p>\n<p><em>原则二</em>：有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用着 CPU，会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。所以，<strong>要提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量。</strong></p>\n<p><em>原则三</em>：从进程开始到结束的过程中，实际上是包含两个时间，分别是进程运行时间和进程等待时间，这两个时间总和就称为周转时间。进程的周转时间越小越好，<strong>如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的，调度程序应该避免这种情况发生。</strong></p>\n<p><em>原则四</em>：处于就绪队列的进程，也不能等太久，当然希望这个等待的时间越短越好，这样可以使得进程更快的在 CPU 中执行。所以，<strong>就绪队列中进程的等待时间也是调度程序所需要考虑的原则。</strong></p>\n<p><em>原则五</em>：对于鼠标、键盘这种交互式比较强的应用，我们当然希望它的响应时间越快越好，否则就会影响用户体验了。所以，<strong>对于交互式比较强的应用，响应时间也是调度程序需要考虑的原则。</strong></p>\n<p>针对上面的五种调度原则，总结成如下：</p>\n<ul>\n<li><strong>CPU 利用率</strong>：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；</li>\n<li><strong>系统吞吐量</strong>：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；</li>\n<li><strong>周转时间</strong>：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；</li>\n<li><strong>等待时间</strong>：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；</li>\n<li><strong>响应时间</strong>：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。</li>\n</ul>\n<h3 id=\"调度算法\"><a href=\"#调度算法\" class=\"headerlink\" title=\"调度算法\"></a>调度算法</h3><p>不同的调度算法适用的场景也是不同的。</p>\n<p>接下来，说说在<strong>单核 CPU 系统</strong>中常见的调度算法。</p>\n<h4 id=\"先来先服务调度算法\"><a href=\"#先来先服务调度算法\" class=\"headerlink\" title=\"先来先服务调度算法\"></a>先来先服务调度算法</h4><p>最简单的一个调度算法，就是非抢占式的<strong>先来先服务（First Come First Serve, FCFS）算法</strong>了。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/24-先来先服务.3hacuqkwdnk0.webp\"/>\n</div>\n\n<p>顾名思义，先来后到，<strong>每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。</strong></p>\n<p>这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。</p>\n<p>FCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I&#x2F;O 繁忙型作业的系统。</p>\n<h4 id=\"最短作业优先调度算法\"><a href=\"#最短作业优先调度算法\" class=\"headerlink\" title=\"最短作业优先调度算法\"></a>最短作业优先调度算法</h4><p><strong>最短作业优先（Shortest Job First, SJF）调度算法</strong>同样也是顾名思义，它会<strong>优先选择运行时间最短的进程来运行</strong>，这有助于提高系统的吞吐量。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/25-最短作业优先算法.4d3seatcvd40.webp\"/>\n</div>\n\n<p>这显然对长作业不利，很容易造成一种极端现象。</p>\n<p>比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。</p>\n<h4 id=\"高响应比优先调度算法\"><a href=\"#高响应比优先调度算法\" class=\"headerlink\" title=\"高响应比优先调度算法\"></a>高响应比优先调度算法</h4><p>前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。</p>\n<p>那么，<strong>高响应比优先 （Highest Response Ratio Next, HRRN）调度算法</strong>主要是权衡了短作业和长作业。</p>\n<p><strong>每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行</strong>，「响应比优先级」的计算公式：</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/26-响应比公式.4l1j4mrqr6g0.webp\"/>\n</div>\n\n<p>从上面的公式，可以发现：</p>\n<ul>\n<li>如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；</li>\n<li>如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；</li>\n</ul>\n<h4 id=\"时间片轮转调度算法\"><a href=\"#时间片轮转调度算法\" class=\"headerlink\" title=\"时间片轮转调度算法\"></a>时间片轮转调度算法</h4><p>最古老、最简单、最公平且使用最广的算法就是<strong>时间片轮转（Round Robin, RR）调度算法</strong>。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/27-时间片轮询.1rwx8jnuqcdc.webp\"/>\n</div>\n\n<p><strong>每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。</strong></p>\n<ul>\n<li>如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；</li>\n<li>如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；</li>\n</ul>\n<p>另外，时间片的长度就是一个很关键的点：</p>\n<ul>\n<li>如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；</li>\n<li>如果设得太长又可能引起对短作业进程的响应时间变长。</li>\n</ul>\n<p>一般来说，时间片设为 <code>20ms~50ms</code> 通常是一个比较合理的折中值。</p>\n<h4 id=\"最高优先级调度算法\"><a href=\"#最高优先级调度算法\" class=\"headerlink\" title=\"最高优先级调度算法\"></a>最高优先级调度算法</h4><p>前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。</p>\n<p>但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能<strong>从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法</strong>。</p>\n<p>进程的优先级可以分为，静态优先级和动态优先级：</p>\n<ul>\n<li>静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；</li>\n<li>动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是<strong>随着时间的推移增加等待进程的优先级</strong>。</li>\n</ul>\n<p>该算法也有两种处理优先级高的方法，非抢占式和抢占式：</p>\n<ul>\n<li>非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。</li>\n<li>抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。</li>\n</ul>\n<p>但是依然有缺点，可能会导致低优先级的进程永远不会运行。</p>\n<h4 id=\"多级反馈队列调度算法\"><a href=\"#多级反馈队列调度算法\" class=\"headerlink\" title=\"多级反馈队列调度算法\"></a>多级反馈队列调度算法</h4><p><strong>多级反馈队列（*Multilevel Feedback Queue*）调度算法</strong>是「时间片轮转算法」和「最高优先级算法」的综合和发展。</p>\n<p>顾名思义：</p>\n<ul>\n<li>「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。</li>\n<li>「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；</li>\n</ul>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/28-多级队列.49qhbky677o0.webp\"/>\n</div>\n\n<p>来看看，它是如何工作的：</p>\n<ul>\n<li>设置了多个队列，赋予每个队列不同的优先级，每个<strong>队列优先级从高到低</strong>，同时<strong>优先级越高时间片越短</strong>；</li>\n<li>新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；</li>\n<li>当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；</li>\n</ul>\n<p>可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的<strong>兼顾了长短作业，同时有较好的响应时间。</strong></p>\n<h2 id=\"进程间通信\"><a href=\"#进程间通信\" class=\"headerlink\" title=\"进程间通信\"></a>进程间通信</h2><p>每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。</p>\n<h3 id=\"管道\"><a href=\"#管道\" class=\"headerlink\" title=\"管道\"></a>管道</h3><div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/微信截图_20221025161613.2fpgm9z3mxj4.webp\"/>\n</div>\n\n<p>同时，我们得知上面这种管道是没有名字，所以「<code>|</code>」表示的管道称为<strong>匿名管道</strong>，用完了就销毁。</p>\n<p>管道还有另外一个类型是<strong>命名管道</strong>，也被叫做 <code>FIFO</code>，因为数据是先进先出的传输方式。</p>\n<p>在使用命名管道前，先需要通过 <code>mkfifo</code> 命令来创建，并且指定管道名字：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">mkfifo</span> myPipe<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p>myPipe 就是这个管道的名称，基于 Linux 一切皆文件的理念，所以管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">ls</span> <span class=\"token parameter variable\">-l</span>\nprw-r--r--. <span class=\"token number\">1</span> root    root         <span class=\"token number\">0</span> Jul <span class=\"token number\">17</span> 02:45 myPipe<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<p>接下来，我们往 myPipe 这个管道写入数据：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token builtin class-name\">echo</span> <span class=\"token string\">\"hello\"</span> <span class=\"token operator\">></span> myPipe  // 将数据写进管道\n                         // 停住了 <span class=\"token punctuation\">..</span>.<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<p>你操作了后，你会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。</p>\n<p>于是，我们执行另外一个命令来读取这个管道里的数据：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">cat</span> <span class=\"token operator\">&lt;</span> myPipe  // 读取管道里的数据\nhello<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<p>可以看到，管道里的内容被读取出来了，并打印在了终端上，另外一方面，echo 那个命令也正常退出了。</p>\n<p>我们可以看出，<strong>管道这种通信方式效率低，不适合进程间频繁地交换数据</strong>。当然，它的好处，自然就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了。</p>\n<h3 id=\"消息队列\"><a href=\"#消息队列\" class=\"headerlink\" title=\"消息队列\"></a>消息队列</h3><p>前面说到管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。</p>\n<p>对于这个问题，<strong>消息队列</strong>的通信模式就可以解决。比如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。</p>\n<p>再来，<strong>消息队列是保存在内核中的消息链表</strong>，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。</p>\n<p>消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。</p>\n<p>消息这种模型，两个进程之间的通信就像平时发邮件一样，你来一封，我回一封，可以频繁沟通了。</p>\n<p>但邮件的通信方式存在不足的地方有两点，<strong>一是通信不及时，二是附件也有大小限制</strong>，这同样也是消息队列通信不足的点。</p>\n<p><strong>消息队列不适合比较大数据的传输</strong>，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 <code>MSGMAX</code> 和 <code>MSGMNB</code>，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。</p>\n<p><strong>消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销</strong>，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。</p>\n<h3 id=\"共享内存\"><a href=\"#共享内存\" class=\"headerlink\" title=\"共享内存\"></a>共享内存</h3><p>消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那<strong>共享内存</strong>的方式，就很好的解决了这一问题。</p>\n<p>现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。</p>\n<p><strong>共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中</strong>。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。</p>\n<h3 id=\"信号量\"><a href=\"#信号量\" class=\"headerlink\" title=\"信号量\"></a>信号量</h3><p>用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。</p>\n<p>为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，<strong>信号量</strong>就实现了这一保护机制。</p>\n<p><strong>信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据</strong>。</p>\n<p>信号量表示资源的数量，控制信号量的方式有两种原子操作：</p>\n<ul>\n<li>一个是 <strong>P 操作</strong>，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;&#x3D; 0，则表明还有资源可使用，进程可正常继续执行。</li>\n<li>另一个是 <strong>V 操作</strong>，这个操作会把信号量加上 1，相加后如果信号量 &lt;&#x3D; 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程；</li>\n</ul>\n<p>P 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。</p>\n<p>接下来，举个例子，如果要使得两个进程互斥访问共享内存，我们可以初始化信号量为 <code>1</code>。</p>\n<p>具体的过程如下：</p>\n<ul>\n<li>进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。</li>\n<li>若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。</li>\n<li>直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。</li>\n</ul>\n<p>可以发现，信号初始化为 <code>1</code>，就代表着是<strong>互斥信号量</strong>，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。</p>\n<p>另外，在多进程里，每个进程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个进程能密切合作，以实现一个共同的任务。</p>\n<p>例如，进程 A 是负责生产数据，而进程 B 是负责读取数据，这两个进程是相互合作、相互依赖的，进程 A 必须先生产了数据，进程 B 才能读取到数据，所以执行是有前后顺序的。</p>\n<p>那么这时候，就可以用信号量来实现多进程同步的方式，我们可以初始化信号量为 <code>0</code>。</p>\n<p>具体过程：</p>\n<ul>\n<li>如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待；</li>\n<li>接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；</li>\n<li>最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。</li>\n</ul>\n<p>可以发现，信号初始化为 <code>0</code>，就代表着是<strong>同步信号量</strong>，它可以保证进程 A 应在进程 B 之前执行。</p>\n<h3 id=\"信号\"><a href=\"#信号\" class=\"headerlink\" title=\"信号\"></a>信号</h3><p><strong>对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。</strong></p>\n<p>在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 <code>kill -l</code> 命令，查看所有的信号：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ <span class=\"token function\">kill</span> <span class=\"token parameter variable\">-l</span>\n <span class=\"token number\">1</span><span class=\"token punctuation\">)</span> SIGHUP       <span class=\"token number\">2</span><span class=\"token punctuation\">)</span> SIGINT       <span class=\"token number\">3</span><span class=\"token punctuation\">)</span> SIGQUIT      <span class=\"token number\">4</span><span class=\"token punctuation\">)</span> SIGILL       <span class=\"token number\">5</span><span class=\"token punctuation\">)</span> SIGTRAP\n <span class=\"token number\">6</span><span class=\"token punctuation\">)</span> SIGABRT      <span class=\"token number\">7</span><span class=\"token punctuation\">)</span> SIGBUS       <span class=\"token number\">8</span><span class=\"token punctuation\">)</span> SIGFPE       <span class=\"token number\">9</span><span class=\"token punctuation\">)</span> SIGKILL     <span class=\"token number\">10</span><span class=\"token punctuation\">)</span> SIGUSR1\n<span class=\"token number\">11</span><span class=\"token punctuation\">)</span> SIGSEGV     <span class=\"token number\">12</span><span class=\"token punctuation\">)</span> SIGUSR2     <span class=\"token number\">13</span><span class=\"token punctuation\">)</span> SIGPIPE     <span class=\"token number\">14</span><span class=\"token punctuation\">)</span> SIGALRM     <span class=\"token number\">15</span><span class=\"token punctuation\">)</span> SIGTERM\n<span class=\"token number\">16</span><span class=\"token punctuation\">)</span> SIGSTKFLT   <span class=\"token number\">17</span><span class=\"token punctuation\">)</span> SIGCHLD     <span class=\"token number\">18</span><span class=\"token punctuation\">)</span> SIGCONT     <span class=\"token number\">19</span><span class=\"token punctuation\">)</span> SIGSTOP     <span class=\"token number\">20</span><span class=\"token punctuation\">)</span> SIGTSTP\n<span class=\"token number\">21</span><span class=\"token punctuation\">)</span> SIGTTIN     <span class=\"token number\">22</span><span class=\"token punctuation\">)</span> SIGTTOU     <span class=\"token number\">23</span><span class=\"token punctuation\">)</span> SIGURG      <span class=\"token number\">24</span><span class=\"token punctuation\">)</span> SIGXCPU     <span class=\"token number\">25</span><span class=\"token punctuation\">)</span> SIGXFSZ\n<span class=\"token number\">26</span><span class=\"token punctuation\">)</span> SIGVTALRM   <span class=\"token number\">27</span><span class=\"token punctuation\">)</span> SIGPROF     <span class=\"token number\">28</span><span class=\"token punctuation\">)</span> SIGWINCH    <span class=\"token number\">29</span><span class=\"token punctuation\">)</span> SIGIO       <span class=\"token number\">30</span><span class=\"token punctuation\">)</span> SIGPWR\n<span class=\"token number\">31</span><span class=\"token punctuation\">)</span> SIGSYS      <span class=\"token number\">34</span><span class=\"token punctuation\">)</span> SIGRTMIN    <span class=\"token number\">35</span><span class=\"token punctuation\">)</span> SIGRTMIN+1  <span class=\"token number\">36</span><span class=\"token punctuation\">)</span> SIGRTMIN+2  <span class=\"token number\">37</span><span class=\"token punctuation\">)</span> SIGRTMIN+3\n<span class=\"token number\">38</span><span class=\"token punctuation\">)</span> SIGRTMIN+4  <span class=\"token number\">39</span><span class=\"token punctuation\">)</span> SIGRTMIN+5  <span class=\"token number\">40</span><span class=\"token punctuation\">)</span> SIGRTMIN+6  <span class=\"token number\">41</span><span class=\"token punctuation\">)</span> SIGRTMIN+7  <span class=\"token number\">42</span><span class=\"token punctuation\">)</span> SIGRTMIN+8\n<span class=\"token number\">43</span><span class=\"token punctuation\">)</span> SIGRTMIN+9  <span class=\"token number\">44</span><span class=\"token punctuation\">)</span> SIGRTMIN+10 <span class=\"token number\">45</span><span class=\"token punctuation\">)</span> SIGRTMIN+11 <span class=\"token number\">46</span><span class=\"token punctuation\">)</span> SIGRTMIN+12 <span class=\"token number\">47</span><span class=\"token punctuation\">)</span> SIGRTMIN+13\n<span class=\"token number\">48</span><span class=\"token punctuation\">)</span> SIGRTMIN+14 <span class=\"token number\">49</span><span class=\"token punctuation\">)</span> SIGRTMIN+15 <span class=\"token number\">50</span><span class=\"token punctuation\">)</span> SIGRTMAX-14 <span class=\"token number\">51</span><span class=\"token punctuation\">)</span> SIGRTMAX-13 <span class=\"token number\">52</span><span class=\"token punctuation\">)</span> SIGRTMAX-12\n<span class=\"token number\">53</span><span class=\"token punctuation\">)</span> SIGRTMAX-11 <span class=\"token number\">54</span><span class=\"token punctuation\">)</span> SIGRTMAX-10 <span class=\"token number\">55</span><span class=\"token punctuation\">)</span> SIGRTMAX-9  <span class=\"token number\">56</span><span class=\"token punctuation\">)</span> SIGRTMAX-8  <span class=\"token number\">57</span><span class=\"token punctuation\">)</span> SIGRTMAX-7\n<span class=\"token number\">58</span><span class=\"token punctuation\">)</span> SIGRTMAX-6  <span class=\"token number\">59</span><span class=\"token punctuation\">)</span> SIGRTMAX-5  <span class=\"token number\">60</span><span class=\"token punctuation\">)</span> SIGRTMAX-4  <span class=\"token number\">61</span><span class=\"token punctuation\">)</span> SIGRTMAX-3  <span class=\"token number\">62</span><span class=\"token punctuation\">)</span> SIGRTMAX-2\n<span class=\"token number\">63</span><span class=\"token punctuation\">)</span> SIGRTMAX-1  <span class=\"token number\">64</span><span class=\"token punctuation\">)</span> SIGRTMAX<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如</p>\n<ul>\n<li>Ctrl+C 产生 <code>SIGINT</code> 信号，表示终止该进程；</li>\n<li>Ctrl+Z 产生 <code>SIGTSTP</code> 信号，表示停止该进程，但还未结束；</li>\n</ul>\n<p>如果进程在后台运行，可以通过 <code>kill</code> 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如：</p>\n<ul>\n<li>kill -9 1050 ，表示给 PID 为 1050 的进程发送 <code>SIGKILL</code> 信号，用来立即结束该进程；</li>\n</ul>\n<p>所以，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。</p>\n<p>信号是进程间通信机制中<strong>唯一的异步通信机制</strong>，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。</p>\n<p><strong>1.执行默认操作</strong>。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。</p>\n<p><strong>2.捕捉信号</strong>。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。</p>\n<p><strong>3.忽略信号</strong>。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 <code>SIGKILL</code> 和 <code>SEGSTOP</code>，它们用于在任何时候中断或结束某一进程。</p>\n<h3 id=\"Socket\"><a href=\"#Socket\" class=\"headerlink\" title=\"Socket\"></a>Socket</h3><p>前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想<strong>跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。</strong></p>\n<p>实际上，Socket 通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。</p>\n<p>创建 socket 的系统调用：</p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\"><span class=\"token keyword\">int</span> <span class=\"token function\">socket</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> domain<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> type<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> protocal<span class=\"token punctuation\">)</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p>三个参数分别代表：</p>\n<ul>\n<li>domain 参数用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL&#x2F;AF_UNIX 用于本机；</li>\n<li>type 参数用来指定通信特性，比如 SOCK_STREAM 表示的是字节流，对应 TCP、SOCK_DGRAM 表示的是数据报，对应 UDP、SOCK_RAW 表示的是原始套接字；</li>\n<li>protocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可；</li>\n</ul>\n<p>根据创建 socket 类型的不同，通信的方式也就不同：</p>\n<ul>\n<li>实现 TCP 字节流通信： socket 类型是 AF_INET 和 SOCK_STREAM；</li>\n<li>实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM；</li>\n<li>实现本地进程间通信： 「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM。另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket；</li>\n</ul>\n<h4 id=\"针对-TCP-协议通信的-socket-编程模型\"><a href=\"#针对-TCP-协议通信的-socket-编程模型\" class=\"headerlink\" title=\"针对 TCP 协议通信的 socket 编程模型\"></a>针对 TCP 协议通信的 socket 编程模型</h4><div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/12-TCP编程模型.41c72vnvkfe0.webp\"/>\n</div>\n\n<ul>\n<li>服务端和客户端初始化 <code>socket</code>，得到文件描述符；</li>\n<li>服务端调用 <code>bind</code>，将绑定在 IP 地址和端口;</li>\n<li>服务端调用 <code>listen</code>，进行监听；</li>\n<li>服务端调用 <code>accept</code>，等待客户端连接；</li>\n<li>客户端调用 <code>connect</code>，向服务器端的地址和端口发起连接请求；</li>\n<li>服务端 <code>accept</code> 返回用于传输的 <code>socket</code> 的文件描述符；</li>\n<li>客户端调用 <code>write</code> 写入数据；服务端调用 <code>read</code> 读取数据；</li>\n<li>客户端断开连接时，会调用 <code>close</code>，那么服务端 <code>read</code> 读取数据的时候，就会读取到了 <code>EOF</code>，待处理完数据后，服务端调用 <code>close</code>，表示连接关闭。</li>\n</ul>\n<p>这里需要注意的是，服务端调用 <code>accept</code> 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。</p>\n<p>所以，监听的 socket 和真正用来传送数据的 socket，是「<strong>两个</strong>」 socket，一个叫作<strong>监听 socket</strong>，一个叫作<strong>已完成连接 socket</strong>。</p>\n<p>成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。</p>\n<h4 id=\"针对-UDP-协议通信的-socket-编程模型\"><a href=\"#针对-UDP-协议通信的-socket-编程模型\" class=\"headerlink\" title=\"针对 UDP 协议通信的 socket 编程模型\"></a>针对 UDP 协议通信的 socket 编程模型</h4><div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/13-UDP编程模型.4g1u1kiz0jc0.webp\"/>\n</div>\n\n<p>UDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。</p>\n<p>对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。</p>\n<p>另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。</p>\n<h4 id=\"针对本地进程间通信的-socket-编程模型\"><a href=\"#针对本地进程间通信的-socket-编程模型\" class=\"headerlink\" title=\"针对本地进程间通信的 socket 编程模型\"></a>针对本地进程间通信的 socket 编程模型</h4><p>本地 socket 被用于在<strong>同一台主机上进程间通信</strong>的场景：</p>\n<ul>\n<li>本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议；</li>\n<li>本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现；</li>\n</ul>\n<p>对于本地字节流 socket，其 socket 类型是 AF_LOCAL 和 SOCK_STREAM。</p>\n<p>对于本地数据报 socket，其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。</p>\n<p>本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是<strong>绑定一个本地文件</strong>，这也就是它们之间的最大区别。</p>\n<h2 id=\"多线程冲突\"><a href=\"#多线程冲突\" class=\"headerlink\" title=\"多线程冲突\"></a>多线程冲突</h2><h3 id=\"竞争与协作\"><a href=\"#竞争与协作\" class=\"headerlink\" title=\"竞争与协作\"></a>竞争与协作</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>在单核 CPU 系统里，为了实现多个程序同时运行的假象，操作系统通常以时间片调度的方式，让每个进程执行每次执行一个时间片，时间片用完了，就切换下一个进程运行，由于这个时间片的时间很短，于是就造成了「并发」的现象。</p>\n<p>另外，操作系统也为每个进程创建巨大、私有的虚拟内存的假象，这种地址空间的抽象让每个程序好像拥有自己的内存，而实际上操作系统在背后秘密地让多个地址空间「复用」物理内存或者磁盘。</p></blockquote>\n<p><strong>如果一个程序只有一个执行流程，也代表它是单线程的。当然一个程序可以有多个执行流程，也就是所谓的多线程程序，线程是调度的基本单位，进程则是资源分配的基本单位。</strong></p>\n<p>多个线程如果竞争共享资源，如果不采取有效的措施，则会造成共享数据的混乱。</p>\n<p>我们做个小实验，创建两个线程，它们分别对共享变量 <code>i</code> 自增 <code>1</code> 执行 <code>10000</code> 次，如下代码：</p>\n<pre class=\"line-numbers language-c++\" data-language=\"c++\"><code class=\"language-c++\">#include &quot;iostream&quot;\n#include &lt;thread&gt;\n\nint i &#x3D;0;\nint count &#x3D;0;\n\nvoid test()&#123;\n    int num &#x3D;10000;\n\n    for(int n&#x3D;0;n&lt;num;n++)&#123;\n        i &#x3D; i+1;\n    &#125;\n&#125;\nint main()&#123;\n    for(int j &#x3D;0;j&lt;100000;j++)&#123;\n        i&#x3D;0;\n        &#x2F;&#x2F;std::cout&lt;&lt;&quot;start&quot;&lt;&lt;std::endl;\n\n        std::thread thread_test1(test);\n        std::thread thread_test2(test);\n\n        thread_test1.join();\n        thread_test2.join();\n        if(i!&#x3D;20000) &#123;\n            &#x2F;&#x2F;std::cout&lt;&lt;i&lt;&lt;std::endl;\n            count++;\n        &#125;\n        &#x2F;&#x2F;std::cout&lt;&lt;&quot;all joined&quot;&lt;&lt;std::endl;\n        &#x2F;&#x2F;::cout&lt;&lt;&quot;now i is&quot;&lt;&lt;i&lt;&lt;std::endl;\n    &#125;\n    std::cout&lt;&lt;&quot;count:&quot;&lt;&lt;count&lt;&lt;std::endl;\n    return 0;\n&#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<pre class=\"line-numbers language-c++\" data-language=\"c++\"><code class=\"language-c++\">count:2513&#x2F;&#x2F;结果为2513次count并不等于20000<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p>在这个例子中，我们只是想给 <code>i</code> 加上数字 1，那么它对应的汇编指令执行过程是这样的：</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/8-汇编语句赋值过程.12ejs583lsqo.webp\"/>\n</div>\n\n<p>可以发现，只是单纯给 <code>i</code> 加上数字 1，在 CPU 运行的时候，实际上要执行 <code>3</code> 条指令。</p>\n<p>设想我们的线程 1 进入这个代码区域，它将 i 的值（假设此时是 50 ）从内存加载到它的寄存器中，然后它向寄存器加 1，此时在寄存器中的 i 值是 51。</p>\n<p>现在，一件不幸的事情发生了：<strong>时钟中断发生</strong>。因此，操作系统将当前正在运行的线程的状态保存到线程的线程控制块 TCB。</p>\n<p>现在更糟的事情发生了，线程 2 被调度运行，并进入同一段代码。它也执行了第一条指令，从内存获取 i 值并将其放入到寄存器中，此时内存中 i 的值仍为 50，因此线程 2 寄存器中的 i 值也是 50。假设线程 2 执行接下来的两条指令，将寄存器中的 i 值 + 1，然后将寄存器中的 i 值保存到内存中，于是此时全局变量 i 值是 51。</p>\n<p>最后，又发生一次上下文切换，线程 1 恢复执行。还记得它已经执行了两条汇编指令，现在准备执行最后一条指令。回忆一下， 线程 1 寄存器中的 i 值是51，因此，执行最后一条指令后，将值保存到内存，全局变量 i 的值再次被设置为 51。</p>\n<p>简单来说，增加 i （值为 50 ）的代码被运行两次，按理来说，最后的 i 值应该是 52，但是由于<strong>不可控的调度</strong>，导致最后 i 值却是 51。</p>\n<h4 id=\"互斥\"><a href=\"#互斥\" class=\"headerlink\" title=\"互斥\"></a>互斥</h4><p>上面展示的情况称为<strong>竞争条件（*race condition*）</strong>，当多线程相互竞争操作共享变量时，由于运气不好，即在执行过程中发生了上下文切换，我们得到了错误的结果，事实上，每次运行都可能得到不同的结果，因此输出的结果存在<strong>不确定性（*indeterminate*）</strong>。</p>\n<p>由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为<strong>临界区（*critical section*），它是访问共享资源的代码片段，一定不能给多线程同时执行。</strong></p>\n<p>我们希望这段代码是<strong>互斥（*mutualexclusion*）的，也就说保证一个线程在临界区执行时，其他线程应该被阻止进入临界区</strong>，说白了，就是这段代码执行过程中，最多只能出现一个线程。</p>\n<h4 id=\"同步的概念\"><a href=\"#同步的概念\" class=\"headerlink\" title=\"同步的概念\"></a>同步的概念</h4><p>互斥解决了并发进程&#x2F;线程对临界区的使用问题。这种基于临界区控制的交互作用是比较简单的，只要一个进程&#x2F;线程进入了临界区，其他试图想进入临界区的进程&#x2F;线程都会被阻塞着，直到第一个进程&#x2F;线程离开了临界区。</p>\n<p>我们都知道在多线程里，每个线程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个线程能密切合作，以实现一个共同的任务。</p>\n<p>例子，线程 1 是负责读入数据的，而线程 2 是负责处理数据的，这两个线程是相互合作、相互依赖的。线程 2 在没有收到线程 1 的唤醒通知时，就会一直阻塞等待，当线程 1 读完数据需要把数据传给线程 2 时，线程 1 会唤醒线程 2，并把数据交给线程 2 处理。</p>\n<p><strong>所谓同步，就是并发进程&#x2F;线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程&#x2F;线程同步</strong>。</p>\n<p>注意，同步与互斥是两种不同的概念：</p>\n<ul>\n<li>同步就好比：「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等；</li>\n<li>互斥就好比：「操作 A 和操作 B 不能在同一时刻执行」；</li>\n</ul>\n<h4 id=\"互斥与同步的实现\"><a href=\"#互斥与同步的实现\" class=\"headerlink\" title=\"互斥与同步的实现\"></a>互斥与同步的实现</h4><p>在进程&#x2F;线程并发执行的过程中，进程&#x2F;线程之间存在协作的关系，例如有互斥、同步的关系。</p>\n<p>为了实现进程&#x2F;线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：</p>\n<ul>\n<li><em>锁</em>：加锁、解锁操作；</li>\n<li><em>信号量</em>：P、V 操作；</li>\n</ul>\n<p>这两个都可以方便地实现进程&#x2F;线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程&#x2F;线程同步。</p>\n<h3 id=\"锁\"><a href=\"#锁\" class=\"headerlink\" title=\"锁\"></a>锁</h3><p>使用加锁操作和解锁操作可以解决并发线程&#x2F;进程的互斥问题。</p>\n<p>任何想进入临界区的线程，必须先执行加锁操作。若加锁操作顺利通过，则线程可进入临界区；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。</p>\n<p>根据锁的实现不同，可以分为「忙等待锁」和「无忙等待锁」。</p>\n<h4 id=\"忙等待锁\"><a href=\"#忙等待锁\" class=\"headerlink\" title=\"忙等待锁\"></a>忙等待锁</h4><p>在说明「忙等待锁」的实现之前，先介绍现代 CPU 体系结构提供的特殊<strong>原子操作指令 —— 测试和置位（*Test-and-Set*）指令</strong>。</p>\n<p>测试并设置指令做了下述事情:</p>\n<ul>\n<li>把 <code>old_ptr</code> 更新为 <code>new</code> 的新值</li>\n<li>返回 <code>old_ptr</code> 的旧值；</li>\n</ul>\n<p>当然，<strong>关键是这些代码是原子执行</strong>。因为既可以测试旧值，又可以设置新值，所以我们把这条指令叫作「测试并设置」。</p>\n<p>那什么是原子操作呢？<strong>原子操作就是要么全部执行，要么都不执行，不能出现执行到一半的中间状态</strong></p>\n<pre class=\"line-numbers language-c++\" data-language=\"c++\"><code class=\"language-c++\">#include &quot;iostream&quot;\n#include &lt;thread&gt;\n#include &quot;atomic&quot;\n\nint i &#x3D;0;\nint count &#x3D;0;\nint TestAndSet(int *old_ptr,int ne) &#123;\n    int old &#x3D; *old_ptr;\n    *old_ptr &#x3D; ne;\n    return old;\n&#125;&#x2F;&#x2F;testandset的原型，但是不能直接这么使用，单纯的函数定义无法保证原子性必须调用库函数实现。\n\nclass lock_t&#123;\npublic:\n    lock_t()&#123;&#125;\n    void lock()&#123;\n        while(std::atomic_flag_test_and_set(&amp;flag) &#x3D;&#x3D; 1);\n    &#125;\n    void unlock()&#123;\n        std::atomic_flag_clear(&amp;flag);\n    &#125;\n    std::atomic_flag flag;\n&#125;;\nvoid test(lock_t* lock)&#123;\n    int num &#x3D;10000;\n    for(int n&#x3D;0;n&lt;num;n++)&#123;\n        lock-&gt;lock();\n        i &#x3D; i+1;\n        lock-&gt;unlock();\n    &#125;\n&#125;\nint main()&#123;\n    lock_t lock;\n    for(int j &#x3D;0;j&lt;1000;j++)&#123;\n        i&#x3D;0;\n        &#x2F;&#x2F;std::cout&lt;&lt;&quot;start&quot;&lt;&lt;std::endl;\n\n        std::thread thread_test1(test,&amp;lock);\n        std::thread thread_test2(test,&amp;lock);\n\n        thread_test1.join();\n        thread_test2.join();\n        if(i!&#x3D;20000) &#123;\n            &#x2F;&#x2F;std::cout&lt;&lt;i&lt;&lt;std::endl;\n            count++;\n        &#125;\n        &#x2F;&#x2F;std::cout&lt;&lt;&quot;all joined&quot;&lt;&lt;std::endl;\n        &#x2F;&#x2F;::cout&lt;&lt;&quot;now i is&quot;&lt;&lt;i&lt;&lt;std::endl;\n    &#125;\n    std::cout&lt;&lt;&quot;count:&quot;&lt;&lt;count&lt;&lt;std::endl;\n    return 0;\n&#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>我们来确保理解为什么这个锁能工作：</p>\n<ul>\n<li>第一个场景是，首先假设一个线程在运行，调用 <code>lock()</code>，没有其他线程持有锁，所以 <code>flag</code> 是 0。当调用 <code>TestAndSet(flag, 1)</code> 方法，返回 0，线程会跳出 while 循环，获取锁。同时也会原子的设置 flag 为1，标志锁已经被持有。当线程离开临界区，调用 <code>unlock()</code> 将 <code>flag</code> 清理为 0。</li>\n<li>第二种场景是，当某一个线程已经持有锁（即 <code>flag</code> 为1）。本线程调用 <code>lock()</code>，然后调用 <code>TestAndSet(flag, 1)</code>，这一次返回 1。只要另一个线程一直持有锁，<code>TestAndSet()</code> 会重复返回 1，本线程会一直<strong>忙等</strong>。当 <code>flag</code> 终于被改为 0，本线程会调用 <code>TestAndSet()</code>，返回 0 并且原子地设置为 1，从而获得锁，进入临界区。</li>\n</ul>\n<p>很明显，当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为<strong>自旋锁（*spin lock*）</strong>。</p>\n<p>这是最简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。在单处理器上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。</p>\n<h4 id=\"无等待锁\"><a href=\"#无等待锁\" class=\"headerlink\" title=\"无等待锁\"></a>无等待锁</h4><p>无等待锁顾明思议就是获取不到锁的时候，不用自旋。</p>\n<p>既然不想自旋，那当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/15-无等待锁.vtg4ty1b41c.webp\"/>\n</div>\n\n<h3 id=\"信号量-1\"><a href=\"#信号量-1\" class=\"headerlink\" title=\"信号量\"></a>信号量</h3><p>信号量是操作系统提供的一种协调共享资源访问的方法。</p>\n<p>通常<strong>信号量表示资源的数量</strong>，对应的变量是一个整型（<code>sem</code>）变量。</p>\n<p>另外，还有<strong>两个原子操作的系统调用函数来控制信号量的</strong>，分别是：</p>\n<ul>\n<li><em>P 操作</em>：将 <code>sem</code> 减 <code>1</code>，相减后，如果 <code>sem &lt; 0</code>，则进程&#x2F;线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；</li>\n<li><em>V 操作</em>：将 <code>sem</code> 加 <code>1</code>，相加后，如果 <code>sem &lt;= 0</code>，唤醒一个等待中的进程&#x2F;线程，表明 V 操作不会阻塞；</li>\n</ul>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/17-操作系统PV算法描述.3l56vx7gxvw0.webp\"/>\n</div>\n\n<p>信号量不仅可以实现临界区的互斥访问控制，还可以线程间的事件同步。</p>\n<p>我们先来说说如何使用<strong>信号量实现临界区的互斥访问</strong>。</p>\n<p>为每类共享资源设置一个信号量 <code>s</code>，其初值为 <code>1</code>，表示该临界资源未被占用。</p>\n<p>只要把进入临界区的操作置于 <code>P(s)</code> 和 <code>V(s)</code> 之间，即可实现进程&#x2F;线程互斥：</p>\n<p>此时，任何想进入临界区的线程，必先在互斥信号量上执行 P 操作，在完成对临界资源的访问后再执行 V 操作。由于互斥信号量的初始值为 1，故在第一个线程执行 P 操作后 s 值变为 0，表示临界资源为空闲，可分配给该线程，使之进入临界区。</p>\n<p>若此时又有第二个线程想进入临界区，也应先执行 P 操作，结果使 s 变为负值，这就意味着临界资源已被占用，因此，第二个线程被阻塞。</p>\n<p>并且，直到第一个线程执行 V 操作，释放临界资源而恢复 s 值为 0 后，才唤醒第二个线程，使之进入临界区，待它完成临界资源的访问后，又执行 V 操作，使 s 恢复到初始值 1。</p>\n<p>对于两个并发线程，互斥信号量的值仅取 1、0 和 -1 三个值，分别表示：</p>\n<ul>\n<li>如果互斥信号量为 1，表示没有线程进入临界区；</li>\n<li>如果互斥信号量为 0，表示有一个线程进入临界区；</li>\n<li>如果互斥信号量为 -1，表示一个线程进入临界区，另一个线程等待进入。</li>\n</ul>\n<p>通过互斥信号量的方式，就能保证临界区任何时刻只有一个线程在执行，就达到了互斥的效果。</p>\n<p>生产者-消费者问题描述：</p>\n<ul>\n<li><strong>生产者</strong>在生成数据后，放在一个缓冲区中；</li>\n<li><strong>消费者</strong>从缓冲区取出数据处理；</li>\n<li>任何时刻，<strong>只能有一个</strong>生产者或消费者可以访问缓冲区；</li>\n</ul>\n<p>我们对问题分析可以得出：</p>\n<ul>\n<li>任何时刻只能有一个线程操作缓冲区，说明操作缓冲区是临界代码，<strong>需要互斥</strong>；</li>\n<li>缓冲区空时，消费者必须等待生产者生成数据；缓冲区满时，生产者必须等待消费者取出数据。说明生产者和消费者<strong>需要同步</strong>。</li>\n</ul>\n<p>那么我们需要三个信号量，分别是：</p>\n<ul>\n<li>互斥信号量 <code>mutex</code>：用于互斥访问缓冲区，初始化值为 1；</li>\n<li>资源信号量 <code>fullBuffers</code>：用于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0（表明缓冲区一开始为空）；</li>\n<li>资源信号量 <code>emptyBuffers</code>：用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为 n （缓冲区大小）；</li>\n</ul>\n<pre class=\"line-numbers language-c++\" data-language=\"c++\"><code class=\"language-c++\">#include &quot;iostream&quot;\n#include &quot;thread&quot;\n#include &lt;mutex&gt;\n#include &quot;condition_variable&quot;\nclass MySemaphore\n&#123;\nprivate:\n    int count;\n    std::mutex mx;\n    std::condition_variable cv;\npublic:\n    MySemaphore(int val &#x3D; 1) :count(val) &#123;&#125;&#x2F;&#x2F;默认实参\n    void P()\n    &#123;\n        std::unique_lock&lt;std::mutex&gt; lock(mx);\n        if (--count &lt; 0)\n        &#123;\n            cv.wait(lock);\n        &#125;\n    &#125;\n    void V()\n    &#123;\n        std::unique_lock&lt;std::mutex&gt; lock(mx);\n        if (++count &lt;&#x3D; 0)\n        &#123;\n            cv.notify_one();\n        &#125;\n    &#125;\n&#125;;\nint g_num &#x3D; 0;\nMySemaphore semp(1);&#x2F;&#x2F;生产\nMySemaphore sems(0);&#x2F;&#x2F;消费\n\nvoid P(int id)\n&#123;\n    for (int i &#x3D; 0; i &lt; 10; ++i)\n    &#123;\n        semp.P();\n        g_num &#x3D; i;\n        std::cout &lt;&lt; &quot;P &quot; &lt;&lt; g_num &lt;&lt; std::endl;\n        sems.V();\n    &#125;\n&#125;\nvoid S(int id)\n&#123;\n    for (int i &#x3D; 0; i &lt; 10; ++i)\n    &#123;\n        sems.P();\n        std::cout &lt;&lt; &quot;S&quot; &lt;&lt; g_num &lt;&lt; std::endl;\n        semp.V();\n    &#125;\n&#125;\nint main()\n&#123;\n    std::thread thp(P,1);\n    std::thread ths(S,1);\n    thp.join();\n    ths.join();\n    return 0;\n&#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>如果消费者线程一开始执行 <code>P(fullBuffers)</code>，由于信号量 <code>fullBuffers</code> 初始值为 0，则此时 <code>fullBuffers</code> 的值从 0 变为 -1，说明缓冲区里没有数据，消费者只能等待。</p>\n<p>接着，轮到生产者执行 <code>P(emptyBuffers)</code>，表示减少 1 个空槽，如果当前没有其他生产者线程在临界区执行代码，那么该生产者线程就可以把数据放到缓冲区，放完后，执行 <code>V(fullBuffers)</code> ，信号量 <code>fullBuffers</code> 从 -1 变成 0，表明有「消费者」线程正在阻塞等待数据，于是阻塞等待的消费者线程会被唤醒。</p>\n<p>消费者线程被唤醒后，如果此时没有其他消费者线程在读数据，那么就可以直接进入临界区，从缓冲区读取数据。最后，离开临界区后，把空槽的个数 + 1。</p>\n<h3 id=\"死锁\"><a href=\"#死锁\" class=\"headerlink\" title=\"死锁\"></a>死锁</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>那么，当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成<strong>两个线程都在等待对方释放锁</strong>，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了<strong>死锁</strong>。</p></blockquote>\n<p>死锁只有<strong>同时满足</strong>以下四个条件才会发生：</p>\n<ul>\n<li><p>互斥条件；</p>\n</li>\n<li><p>持有并等待条件；</p>\n</li>\n<li><p>不可剥夺条件；</p>\n</li>\n<li><p>环路等待条件；</p>\n</li>\n<li><p><strong>互斥条件</strong></p>\n</li>\n</ul>\n<p>互斥条件是指<strong>多个线程不能同时使用同一个资源</strong>。</p>\n<p>比如下图，如果线程 A 已经持有的资源，不能再同时被线程 B 持有，如果线程 B 请求获取线程 A 已经占用的资源，那线程 B 只能等待，直到线程 A 释放了资源。</p>\n<ul>\n<li><strong>持有并等待条件</strong></li>\n</ul>\n<p>持有并等待条件是指，当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是<strong>线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1</strong>。</p>\n<ul>\n<li><strong>不可剥夺条件</strong></li>\n</ul>\n<p>不可剥夺条件是指，当线程已经持有了资源 ，<strong>在自己使用完之前不能被其他线程获取</strong>，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。</p>\n<ul>\n<li><strong>环路等待条件</strong></li>\n</ul>\n<p>环路等待条件指的是，在死锁发生的时候，<strong>两个线程获取资源的顺序构成了环形链</strong>。</p>\n<p>比如，线程 A 已经持有资源 2，而想请求资源 1， 线程 B 已经获取了资源 1，而想请求资源 2，这就形成资源请求等待的环形图。</p>\n<pre class=\"line-numbers language-c++\" data-language=\"c++\"><code class=\"language-c++\">#include &quot;thread&quot;\n#include &quot;iostream&quot;\n#include &quot;mutex&quot;\n#include &quot;unistd.h&quot;\n\npthread_mutex_t mutex_A &#x3D; PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex_B &#x3D; PTHREAD_MUTEX_INITIALIZER;\n\n\nvoid *threadB_proc(void *data)\n&#123;\n    printf(&quot;thread B waiting get ResourceB \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_B);\n    printf(&quot;thread B got ResourceB \\n&quot;);\n\n    sleep(1);\n\n    printf(&quot;thread B waiting  get ResourceA \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_A);\n    printf(&quot;thread B got ResourceA \\n&quot;);\n\n    pthread_mutex_unlock(&amp;mutex_A);\n    pthread_mutex_unlock(&amp;mutex_B);\n    return (void *)0;\n&#125;\n\nvoid *threadA_proc(void *data)\n&#123;\n    printf(&quot;thread A waiting get ResourceA \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_A);\n    printf(&quot;thread A got ResourceA \\n&quot;);\n\n    sleep(1);\n\n    printf(&quot;thread A waiting get ResourceB \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_B);\n    printf(&quot;thread A got ResourceB \\n&quot;);\n\n    pthread_mutex_unlock(&amp;mutex_B);\n    pthread_mutex_unlock(&amp;mutex_A);\n    return (void *)0;\n&#125;\n\nint main()\n&#123;\n    pthread_t tidA, tidB;\n\n    &#x2F;&#x2F;创建两个线程\n    pthread_create(&amp;tidA, NULL, threadA_proc, NULL);\n    pthread_create(&amp;tidB, NULL, threadB_proc, NULL);\n\n    pthread_join(tidA, NULL);\n    pthread_join(tidB, NULL);\n\n    printf(&quot;exit\\n&quot;);\n\n    return 0;\n&#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>可以看到线程 B 在等待互斥锁 A 的释放，线程 A 在等待互斥锁 B 的释放，双方都在等待对方资源的释放，很明显，产生了死锁问题。</p>\n<hr>\n<h4 id=\"利用工具排查死锁问题\"><a href=\"#利用工具排查死锁问题\" class=\"headerlink\" title=\"利用工具排查死锁问题\"></a>利用工具排查死锁问题</h4><p>在 Linux 下，我们可以使用 <code>pstack</code> + <code>gdb</code> 工具来定位死锁问题。</p>\n<p>pstack 命令可以显示每个线程的栈跟踪信息（函数调用过程），它的使用方式也很简单，只需要 <code>pstack &lt;pid&gt;</code> 就可以了。</p>\n<p>那么，在定位死锁问题时，我们可以多次执行 pstack 命令查看线程的函数调用过程，多次对比结果，确认哪几个线程一直没有变化，且是因为在等待锁，那么大概率是由于死锁问题导致的。</p>\n<p>我用 pstack 输出了我前面模拟死锁问题的进程的所有线程的情况，我多次执行命令后，其结果都一样，如下：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">$ pstack <span class=\"token number\">87746</span>\nThread <span class=\"token number\">3</span> <span class=\"token punctuation\">(</span>Thread 0x7f60a610a700 <span class=\"token punctuation\">(</span>LWP <span class=\"token number\">87747</span><span class=\"token punctuation\">))</span>:\n<span class=\"token comment\">#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#3  0x0000000000400725 in threadA_proc ()</span>\n<span class=\"token comment\">#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6</span>\nThread <span class=\"token number\">2</span> <span class=\"token punctuation\">(</span>Thread 0x7f60a5709700 <span class=\"token punctuation\">(</span>LWP <span class=\"token number\">87748</span><span class=\"token punctuation\">))</span>:\n<span class=\"token comment\">#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#3  0x0000000000400792 in threadB_proc ()</span>\n<span class=\"token comment\">#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6</span>\nThread <span class=\"token number\">1</span> <span class=\"token punctuation\">(</span>Thread 0x7f60a610c700 <span class=\"token punctuation\">(</span>LWP <span class=\"token number\">87746</span><span class=\"token punctuation\">))</span>:\n<span class=\"token comment\">#0  0x0000003720e080e5 in pthread_join () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#1  0x0000000000400806 in main ()</span>\n\n<span class=\"token punctuation\">..</span><span class=\"token punctuation\">..</span>\n\n$ pstack <span class=\"token number\">87746</span>\nThread <span class=\"token number\">3</span> <span class=\"token punctuation\">(</span>Thread 0x7f60a610a700 <span class=\"token punctuation\">(</span>LWP <span class=\"token number\">87747</span><span class=\"token punctuation\">))</span>:\n<span class=\"token comment\">#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#3  0x0000000000400725 in threadA_proc ()</span>\n<span class=\"token comment\">#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6</span>\nThread <span class=\"token number\">2</span> <span class=\"token punctuation\">(</span>Thread 0x7f60a5709700 <span class=\"token punctuation\">(</span>LWP <span class=\"token number\">87748</span><span class=\"token punctuation\">))</span>:\n<span class=\"token comment\">#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#3  0x0000000000400792 in threadB_proc ()</span>\n<span class=\"token comment\">#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6</span>\nThread <span class=\"token number\">1</span> <span class=\"token punctuation\">(</span>Thread 0x7f60a610c700 <span class=\"token punctuation\">(</span>LWP <span class=\"token number\">87746</span><span class=\"token punctuation\">))</span>:\n<span class=\"token comment\">#0  0x0000003720e080e5 in pthread_join () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#1  0x0000000000400806 in main ()</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>可以看到，Thread 2 和 Thread 3 一直阻塞获取锁（<em>pthread_mutex_lock</em>）的过程，而且 pstack 多次输出信息都没有变化，那么可能大概率发生了死锁。</p>\n<p>但是，还不能够确认这两个线程是在互相等待对方的锁的释放，因为我们看不到它们是等在哪个锁对象，于是我们可以使用 gdb 工具进一步确认。</p>\n<p>整个 gdb 调试过程，如下：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">// gdb 命令\n$ gdb <span class=\"token parameter variable\">-p</span> <span class=\"token number\">87746</span>\n\n// 打印所有的线程信息\n<span class=\"token punctuation\">(</span>gdb<span class=\"token punctuation\">)</span> info thread\n  <span class=\"token number\">3</span> Thread 0x7f60a610a700 <span class=\"token punctuation\">(</span>LWP <span class=\"token number\">87747</span><span class=\"token punctuation\">)</span>  0x0000003720e0da1d <span class=\"token keyword\">in</span> __lll_lock_wait <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> from /lib64/libpthread.so.0\n  <span class=\"token number\">2</span> Thread 0x7f60a5709700 <span class=\"token punctuation\">(</span>LWP <span class=\"token number\">87748</span><span class=\"token punctuation\">)</span>  0x0000003720e0da1d <span class=\"token keyword\">in</span> __lll_lock_wait <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> from /lib64/libpthread.so.0\n* <span class=\"token number\">1</span> Thread 0x7f60a610c700 <span class=\"token punctuation\">(</span>LWP <span class=\"token number\">87746</span><span class=\"token punctuation\">)</span>  0x0000003720e080e5 <span class=\"token keyword\">in</span> pthread_join <span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span> from /lib64/libpthread.so.0\n//最左边的 * 表示 gdb 锁定的线程，切换到第二个线程去查看\n\n// 切换到第2个线程\n<span class=\"token punctuation\">(</span>gdb<span class=\"token punctuation\">)</span> thread <span class=\"token number\">2</span>\n<span class=\"token punctuation\">[</span>Switching to thread <span class=\"token number\">2</span> <span class=\"token punctuation\">(</span>Thread 0x7f60a5709700 <span class=\"token punctuation\">(</span>LWP <span class=\"token number\">87748</span><span class=\"token punctuation\">))</span><span class=\"token punctuation\">]</span><span class=\"token comment\">#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0 </span>\n\n// bt 可以打印函数堆栈，却无法看到函数参数，跟 pstack 命令一样 \n<span class=\"token punctuation\">(</span>gdb<span class=\"token punctuation\">)</span> bt\n<span class=\"token comment\">#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#3  0x0000000000400792 in threadB_proc (data=0x0) at dead_lock.c:25</span>\n<span class=\"token comment\">#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0</span>\n<span class=\"token comment\">#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6</span>\n\n// 打印第三帧信息，每次函数调用都会有压栈的过程，而 frame 则记录栈中的帧信息\n<span class=\"token punctuation\">(</span>gdb<span class=\"token punctuation\">)</span> frame <span class=\"token number\">3</span>\n<span class=\"token comment\">#3  0x0000000000400792 in threadB_proc (data=0x0) at dead_lock.c:25</span>\n<span class=\"token number\">27</span>    printf<span class=\"token punctuation\">(</span><span class=\"token string\">\"thread B waiting get ResourceA <span class=\"token entity\" title=\"\\n\">\\n</span>\"</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token number\">28</span>    pthread_mutex_lock<span class=\"token punctuation\">(</span><span class=\"token operator\">&amp;</span>mutex_A<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n\n// 打印mutex_A的值 ,  __owner表示gdb中标示线程的值，即LWP\n<span class=\"token punctuation\">(</span>gdb<span class=\"token punctuation\">)</span> p mutex_A\n<span class=\"token variable\">$1</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>__data <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>__lock <span class=\"token operator\">=</span> <span class=\"token number\">2</span>, __count <span class=\"token operator\">=</span> <span class=\"token number\">0</span>, __owner <span class=\"token operator\">=</span> <span class=\"token number\">87747</span>, __nusers <span class=\"token operator\">=</span> <span class=\"token number\">1</span>, __kind <span class=\"token operator\">=</span> <span class=\"token number\">0</span>, __spins <span class=\"token operator\">=</span> <span class=\"token number\">0</span>, __list <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>__prev <span class=\"token operator\">=</span> 0x0, __next <span class=\"token operator\">=</span> 0x0<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#125;</span>, \n  __size <span class=\"token operator\">=</span> <span class=\"token string\">\"<span class=\"token entity\" title=\"\\002\">\\002</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\303\">\\303</span>V<span class=\"token entity\" title=\"\\001\">\\001</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\001\">\\001</span>\"</span>, <span class=\"token string\">'\\000'</span> <span class=\"token operator\">&lt;</span>repeats <span class=\"token number\">26</span> times<span class=\"token operator\">></span>, __align <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">&#125;</span>\n\n// 打印mutex_B的值 ,  __owner表示gdb中标示线程的值，即LWP\n<span class=\"token punctuation\">(</span>gdb<span class=\"token punctuation\">)</span> p mutex_B\n<span class=\"token variable\">$2</span> <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>__data <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>__lock <span class=\"token operator\">=</span> <span class=\"token number\">2</span>, __count <span class=\"token operator\">=</span> <span class=\"token number\">0</span>, __owner <span class=\"token operator\">=</span> <span class=\"token number\">87748</span>, __nusers <span class=\"token operator\">=</span> <span class=\"token number\">1</span>, __kind <span class=\"token operator\">=</span> <span class=\"token number\">0</span>, __spins <span class=\"token operator\">=</span> <span class=\"token number\">0</span>, __list <span class=\"token operator\">=</span> <span class=\"token punctuation\">&#123;</span>__prev <span class=\"token operator\">=</span> 0x0, __next <span class=\"token operator\">=</span> 0x0<span class=\"token punctuation\">&#125;</span><span class=\"token punctuation\">&#125;</span>, \n  __size <span class=\"token operator\">=</span> <span class=\"token string\">\"<span class=\"token entity\" title=\"\\002\">\\002</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\304\">\\304</span>V<span class=\"token entity\" title=\"\\001\">\\001</span><span class=\"token entity\" title=\"\\000\">\\000</span><span class=\"token entity\" title=\"\\001\">\\001</span>\"</span>, <span class=\"token string\">'\\000'</span> <span class=\"token operator\">&lt;</span>repeats <span class=\"token number\">26</span> times<span class=\"token operator\">></span>, __align <span class=\"token operator\">=</span> <span class=\"token number\">2</span><span class=\"token punctuation\">&#125;</span>  <span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>我来解释下，上面的调试过程：</p>\n<ol>\n<li>通过 <code>info thread</code> 打印了所有的线程信息，可以看到有 3 个线程，一个是主线程（LWP 87746），另外两个都是我们自己创建的线程（LWP 87747 和 87748）；</li>\n<li>通过 <code>thread 2</code>，将切换到第 2 个线程（LWP 87748）；</li>\n<li>通过 <code>bt</code>，打印线程的调用栈信息，可以看到有 threadB_proc 函数，说明这个是线程 B 函数，也就说 LWP 87748 是线程 B;</li>\n<li>通过 <code>frame 3</code>，打印调用栈中的第三个帧的信息，可以看到线程 B 函数，在获取互斥锁 A 的时候阻塞了；</li>\n<li>通过 <code>p mutex_A</code>，打印互斥锁 A 对象信息，可以看到它被 LWP 为 87747（线程 A） 的线程持有着；</li>\n<li>通过 <code>p mutex_B</code>，打印互斥锁 B 对象信息，可以看到他被 LWP 为 87748 （线程 B） 的线程持有着；</li>\n</ol>\n<p>因为线程 B 在等待线程 A 所持有的 mutex_A, 而同时线程 A 又在等待线程 B 所拥有的mutex_B, 所以可以断定该程序发生了死锁。</p>\n<h4 id=\"避免死锁问题的发生\"><a href=\"#避免死锁问题的发生\" class=\"headerlink\" title=\"避免死锁问题的发生\"></a>避免死锁问题的发生</h4><p>前面我们提到，产生死锁的四个必要条件是：互斥条件、持有并等待条件、不可剥夺条件、环路等待条件。</p>\n<p>那么避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是<strong>使用资源有序分配法，来破环环路等待条件</strong>。</p>\n<p>那什么是资源有序分配法呢？</p>\n<p>线程 A 和 线程 B 获取资源的顺序要一样，当线程 A 是先尝试获取资源 A，然后尝试获取资源 B 的时候，线程 B 同样也是先尝试获取资源 A，然后尝试获取资源 B。也就是说，线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。</p>\n<p>我们使用资源有序分配法的方式来修改前面发生死锁的代码，我们可以不改动线程 A 的代码。</p>\n<p>我们先要清楚线程 A 获取资源的顺序，它是先获取互斥锁 A，然后获取互斥锁 B。</p>\n<p>所以我们只需将线程 B 改成以相同顺序的获取资源，就可以打破死锁了。</p>\n<h3 id=\"互斥锁与自旋锁\"><a href=\"#互斥锁与自旋锁\" class=\"headerlink\" title=\"互斥锁与自旋锁\"></a>互斥锁与自旋锁</h3><p>最底层的两种就是会「互斥锁和自旋锁」，有很多高级的锁都是基于它们实现的，你可以认为它们是各种锁的地基，所以我们必须清楚它俩之间的区别和应用。</p>\n<p>加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。</p>\n<p>当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：</p>\n<ul>\n<li><strong>互斥锁</strong>加锁失败后，线程会<strong>释放 CPU</strong> ，给其他线程；</li>\n<li><strong>自旋锁</strong>加锁失败后，线程会<strong>忙等待</strong>，直到它拿到锁；</li>\n</ul>\n<p>互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，<strong>既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞</strong>。</p>\n<p><strong>对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的</strong>。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/互斥锁工作流程.3kzz0mkm9ty0.webp\"/>\n</div>\n\n<p>所以，互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。</p>\n<p>那这个开销成本是什么呢？会有<strong>两次线程上下文切换的成本</strong>：</p>\n<ul>\n<li>当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行；</li>\n<li>接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。</li>\n</ul>\n<p>线程的上下文切换的是什么？当两个线程是属于同一个进程，<strong>因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。</strong></p>\n<p>上下切换的耗时有大佬统计过，大概在几十纳秒到几微秒之间，如果你锁住的代码执行时间比较短，那可能上下文切换的时间都比你锁住的代码执行时间还要长。</p>\n<p>所以，<strong>如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。</strong></p>\n<p>自旋锁是通过 CPU 提供的 <code>CAS</code> 函数（<em>Compare And Swap</em>），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。</p>\n<p>一般加锁的过程，包含两个步骤：</p>\n<ul>\n<li>第一步，查看锁的状态，如果锁是空闲的，则执行第二步；</li>\n<li>第二步，将锁设置为当前线程持有；</li>\n</ul>\n<p>CAS 函数就把这两个步骤合并成一条硬件级指令，形成<strong>原子指令</strong>，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。</p>\n<p>比如，设锁为变量 lock，整数 0 表示锁是空闲状态，整数 pid 表示线程 ID，那么 CAS(lock, 0, pid) 就表示自旋锁的加锁操作，CAS(lock, pid, 0) 则表示解锁操作。</p>\n<p>使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 <code>while</code> 循环等待实现，不过最好是使用 CPU 提供的 <code>PAUSE</code> 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。</p>\n<p>自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。<strong>需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。</strong></p>\n<p>自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系，我们需要清楚的知道这一点。</p>\n<p>自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：<strong>当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对</strong>。</p>\n<p>它俩是锁的最基本处理方式，更高级的锁都会选择其中一个来实现，比如读写锁既可以选择互斥锁实现，也可以基于自旋锁实现。</p>\n<h3 id=\"读写锁\"><a href=\"#读写锁\" class=\"headerlink\" title=\"读写锁\"></a>读写锁</h3><p>读写锁从字面意思我们也可以知道，它由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。</p>\n<p>所以，<strong>读写锁适用于能明确区分读操作和写操作的场景</strong>。</p>\n<p>读写锁的工作原理是：</p>\n<ul>\n<li>当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。</li>\n<li>但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。</li>\n</ul>\n<p>所以说，写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有。</p>\n<p>知道了读写锁的工作原理后，我们可以发现，<strong>读写锁在读多写少的场景，能发挥出优势</strong>。</p>\n<p>另外，根据实现的不同，读写锁可以分为「读优先锁」和「写优先锁」。</p>\n<p>读优先锁期望的是，读锁能被更多的线程持有，以便提高读线程的并发性，它的工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取写锁。</p>\n<p>读优先锁对于读线程并发性更好，但也不是没有问题。我们试想一下，如果一直有读线程获取读锁，那么写线程将永远获取不到写锁，这就造成了写线程「饥饿」的现象。</p>\n<p>写优先锁可以保证写线程不会饿死，但是如果一直有写线程获取写锁，读线程也会被「饿死」。</p>\n<p>既然不管优先读锁还是写锁，对方可能会出现饿死问题，那么我们就不偏袒任何一方，搞个「公平读写锁」。</p>\n<p><strong>公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。</strong></p>\n<p>互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。</p>\n<h3 id=\"乐观锁与悲观锁\"><a href=\"#乐观锁与悲观锁\" class=\"headerlink\" title=\"乐观锁与悲观锁\"></a>乐观锁与悲观锁</h3><p>悲观锁做事比较悲观，它认为<strong>多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁</strong>。</p>\n<p>那相反的，如果多线程同时修改共享资源的概率比较低，就可以采用乐观锁。</p>\n<p>乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：<strong>先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作</strong>。</p>\n<p>放弃后如何重试，这跟业务场景息息相关，虽然重试的成本很高，但是冲突的概率足够低的话，还是可以接受的。</p>\n<p>可见，乐观锁的心态是，不管三七二十一，先改了资源再说。另外，你会发现<strong>乐观锁全程并没有加锁，所以它也叫无锁编程</strong>。</p>\n<p>服务端要怎么验证是否冲突了呢？通常方案如下：</p>\n<ul>\n<li>由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号；</li>\n<li>当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号不一致则提交失败，如果版本号一致则修改成功，然后服务端版本号更新到最新的版本号。</li>\n</ul>\n<p>实际上，我们常见的 SVN 和 Git 也是用了乐观锁的思想，先让用户编辑代码，然后提交的时候，通过版本号来判断是否产生了冲突，发生了冲突的地方，需要我们自己修改后，再重新提交。</p>\n<p>乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以<strong>只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。</strong></p>\n<h1 id=\"网络系统\"><a href=\"#网络系统\" class=\"headerlink\" title=\"网络系统\"></a>网络系统</h1><h2 id=\"零拷贝\"><a href=\"#零拷贝\" class=\"headerlink\" title=\"零拷贝\"></a>零拷贝</h2><h3 id=\"DMA技术\"><a href=\"#DMA技术\" class=\"headerlink\" title=\"DMA技术\"></a>DMA技术</h3><p>在没有 DMA 技术前，I&#x2F;O 的过程是这样的：</p>\n<ul>\n<li>CPU 发出对应的指令给磁盘控制器，然后返回；</li>\n<li>磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个<strong>中断</strong>；</li>\n<li>CPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。</li>\n</ul>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/I_O-中断.18g5kt3rs5r4.webp\"/>\n</div>\n\n<p>可以看到，整个数据的传输过程，都要需要 CPU 亲自参与搬运数据的过程，而且这个过程，CPU 是不能做其他事情的。</p>\n<p>简单的搬运几个字符数据那没问题，但是如果我们用千兆网卡或者硬盘传输大量数据的时候，都用 CPU 来搬运的话，肯定忙不过来。</p>\n<p>计算机科学家们发现了事情的严重性后，于是就发明了 DMA 技术，也就是<strong>直接内存访问（*Direct Memory Access*）</strong> 技术。</p>\n<p>什么是 DMA 技术？简单理解就是，<strong>在进行 I&#x2F;O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务</strong>。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/DRM-I_O-过程.sy5qmi80400.webp\"/>\n</div>\n\n<p>具体过程：</p>\n<ul>\n<li>用户进程调用 read 方法，向操作系统发出 I&#x2F;O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；</li>\n<li>操作系统收到请求后，进一步将 I&#x2F;O 请求发送 DMA，然后让 CPU 执行其他任务；</li>\n<li>DMA 进一步将 I&#x2F;O 请求发送给磁盘；</li>\n<li>磁盘收到 DMA 的 I&#x2F;O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；</li>\n<li><strong>DMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务</strong>；</li>\n<li>当 DMA 读取了足够多的数据，就会发送中断信号给 CPU；</li>\n<li>CPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；</li>\n</ul>\n<p>可以看到， 整个数据传输的过程，CPU 不再参与数据搬运的工作，而是全程由 DMA 完成，但是 CPU 在这个过程中也是必不可少的，因为传输什么数据，从哪里传输到哪里，都需要 CPU 来告诉 DMA 控制器。</p>\n<p>早期 DMA 只存在在主板上，如今由于 I&#x2F;O 设备越来越多，数据传输的需求也不尽相同，所以每个 I&#x2F;O 设备里面都有自己的 DMA 控制器。</p>\n<h3 id=\"传统文件传输\"><a href=\"#传统文件传输\" class=\"headerlink\" title=\"传统文件传输\"></a>传统文件传输</h3><p>如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。</p>\n<p>传统 I&#x2F;O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I&#x2F;O 接口从磁盘读取或写入。</p>\n<p>代码通常如下，一般会需要两个系统调用：</p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\"><span class=\"token function\">read</span><span class=\"token punctuation\">(</span>file<span class=\"token punctuation\">,</span> tmp_buf<span class=\"token punctuation\">,</span> len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token function\">write</span><span class=\"token punctuation\">(</span>socket<span class=\"token punctuation\">,</span> tmp_buf<span class=\"token punctuation\">,</span> len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/传统文件传输.2f8q0ou4zow0.webp\"/>\n</div>\n\n<p>首先，期间共<strong>发生了 4 次用户态与内核态的上下文切换</strong>，因为发生了两次系统调用，一次是 <code>read()</code> ，一次是 <code>write()</code>，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。</p>\n<p>上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。</p>\n<p>其次，还<strong>发生了 4 次数据拷贝</strong>，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程：</p>\n<ul>\n<li><em>第一次拷贝</em>，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。</li>\n<li><em>第二次拷贝</em>，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。</li>\n<li><em>第三次拷贝</em>，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。</li>\n<li><em>第四次拷贝</em>，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。</li>\n</ul>\n<p>我们回过头看这个文件传输的过程，我们只是搬运一份数据，结果却搬运了 4 次，过多的数据拷贝无疑会消耗 CPU 资源，大大降低了系统性能。</p>\n<p>这种简单又传统的文件传输方式，存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。</p>\n<p>所以，<strong>要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数</strong>。</p>\n<h3 id=\"传输性能优化\"><a href=\"#传输性能优化\" class=\"headerlink\" title=\"传输性能优化\"></a>传输性能优化</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>先来看看，如何减少「用户态与内核态的上下文切换」的次数呢？</p></blockquote>\n<p>读取磁盘数据的时候，之所以要发生上下文切换，这是因为用户空间没有权限操作磁盘或网卡，内核的权限最高，这些操作设备的过程都需要交由操作系统内核来完成，所以一般要通过内核去完成某些任务的时候，就需要使用操作系统提供的系统调用函数。</p>\n<p>而一次系统调用必然会发生 2 次上下文切换：首先从用户态切换到内核态，当内核执行完任务后，再切换回用户态交由进程代码执行。</p>\n<p>所以，<strong>要想减少上下文切换到次数，就要减少系统调用的次数</strong>。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>再来看看，如何减少「数据拷贝」的次数？</p></blockquote>\n<p>在前面我们知道了，传统的文件传输方式会历经 4 次数据拷贝，而且这里面，「从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里」，这个过程是没有必要的。</p>\n<p>因为文件传输的应用场景中，在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此<strong>用户的缓冲区是没有必要存在的</strong>。</p>\n<h3 id=\"零拷贝实现\"><a href=\"#零拷贝实现\" class=\"headerlink\" title=\"零拷贝实现\"></a>零拷贝实现</h3><p>零拷贝技术实现的方式通常有 2 种：</p>\n<ul>\n<li>mmap + write</li>\n<li>sendfile</li>\n</ul>\n<p>下面就谈一谈，它们是如何减少「上下文切换」和「数据拷贝」的次数。</p>\n<h4 id=\"mmap-write\"><a href=\"#mmap-write\" class=\"headerlink\" title=\"mmap + write\"></a>mmap + write</h4><p>在前面我们知道，<code>read()</code> 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 <code>mmap()</code> 替换 <code>read()</code> 系统调用函数。</p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">buf <span class=\"token operator\">=</span> <span class=\"token function\">mmap</span><span class=\"token punctuation\">(</span>file<span class=\"token punctuation\">,</span> len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token function\">write</span><span class=\"token punctuation\">(</span>sockfd<span class=\"token punctuation\">,</span> buf<span class=\"token punctuation\">,</span> len<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<p><code>mmap()</code> 系统调用函数会直接把内核缓冲区里的数据「<strong>映射</strong>」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/mmap-+-write-零拷贝.78ubxpi6nwo0.webp\"/>\n</div>\n\n<p>具体过程如下：</p>\n<ul>\n<li>应用进程调用了 <code>mmap()</code> 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；</li>\n<li>应用进程再调用 <code>write()</code>，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；</li>\n<li>最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。</li>\n</ul>\n<p>我们可以得知，通过使用 <code>mmap()</code> 来代替 <code>read()</code>， 可以减少一次数据拷贝的过程。</p>\n<p>但这还不是最理想的零拷贝，因为仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。</p>\n<h3 id=\"sendfile\"><a href=\"#sendfile\" class=\"headerlink\" title=\"sendfile\"></a>sendfile</h3><p>在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 <code>sendfile()</code>，函数形式如下：</p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\"><span class=\"token macro property\"><span class=\"token directive-hash\">#</span><span class=\"token directive keyword\">include</span> <span class=\"token string\">&lt;sys/socket.h></span></span>\n<span class=\"token class-name\">ssize_t</span> <span class=\"token function\">sendfile</span><span class=\"token punctuation\">(</span><span class=\"token keyword\">int</span> out_fd<span class=\"token punctuation\">,</span> <span class=\"token keyword\">int</span> in_fd<span class=\"token punctuation\">,</span> <span class=\"token class-name\">off_t</span> <span class=\"token operator\">*</span>offset<span class=\"token punctuation\">,</span> <span class=\"token class-name\">size_t</span> count<span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span></span></code></pre>\n\n<p>它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。</p>\n<p>首先，它可以替代前面的 <code>read()</code> 和 <code>write()</code> 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。</p>\n<p>其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图：</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/senfile-3次拷贝.11710tap26j4.webp\"/>\n</div>\n\n<p>但是这还不是真正的零拷贝技术，如果网卡支持 SG-DMA（<em>The Scatter-Gather Direct Memory Access</em>）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。</p>\n<p>于是，从 Linux 内核 <code>2.4</code> 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， <code>sendfile()</code> 系统调用的过程发生了点变化，具体过程如下：</p>\n<ul>\n<li>第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；</li>\n<li>第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；</li>\n</ul>\n<p>这就是所谓的<strong>零拷贝（*Zero-copy*）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。</strong>。</p>\n<p>零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，<strong>只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。</strong></p>\n<p>所以，总体来看，<strong>零拷贝技术可以把文件传输的性能提高至少一倍以上</strong>。</p>\n<h3 id=\"PageCache\"><a href=\"#PageCache\" class=\"headerlink\" title=\"PageCache\"></a>PageCache</h3><p>回顾前面说道文件传输过程，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是<strong>磁盘高速缓存（*PageCache*）</strong>。</p>\n<p>由于零拷贝使用了 PageCache 技术，可以使得零拷贝进一步提升了性能，我们接下来看看 PageCache 是如何做到这一点的。</p>\n<p>读写磁盘相比读写内存的速度慢太多了，所以我们应该想办法把「读写磁盘」替换成「读写内存」。于是，我们会通过 DMA 把磁盘里的数据搬运到内存里，这样就可以用读内存替换读磁盘。</p>\n<p>我们都知道程序运行的时候，具有「局部性」，所以通常，刚被访问的数据在短时间内再次被访问的概率很高，于是我们可以用 <strong>PageCache 来缓存最近被访问的数据</strong>，当空间不足时淘汰最久未被访问的缓存。</p>\n<p>所以，读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中。</p>\n<p>还有一点，读取磁盘数据的时候，需要找到数据所在的位置，但是对于机械磁盘来说，就是通过磁头旋转到数据所在的扇区，再开始「顺序」读取数据，但是旋转磁头这个物理动作是非常耗时的，为了降低它的影响，<strong>PageCache 使用了「预读功能」</strong>。</p>\n<p>比如，假设 read 方法每次只会读 <code>32 KB</code> 的字节，虽然 read 刚开始只会读 0 ～ 32 KB 的字节，但内核会把其后面的 32～64 KB 也读取到 PageCache，这样后面读取 32～64 KB 的成本就很低，如果在 32～64 KB 淘汰出 PageCache 前，进程读取到它了，收益就非常大。</p>\n<p>所以，PageCache 的优点主要是两个：</p>\n<ul>\n<li>缓存最近被访问的数据；</li>\n<li>预读功能；</li>\n</ul>\n<p><strong>但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能</strong></p>\n<p>这是因为如果你有很多 GB 级别文件需要传输，每当用户访问这些大文件的时候，内核就会把它们载入 PageCache 中，于是 PageCache 空间很快被这些大文件占满。</p>\n<p>另外，由于文件太大，可能某些部分的文件数据被再次访问的概率比较低，这样就会带来 2 个问题：</p>\n<ul>\n<li>PageCache 由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 PageCache，于是这样磁盘读写的性能就会下降了；</li>\n<li>PageCache 中的大文件数据，由于没有享受到缓存带来的好处，但却耗费 DMA 多拷贝到 PageCache 一次；</li>\n</ul>\n<p>所以，针对大文件的传输，不应该使用 PageCache，也就是说不应该使用零拷贝技术，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，这样在高并发的环境下，会带来严重的性能问题。</p>\n<h3 id=\"大文件传输方式\"><a href=\"#大文件传输方式\" class=\"headerlink\" title=\"大文件传输方式\"></a>大文件传输方式</h3><p>绕开 PageCache 的 I&#x2F;O 叫直接 I&#x2F;O，使用 PageCache 的 I&#x2F;O 则叫缓存 I&#x2F;O。通常，对于磁盘，异步 I&#x2F;O 只支持直接 I&#x2F;O。</p>\n<p>前面也提到，大文件的传输不应该使用 PageCache，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache。</p>\n<p>于是，<strong>在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I&#x2F;O + 直接 I&#x2F;O」来替代零拷贝技术</strong>。</p>\n<p>直接 I&#x2F;O 应用场景常见的两种：</p>\n<ul>\n<li>应用程序已经实现了磁盘数据的缓存，那么可以不需要 PageCache 再次缓存，减少额外的性能损耗。在 MySQL 数据库中，可以通过参数设置开启直接 I&#x2F;O，默认是不开启；</li>\n<li>传输大文件的时候，由于大文件难以命中 PageCache 缓存，而且会占满 PageCache 导致「热点」文件无法充分利用缓存，从而增大了性能开销，因此，这时应该使用直接 I&#x2F;O。</li>\n</ul>\n<p>另外，由于直接 I&#x2F;O 绕过了 PageCache，就无法享受内核的这两点的优化：</p>\n<ul>\n<li>内核的 I&#x2F;O 调度算法会缓存尽可能多的 I&#x2F;O 请求在 PageCache 中，最后「<strong>合并</strong>」成一个更大的 I&#x2F;O 请求再发给磁盘，这样做是为了减少磁盘的寻址操作；</li>\n<li>内核也会「<strong>预读</strong>」后续的 I&#x2F;O 请求放在 PageCache 中，一样是为了减少对磁盘的操作；</li>\n</ul>\n<p>于是，传输大文件的时候，使用「异步 I&#x2F;O + 直接 I&#x2F;O」了，就可以无阻塞地读取文件了。</p>\n<p>所以，传输文件的时候，我们要根据文件的大小来使用不同的方式：</p>\n<ul>\n<li>传输大文件的时候，使用「异步 I&#x2F;O + 直接 I&#x2F;O」；</li>\n<li>传输小文件的时候，则使用「零拷贝技术」；</li>\n</ul>\n<p>在 nginx 中，我们可以用如下配置，来根据文件的大小来使用不同的方式：</p>\n<pre class=\"line-numbers language-text\" data-language=\"text\"><code class=\"language-text\">location /video/ &#123; \n    sendfile on; \n    aio on; \n    directio 1024m; \n&#125;<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>当文件大小大于 <code>directio</code> 值后，使用「异步 I&#x2F;O + 直接 I&#x2F;O」，否则使用「零拷贝技术」。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/异步-IO-的过程.3tl8xleh7go0.webp\"/>\n</div>\n\n<h2 id=\"I-x2F-O-多路复用\"><a href=\"#I-x2F-O-多路复用\" class=\"headerlink\" title=\"I&#x2F;O 多路复用\"></a>I&#x2F;O 多路复用</h2><h3 id=\"Socket-模型\"><a href=\"#Socket-模型\" class=\"headerlink\" title=\"Socket 模型\"></a>Socket 模型</h3><p>要想客户端和服务器能在网络中通信，那必须得使用 Socket 编程，它是进程间通信里比较特别的方式，特别之处在于它是可以跨主机间通信。</p>\n<p>Socket 的中文名叫作插口，咋一看还挺迷惑的。事实上，双方要进行网络通信前，各自得创建一个 Socket，这相当于客户端和服务器都开了一个“口子”，双方读取和发送数据的时候，都通过这个“口子”。这样一看，是不是觉得很像弄了一根网线，一头插在客户端，一头插在服务端，然后进行通信。</p>\n<p>创建 Socket 的时候，可以指定网络层使用的是 IPv4 还是 IPv6，传输层使用的是 TCP 还是 UDP。</p>\n<ul>\n<li>服务端</li>\n</ul>\n<p>服务端首先调用 <code>socket()</code> 函数，创建网络协议为 IPv4，以及传输协议为 TCP 的 Socket ，接着调用 <code>bind()</code> 函数，给这个 Socket 绑定一个 <strong>IP 地址和端口</strong>，绑定这两个的目的是什么？</p>\n<ul>\n<li>绑定端口的目的：当内核收到 TCP 报文，通过 TCP 头里面的端口号，来找到我们的应用程序，然后把数据传递给我们。</li>\n<li>绑定 IP 地址的目的：一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址，当绑定一个网卡时，内核在收到该网卡上的包，才会发给我们；</li>\n</ul>\n<p>绑定完 IP 地址和端口后，就可以调用 <code>listen()</code> 函数进行监听，此时对应 TCP 状态图中的 <code>listen</code>，如果我们要判定服务器中一个网络程序有没有启动，可以通过 <code>netstat</code> 命令查看对应的端口号是否有被监听。</p>\n<p>服务端进入了监听状态后，通过调用 <code>accept()</code> 函数，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来。</p>\n<ul>\n<li>客户端</li>\n</ul>\n<p>客户端在创建好 Socket 后，调用 <code>connect()</code> 函数发起连接，该函数的参数要指明服务端的 IP 地址和端口号，然后万众期待的 TCP 三次握手就开始了。</p>\n<p>在 TCP 连接的过程中，服务器的内核实际上为每个 Socket 维护了两个队列：</p>\n<ul>\n<li>一个是「还没完全建立」连接的队列，称为 <strong>TCP 半连接队列</strong>，这个队列都是没有完成三次握手的连接，此时服务端处于 <code>syn_rcvd</code> 的状态；</li>\n<li>一个是「已经建立」连接的队列，称为 <strong>TCP 全连接队列</strong>，这个队列都是完成了三次握手的连接，此时服务端处于 <code>established</code> 状态；</li>\n</ul>\n<p>当 TCP 全连接队列不为空后，服务端的 <code>accept()</code> 函数，就会从内核中的 TCP 全连接队列里拿出一个已经完成连接的 Socket 返回应用程序，后续数据传输都用这个 Socket。</p>\n<p>注意，监听的 Socket 和真正用来传数据的 Socket 是两个：</p>\n<ul>\n<li>一个叫作<strong>监听 Socket</strong>；</li>\n<li>一个叫作<strong>已连接 Socket</strong>；</li>\n</ul>\n<p>连接建立后，客户端和服务端就开始相互传输数据了，双方都可以通过 <code>read()</code> 和 <code>write()</code> 函数来读写数据。</p>\n<h4 id=\"文件描述符\"><a href=\"#文件描述符\" class=\"headerlink\" title=\"*文件描述符\"></a>*文件描述符</h4><p>文件描述符的作用是什么？每一个进程都有一个数据结构 <code>task_struct</code>，该结构体里有一个指向「文件描述符数组」的成员指针。该数组里列出这个进程打开的所有文件的文件描述符。数组的下标是文件描述符，是一个整数，而数组的内容是一个指针，指向内核中所有打开的文件的列表，也就是说内核可以通过文件描述符找到对应打开的文件。</p>\n<p>然后每个文件都有一个 inode，Socket 文件的 inode 指向了内核中的 Socket 结构，在这个结构体里有两个队列，分别是<strong>发送队列</strong>和<strong>接收队列</strong>，这个两个队列里面保存的是一个个 <code>struct sk_buff</code>，用链表的组织形式串起来。</p>\n<p>sk_buff 可以表示各个层的数据包，在应用层数据包叫 data，在 TCP 层我们称为 segment，在 IP 层我们叫 packet，在数据链路层称为 frame。</p>\n<p>你可能会好奇，为什么全部数据包只用一个结构体来描述呢？协议栈采用的是分层结构，上层向下层传递数据时需要增加包头，下层向上层数据时又需要去掉包头，如果每一层都用一个结构体，那在层之间传递数据的时候，就要发生多次拷贝，这将大大降低 CPU 效率。</p>\n<p>于是，为了在层级之间传递数据时，不发生拷贝，只用 sk_buff 一个结构体来描述所有的网络包，那它是如何做到的呢？是通过调整 sk_buff 中 <code>data</code> 的指针，比如：</p>\n<ul>\n<li>当接收报文时，从网卡驱动开始，通过协议栈层层往上传送数据报，通过增加 skb-&gt;data 的值，来逐步剥离协议首部。</li>\n<li>当要发送报文时，创建 sk_buff 结构体，数据缓存区的头部预留足够的空间，用来填充各层首部，在经过各下层协议时，通过减少 skb-&gt;data 的值来增加协议首部。</li>\n</ul>\n<p>你可以从下面这张图看到，当发送报文时，data 指针的移动过程。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/sk_buff.3ak1c4i6bso0.webp\"/>\n</div>\n\n<p>前面提到的 TCP Socket 调用流程是最简单、最基本的，它基本只能一对一通信，因为使用的是同步阻塞的方式，当服务端在还没处理完一个客户端的网络 I&#x2F;O 时，或者 读写操作发生阻塞时，其他客户端是无法与服务端连接的。</p>\n<p>可如果我们服务器只能服务一个客户，那这样就太浪费资源了，于是我们要改进这个网络 I&#x2F;O 模型，以支持更多的客户端。</p>\n<p>在改进网络 I&#x2F;O 模型前，我先来提一个问题，你知道服务器单机理论最大能连接多少个客户端？</p>\n<p>相信你知道 TCP 连接是由四元组唯一确认的，这个四元组就是：<strong>本机IP, 本机端口, 对端IP, 对端端口</strong>。</p>\n<p>服务器作为服务方，通常会在本地固定监听一个端口，等待客户端的连接。因此服务器的本地 IP 和端口是固定的，于是对于服务端 TCP 连接的四元组只有对端 IP 和端口是会变化的，所以<strong>最大 TCP 连接数 &#x3D; 客户端 IP 数×客户端端口数</strong>。</p>\n<p>对于 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是<strong>服务端单机最大 TCP 连接数约为 2 的 48 次方</strong>。</p>\n<p>这个理论值相当“丰满”，但是服务器肯定承载不了那么大的连接数，主要会受两个方面的限制：</p>\n<ul>\n<li><strong>文件描述符</strong>，Socket 实际上是一个文件，也就会对应一个文件描述符。在 Linux 下，单个进程打开的文件描述符数是有限制的，没有经过修改的值一般都是 1024，不过我们可以通过 ulimit 增大文件描述符的数目；</li>\n<li><strong>系统内存</strong>，每个 TCP 连接在内核中都有对应的数据结构，意味着每个连接都是会占用一定内存的；</li>\n</ul>\n<p>那如果服务器的内存只有 2 GB，网卡是千兆的，能支持并发 1 万请求吗？</p>\n<p>并发 1 万请求，也就是经典的 C10K 问题 ，C 是 Client 单词首字母缩写，C10K 就是单机同时处理 1 万个请求的问题。</p>\n<p>从硬件资源角度看，对于 2GB 内存千兆网卡的服务器，如果每个请求处理占用不到 200KB 的内存和 100Kbit 的网络带宽就可以满足并发 1 万个请求。</p>\n<p>不过，要想真正实现 C10K 的服务器，要考虑的地方在于服务器的网络 I&#x2F;O 模型，效率低的模型，会加重系统开销，从而会离 C10K 的目标越来越远。</p>\n<h3 id=\"多进程模型\"><a href=\"#多进程模型\" class=\"headerlink\" title=\"多进程模型\"></a>多进程模型</h3><p>基于最原始的阻塞网络 I&#x2F;O， 如果服务器要支持多个客户端，其中比较传统的方式，就是使用<strong>多进程模型</strong>，也就是为每个客户端分配一个进程来处理请求。</p>\n<p>服务器的主进程负责监听客户的连接，一旦与客户端连接完成，accept() 函数就会返回一个「已连接 Socket」，这时就通过 <code>fork()</code> 函数创建一个子进程，实际上就把父进程所有相关的东西都<strong>复制</strong>一份，包括文件描述符、内存地址空间、程序计数器、执行的代码等。</p>\n<p>这两个进程刚复制完的时候，几乎一模一样。不过，会根据<strong>返回值</strong>来区分是父进程还是子进程，如果返回值是 0，则是子进程；如果返回值是其他的整数，就是父进程。</p>\n<p>正因为子进程会<strong>复制父进程的文件描述符</strong>，于是就可以直接使用「已连接 Socket 」和客户端通信了，</p>\n<p>可以发现，子进程不需要关心「监听 Socket」，只需要关心「已连接 Socket」；父进程则相反，将客户服务交给子进程来处理，因此父进程不需要关心「已连接 Socket」，只需要关心「监听 Socket」。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/多进程.6ybqjrcyrco0.webp\"/>\n</div>\n\n<p>另外，当「子进程」退出时，实际上内核里还会保留该进程的一些信息，也是会占用内存的，如果不做好“回收”工作，就会变成<strong>僵尸进程</strong>，随着僵尸进程越多，会慢慢耗尽我们的系统资源。</p>\n<p>因此，父进程要“善后”好自己的孩子，怎么善后呢？那么有两种方式可以在子进程退出后回收资源，分别是调用 <code>wait()</code> 和 <code>waitpid()</code> 函数。</p>\n<p>这种用多个进程来应付多个客户端的方式，在应对 100 个客户端还是可行的，但是当客户端数量高达一万时，肯定扛不住的，因为每产生一个进程，必会占据一定的系统资源，而且进程间上下文切换的“包袱”是很重的，性能会大打折扣。</p>\n<p>进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。</p>\n<h4 id=\"僵尸进程\"><a href=\"#僵尸进程\" class=\"headerlink\" title=\"僵尸进程\"></a>僵尸进程</h4><p>如果子进程先退出，父进程还没退出，那么子进程必须等到父进程捕获到了子进 程的退出状态才真正结束，否则这个时候子进程就成为僵尸进程。 </p>\n<p>设置僵尸进程的目的是维护子进程的信息，以便父进程在以后某个时候获取。这些信息 至少包括进程 ID，进程的终止状态，以及该进程使用的 CPU 时间，所以当终止子进程的父 进程调用 wait 或 waitpid 时就可以得到这些信息。如果一个进程终止时该进程有子进程处于 僵尸状态，那么它的所有僵尸子进程的父进程将被重置为 init 进程并且清理它们。</p>\n<ul>\n<li>如何避免僵尸进程</li>\n</ul>\n<ol>\n<li>父进程可将 SIGCHLD 的处理函数设为 SIG_IGN（亦为默认设定）通知内核对子进程的结束 不关心，由内核回收。这种忽略 SIGCHLD 信号的方法，常用于并发服务器的性能的一个技巧 因为并发服务器常常 fork 很多子进程，子进程终结之后需要服务器进程去 wait 清理资源。 如果将此信号的处理方式设为忽略，可让内核把僵尸子进程转交给 init 进程去处理，省去了 大量僵尸进程占用系统资源。 </li>\n<li>如果父进程很忙可以用 signal 注册信号处理函数，在信号处理函数调用 wait&#x2F;waitpid 等待 子进程退出。 </li>\n<li>通过两次调用 fork。父进程首先调用 fork 创建一个子进程然后 waitpid 等待子进程退出， 子进程再 fork 一个子孙进程后退出。这样子进程退出后会被父进程等待回收，而对于子孙 进程其父进程已经退出所以子孙进程成为一个孤儿进程，孤儿进程由 init 进程接管，子孙进 程结束后，init 会回收。</li>\n</ol>\n<h3 id=\"多线程模型\"><a href=\"#多线程模型\" class=\"headerlink\" title=\"多线程模型\"></a>多线程模型</h3><p>既然进程间上下文切换的“包袱”很重，那我们就搞个比较轻量级的模型来应对多用户的请求 —— <strong>多线程模型</strong>。</p>\n<p>线程是运行在进程中的一个“逻辑流”，单进程中可以运行多个线程，同进程里的线程可以共享进程的部分资源，比如文件描述符列表、进程空间、代码、全局数据、堆、共享库等，这些共享些资源在上下文切换时不需要切换，而只需要切换线程的私有数据、寄存器等不共享的数据，因此同一个进程下的线程上下文切换的开销要比进程小得多。</p>\n<p>当服务器与客户端 TCP 完成连接后，通过 <code>pthread_create()</code> 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的。</p>\n<p>如果每来一个连接就创建一个线程，线程运行完后，还得操作系统还得销毁线程，虽说线程切换的上写文开销不大，但是如果频繁创建和销毁线程，系统开销也是不小的。</p>\n<p>那么，我们可以使用<strong>线程池</strong>的方式来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建若干个线程，这样当由新连接建立时，将这个已连接的 Socket 放入到一个队列里，然后线程池里的线程负责从队列中取出「已连接 Socket 」进行处理。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/线程池.2q38bdbh0ps0.webp\"/>\n</div>\n\n<p>需要注意的是，这个队列是全局的，每个线程都会操作，为了避免多线程竞争，线程在操作这个队列前要加锁。</p>\n<p>上面基于进程或者线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程，那么如果要达到 C10K，意味着要一台机器维护 1 万个连接，相当于要维护 1 万个进程&#x2F;线程，操作系统就算死扛也是扛不住的。</p>\n<h3 id=\"I-x2F-O-多路复用-1\"><a href=\"#I-x2F-O-多路复用-1\" class=\"headerlink\" title=\"I&#x2F;O 多路复用\"></a>I&#x2F;O 多路复用</h3><p>既然为每个请求分配一个进程&#x2F;线程的方式不合适，那有没有可能只使用一个进程来维护多个 Socket 呢？答案是有的，那就是 <strong>I&#x2F;O 多路复用</strong>技术。</p>\n<p>一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。</p>\n<p>我们熟悉的 select&#x2F;poll&#x2F;epoll 内核提供给用户态的多路复用系统调用，<strong>进程可以通过一个系统调用函数从内核中获取多个事件</strong>。</p>\n<p>select&#x2F;poll&#x2F;epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。</p>\n<p>select&#x2F;poll&#x2F;epoll 这是三个多路复用接口，都能实现 C10K 吗？接下来，我们分别说说它们。</p>\n<h4 id=\"select-x2F-poll\"><a href=\"#select-x2F-poll\" class=\"headerlink\" title=\"select&#x2F;poll\"></a>select&#x2F;poll</h4><p>select 实现多路复用的方式是，将已连接的 Socket 都放到一个<strong>文件描述符集合</strong>，然后调用 select 函数将文件描述符集合<strong>拷贝</strong>到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过<strong>遍历</strong>文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合<strong>拷贝</strong>回用户态里，然后用户态还需要再通过<strong>遍历</strong>的方法找到可读或可写的 Socket，然后再对其处理。</p>\n<p>所以，对于 select 这种方式，需要进行 <strong>2 次「遍历」文件描述符集合</strong>，一次是在内核态里，一个次是在用户态里 ，而且还会发生 <strong>2 次「拷贝」文件描述符集合</strong>，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。</p>\n<p>select 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 <code>1024</code>，只能监听 0~1023 的文件描述符。</p>\n<p>poll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。</p>\n<p>但是 poll 和 select 并没有太大的本质区别，<strong>都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合</strong>，这种方式随着并发数上来，性能的损耗会呈指数级增长。</p>\n<h3 id=\"epoll\"><a href=\"#epoll\" class=\"headerlink\" title=\"epoll\"></a>epoll</h3><p>先复习下 epoll 的用法。如下的代码中，先用e poll_create 创建一个 epol l对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到epfd中，最后调用 epoll_wait 等待数据。</p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\"><span class=\"token keyword\">int</span> s <span class=\"token operator\">=</span> <span class=\"token function\">socket</span><span class=\"token punctuation\">(</span>AF_INET<span class=\"token punctuation\">,</span> SOCK_STREAM<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token function\">bind</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token function\">listen</span><span class=\"token punctuation\">(</span>s<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token keyword\">int</span> epfd <span class=\"token operator\">=</span> <span class=\"token function\">epoll_create</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n<span class=\"token function\">epoll_ctl</span><span class=\"token punctuation\">(</span>epfd<span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span> <span class=\"token comment\">//将所有需要监听的socket添加到epfd中</span>\n\n<span class=\"token keyword\">while</span><span class=\"token punctuation\">(</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span> <span class=\"token punctuation\">&#123;</span>\n    <span class=\"token keyword\">int</span> n <span class=\"token operator\">=</span> <span class=\"token function\">epoll_wait</span><span class=\"token punctuation\">(</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">;</span>\n    <span class=\"token keyword\">for</span><span class=\"token punctuation\">(</span>接收到数据的socket<span class=\"token punctuation\">)</span><span class=\"token punctuation\">&#123;</span>\n        <span class=\"token comment\">//处理</span>\n    <span class=\"token punctuation\">&#125;</span>\n<span class=\"token punctuation\">&#125;</span><span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>\n\n<p>epoll 通过两个方面，很好解决了 select&#x2F;poll 的问题。</p>\n<p><em>第一点</em>，epoll 在内核里使用<strong>红黑树来跟踪进程所有待检测的文件描述字</strong>，把需要监控的 socket 通过 <code>epoll_ctl()</code> 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 <code>O(logn)</code>。而 select&#x2F;poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select&#x2F;poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Epoll 在内核里面有一个相应的数据结构去存储数据，这个数据结构就是 eventpoll，它主 要存储两方面的信息：需要监听的 fd（文件描述符）集合（红黑树实现，因为要利于添加和 删除，还要便于搜索以免重复添加）和<strong>就绪列表（双向链表）</strong>用来存放就绪的 socket 集合。 Eventpoll 主要采用了回调的方式去代替轮询检查，当在 eventpoll 中注册一个 socket 时，会 在等待队列保存 eventpoll 的引用，如果 socket 读缓存区写入数据后会采用回调的方式将其 放入 eventpoll 中的就绪队列。 所以当调用 epoll_wait 检测是否有事件发生时只需要检测 eventpoll 中的就绪队列是否为 空即可。</p></blockquote>\n<p><em>第二点</em>， epoll 使用<strong>事件驱动</strong>的机制，内核里<strong>维护了一个链表来记录就绪事件</strong>，当某个 socket 有事件发生时，通过<strong>回调函数</strong>内核会将其加入到这个就绪事件列表中，当用户调用 <code>epoll_wait()</code> 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select&#x2F;poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/epoll.6fztxwehtd40.webp\"/>\n</div>\n\n<p>epoll 支持两种事件触发模式，分别是**边缘触发（*edge-triggered，ET*）**和**水平触发（*level-triggered，LT*）**。</p>\n<p>这两个术语还挺抽象的，其实它们的区别还是很好理解的。</p>\n<ul>\n<li>使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，<strong>服务器端只会从 epoll_wait 中苏醒一次</strong>，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；</li>\n</ul>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>epoll 边沿触发时，假设一个客户端发送 100 字节的数据，而服务器设定 read 每次读取 20 字 节，那么一次触发只能读取 20 个字节， 然后内核调用 epoll_wait 直到下一次事件发生，才会继续从剩下的 80 字节读取 20 个字节， 由此可见，这种模式其工作效率非常低且无法保证数据的完整性，因此边沿触发不会单独使 用。边沿触发通常与非阻塞 IO 一起使用，其工作模式为：epoll_wait 触发一次，在 while（1） 循环内非阻塞 IO 读取数据，直到缓冲区数据为空（保证了数据的完整性），内核才会继续 调用 epoll_wait 等待事件发生。</p></blockquote>\n<ul>\n<li>使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，<strong>服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束</strong>，目的是告诉我们有数据需要读取；</li>\n</ul>\n<p>如果使用水平触发模式，当内核通知文件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要一次执行尽可能多的读写操作。</p>\n<p>如果使用边缘触发模式，I&#x2F;O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会<strong>循环</strong>从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，<strong>边缘触发模式一般和非阻塞 I&#x2F;O 搭配使用</strong>，程序会一直执行 I&#x2F;O 操作，直到系统调用（如 <code>read</code> 和 <code>write</code>）返回错误，错误类型为 <code>EAGAIN</code> 或 <code>EWOULDBLOCK</code>。</p>\n<p>一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。</p>\n<p>select&#x2F;poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。</p>\n<p>另外，使用 I&#x2F;O 多路复用时，最好搭配非阻塞 I&#x2F;O 一起使用</p>\n<p><strong>多路复用 API 返回的事件并不一定可读写的</strong>，如果使用阻塞 I&#x2F;O， 那么在调用 read&#x2F;write 时则会发生程序阻塞，因此最好搭配非阻塞 I&#x2F;O，以便应对极少数的特殊情况。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>通常的，对一个文件描述符指定的文件或设备*,* 有两种工作方式*:* 阻塞 与非阻塞 。所谓阻塞方式的意思是指*,* 当试图对该文件描述符进行读写时*,* 如果当时没有东西可读*,<em>或者暂时不可写</em>,* 程序就进入<strong>等待 状态</strong><em>,</em> 直到有东西可读或者可写为止。而对于非阻塞状态*,* 如果没有东西可读*,* 或者不可写*,* 读写函数<strong>马上返回</strong><em>,</em> 而不会等待 。</p></blockquote>\n<h2 id=\"高性能网络模式\"><a href=\"#高性能网络模式\" class=\"headerlink\" title=\"高性能网络模式\"></a>高性能网络模式</h2><h3 id=\"Reactor\"><a href=\"#Reactor\" class=\"headerlink\" title=\"Reactor\"></a>Reactor</h3><p>这里的反应指的是「<strong>对事件反应</strong>」，也就是<strong>来了一个事件，Reactor 就有相对应的反应&#x2F;响应</strong>。</p>\n<p>事实上，Reactor 模式也叫 <code>Dispatcher</code> 模式，我觉得这个名字更贴合该模式的含义，即 <strong>I&#x2F;O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 &#x2F; 线程</strong>。</p>\n<p>Reactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：</p>\n<ul>\n<li>Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；</li>\n<li>处理资源池负责处理事件，如 read -&gt; 业务逻辑 -&gt; send；</li>\n</ul>\n<p>Reactor 模式是灵活多变的，可以应对不同的业务场景，灵活在于：</p>\n<ul>\n<li>Reactor 的数量可以只有一个，也可以有多个；</li>\n<li>处理资源池可以是单个进程 &#x2F; 线程，也可以是多个进程 &#x2F;线程；</li>\n</ul>\n<p>将上面的两个因素排列组设一下，理论上就可以有 4 种方案选择：</p>\n<ul>\n<li>单 Reactor 单进程 &#x2F; 线程；</li>\n<li>单 Reactor 多进程 &#x2F; 线程；</li>\n<li>多 Reactor 单进程 &#x2F; 线程；</li>\n<li>多 Reactor 多进程 &#x2F; 线程；</li>\n</ul>\n<p>其中，「多 Reactor 单进程 &#x2F; 线程」实现方案相比「单 Reactor 单进程 &#x2F; 线程」方案，不仅复杂而且也没有性能优势，因此实际中并没有应用。</p>\n<p>剩下的 3 个方案都是比较经典的，且都有应用在实际的项目中：</p>\n<ul>\n<li>单 Reactor 单进程 &#x2F; 线程；</li>\n<li>单 Reactor 多线程 &#x2F; 进程；</li>\n<li>多 Reactor 多进程 &#x2F; 线程；</li>\n</ul>\n<p>方案具体使用进程还是线程，要看使用的编程语言以及平台有关：</p>\n<ul>\n<li>Java 语言一般使用线程，比如 Netty;</li>\n<li>C 语言使用进程和线程都可以，例如 Nginx 使用的是进程，Memcache 使用的是线程。</li>\n</ul>\n<p>接下来，分别介绍这三个经典的 Reactor 方案。</p>\n<h4 id=\"单-Reactor-单进程-x2F-线程\"><a href=\"#单-Reactor-单进程-x2F-线程\" class=\"headerlink\" title=\"单 Reactor 单进程 &#x2F; 线程\"></a>单 Reactor 单进程 &#x2F; 线程</h4><p>一般来说，C 语言实现的是「<strong>单 Reactor <em>单进程</em></strong>」的方案，因为 C 语编写完的程序，运行后就是一个独立的进程，不需要在进程中再创建线程。</p>\n<p>而 Java 语言实现的是「<strong>单 Reactor <em>单线程</em></strong>」的方案，因为 Java 程序是跑在 Java 虚拟机这个进程上面的，虚拟机中有很多线程，我们写的 Java 程序只是其中的一个线程而已。</p>\n<p>我们来看看「<strong>单 Reactor 单进程</strong>」的方案示意图：</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/单Reactor单进程.694ajzuc96k0.webp\"/>\n</div>\n\n<p>可以看到进程里有 <strong>Reactor、Acceptor、Handler</strong> 这三个对象：</p>\n<ul>\n<li>Reactor 对象的作用是监听和分发事件；</li>\n<li>Acceptor 对象的作用是获取连接；</li>\n<li>Handler 对象的作用是处理业务；</li>\n</ul>\n<p>对象里的 select、accept、read、send 是系统调用函数，dispatch 和 「业务处理」是需要完成的操作，其中 dispatch 是分发事件操作。</p>\n<p>接下来，介绍下「单 Reactor 单进程」这个方案：</p>\n<ul>\n<li>Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；</li>\n<li>如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；</li>\n<li>如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；</li>\n<li>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li>\n</ul>\n<p>单 Reactor 单进程的方案因为全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。</p>\n<p>但是，这种方案存在 2 个缺点：</p>\n<ul>\n<li>第一个缺点，因为只有一个进程，<strong>无法充分利用 多核 CPU 的性能</strong>；</li>\n<li>第二个缺点，Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，<strong>如果业务处理耗时比较长，那么就造成响应的延迟</strong>；</li>\n</ul>\n<p>所以，单 Reactor 单进程的方案<strong>不适用计算机密集型的场景，只适用于业务处理非常快速的场景</strong>。</p>\n<p>Redis 是由 C 语言实现的，在 Redis 6.0 版本之前采用的正是「单 Reactor 单进程」的方案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。</p>\n<h4 id=\"单-Reactor-多线程-x2F-多进程\"><a href=\"#单-Reactor-多线程-x2F-多进程\" class=\"headerlink\" title=\"单 Reactor 多线程 &#x2F; 多进程\"></a>单 Reactor 多线程 &#x2F; 多进程</h4><p>如果要克服「单 Reactor 单线程 &#x2F; 进程」方案的缺点，那么就需要引入多线程 &#x2F; 多进程，这样就产生了<strong>单 Reactor 多线程 &#x2F; 多进程</strong>的方案。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/单Reactor多线程.1jncjx7hlfq.webp\"/>\n</div>\n\n<p>详细说一下这个方案：</p>\n<ul>\n<li>Reactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；</li>\n<li>如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；</li>\n<li>如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；</li>\n</ul>\n<p>上面的三个步骤和单 Reactor 单线程方案是一样的，接下来的步骤就开始不一样了：</p>\n<ul>\n<li>Handler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后，会将数据发给子线程里的 Processor 对象进行业务处理；</li>\n<li>子线程里的 Processor 对象就进行业务处理，处理完后，将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send 方法将响应结果发送给 client；</li>\n</ul>\n<p>单 Reator 多线程的方案优势在于<strong>能够充分利用多核 CPU 的能</strong>，那既然引入多线程，那么自然就带来了多线程竞争资源的问题。</p>\n<p>例如，子线程完成业务处理后，要把结果传递给主线程的 Handler 进行发送，这里涉及共享数据的竞争。</p>\n<p>要避免多线程由于竞争共享资源而导致数据错乱的问题，就需要在操作共享资源前加上互斥锁，以保证任意时间里只有一个线程在操作共享资源，待该线程操作完释放互斥锁后，其他线程才有机会操作共享数据。</p>\n<p>另外，「单 Reactor」的模式还有个问题，<strong>因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方</strong>。</p>\n<h3 id=\"多-Reactor-多进程-x2F-线程\"><a href=\"#多-Reactor-多进程-x2F-线程\" class=\"headerlink\" title=\"多 Reactor 多进程 &#x2F; 线程\"></a>多 Reactor 多进程 &#x2F; 线程</h3><p>要解决「单 Reactor」的问题，就是将「单 Reactor」实现成「多 Reactor」，这样就产生了第 <strong>多 Reactor 多进程 &#x2F; 线程</strong>的方案。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/主从Reactor多线程.155zxl7xre9s.webp\"/>\n</div>\n\n<p>方案详细说明如下：</p>\n<ul>\n<li>主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept 获取连接，将新的连接分配给某个子线程；</li>\n<li>子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听，并创建一个 Handler 用于处理连接的响应事件。</li>\n<li>如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应。</li>\n<li>Handler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。</li>\n</ul>\n<p>多 Reactor 多线程的方案虽然看起来复杂的，但是实际实现时比单 Reactor 多线程的方案要简单的多，原因如下：</p>\n<ul>\n<li>主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理。</li>\n<li>主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端。</li>\n</ul>\n<p>大名鼎鼎的两个开源软件 Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案。</p>\n<p>采用了「多 Reactor 多进程」方案的开源软件是 Nginx，不过方案与标准的多 Reactor 多进程有些差异。</p>\n<p>具体差异表现在主进程中仅仅用来初始化 socket，并没有创建 mainReactor 来 accept 连接，而是由子进程的 Reactor 来 accept 连接，通过锁来控制一次只有一个子进程进行 accept（防止出现惊群现象），子进程 accept 新连接后就放到自己的 Reactor 进行处理，不会再分配给其他子进程。</p>\n<p>关于惊群现象可以参考这篇文章<a href=\"https://www.zhihu.com/question/22756773\">什么是惊群，如何有效避免惊群? </a></p>\n<h3 id=\"Proactor\"><a href=\"#Proactor\" class=\"headerlink\" title=\"Proactor\"></a>Proactor</h3><p>前面提到的 Reactor 是非阻塞同步网络模式，而 <strong>Proactor 是异步网络模式</strong>。</p>\n<p>先来看看<strong>阻塞 I&#x2F;O</strong>，当用户程序执行 <code>read</code> ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，<code>read</code> 才会返回。</p>\n<p>注意，<strong>阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程</strong>。</p>\n<p>知道了阻塞 I&#x2F;O ，来看看<strong>非阻塞 I&#x2F;O</strong>，非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，<code>read</code> 调用才可以获取到结果。</p>\n<p>注意，<strong>这里最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。</strong></p>\n<p>举个例子，如果 socket 设置了 <code>O_NONBLOCK</code> 标志，那么就表示使用的是非阻塞 I&#x2F;O 的方式访问，而不做任何设置的话，默认是阻塞 I&#x2F;O。</p>\n<p>因此，无论 read 和 send 是阻塞 I&#x2F;O，还是非阻塞 I&#x2F;O 都是同步调用。因为在 read 调用时，内核将数据从内核空间拷贝到用户空间的过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。</p>\n<p>而真正的<strong>异步 I&#x2F;O</strong> 是「内核数据准备好」和「数据从内核态拷贝到用户态」这<strong>两个过程都不用等待</strong>。</p>\n<p>当我们发起 <code>aio_read</code> （异步 I&#x2F;O） 之后，就立即返回，内核自动将数据从内核空间拷贝到用户空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，<strong>应用程序并不需要主动发起拷贝动作</strong>。过程如下图：</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/异步-I_O.6jaa7y41k280.webp\"/>\n</div>\n\n<p>很明显，异步 I&#x2F;O 比同步 I&#x2F;O 性能更好，因为异步 I&#x2F;O 在「内核数据准备好」和「数据从内核空间拷贝到用户空间」这两个过程都不用等待。</p>\n<p>Proactor 正是采用了异步 I&#x2F;O 技术，所以被称为异步网络模型。</p>\n<p>现在我们再来理解 Reactor 和 Proactor 的区别，就比较清晰了。</p>\n<ul>\n<li><strong>Reactor 是非阻塞同步网络模式，感知的是就绪可读写事件</strong>。在每次感知到有事件发生（比如可读就绪事件）后，就需要应用进程主动调用 read 方法来完成数据的读取，也就是要应用进程主动将 socket 接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。</li>\n<li><strong>Proactor 是异步网络模式， 感知的是已完成的读写事件</strong>。在发起异步读写请求时，需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全程由操作系统来做，并不需要像 Reactor 那样还需要应用进程主动发起 read&#x2F;write 来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。</li>\n</ul>\n<p>因此，<strong>Reactor 可以理解为「来了事件操作系统通知应用进程，让应用进程来处理」</strong>，而 <strong>Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应用进程」</strong>。这里的「事件」就是有新连接、有数据可读、有数据可写的这些 I&#x2F;O 事件这里的「处理」包含从驱动读取到内核以及从内核读取到用户空间。</p>\n<p>无论是 Reactor，还是 Proactor，都是一种基于「事件分发」的网络编程模式，区别在于 <strong>Reactor 模式是基于「待完成」的 I&#x2F;O 事件，而 Proactor 模式则是基于「已完成」的 I&#x2F;O 事件</strong>。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/Proactor.1ecn1s99hlmo.webp\"/>\n</div>\n\n<p>介绍一下 Proactor 模式的工作流程：</p>\n<ul>\n<li>Proactor Initiator 负责创建 Proactor 和 Handler 对象，并将 Proactor 和 Handler 都通过 Asynchronous Operation Processor 注册到内核；</li>\n<li>Asynchronous Operation Processor 负责处理注册请求，并处理 I&#x2F;O 操作；</li>\n<li>Asynchronous Operation Processor 完成 I&#x2F;O 操作后通知 Proactor；</li>\n<li>Proactor 根据不同的事件类型回调不同的 Handler 进行业务处理；</li>\n<li>Handler 完成业务处理；</li>\n</ul>\n<p>可惜的是，在 Linux 下的异步 I&#x2F;O 是不完善的， <code>aio</code> 系列函数是由 POSIX 定义的异步操作接口，不是真正的操作系统级别支持的，而是在用户空间模拟出来的异步，并且仅仅支持基于本地文件的 aio 异步操作，网络编程中的 socket 是不支持的，这也使得基于 Linux 的高性能网络程序都是使用 Reactor 方案。</p>\n<p>而 Windows 里实现了一套完整的支持 socket 的异步编程接口，这套接口就是 <code>IOCP</code>，是由操作系统级别实现的异步 I&#x2F;O，真正意义上异步 I&#x2F;O，因此在 Windows 里实现高性能网络程序可以使用效率更高的 Proactor 方案。</p>\n<h2 id=\"一致性哈希\"><a href=\"#一致性哈希\" class=\"headerlink\" title=\"一致性哈希\"></a>一致性哈希</h2><p>有的同学可能很快就想到了：<strong>哈希算法</strong>。因为对同一个关键字进行哈希计算，每次计算都是相同的值，这样就可以将某个 key 确定到一个节点了，可以满足分布式系统的负载均衡需求。</p>\n<p>哈希算法最简单的做法就是进行取模运算，比如分布式系统中有 3 个节点，基于 <code>hash(key) % 3</code> 公式对数据进行了映射。</p>\n<p>如果客户端要获取指定 key 的数据，通过下面的公式可以定位节点：</p>\n<pre class=\"line-numbers language-text\" data-language=\"text\"><code class=\"language-text\">hash(key) % 3<span aria-hidden=\"true\" class=\"line-numbers-rows\"><span></span></span></code></pre>\n\n<p>如果经过上面这个公式计算后得到的值是 0，就说明该 key 需要去第一个节点获取。</p>\n<p>但是有一个很致命的问题，<strong>如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据</strong>，否则会出现查询不到数据的问题。</p>\n<p>同样的道理，如果我们对分布式系统进行缩容，比如移除一个节点，也会因为取模哈希函数中基数的变化，可能出现查询不到数据的问题。</p>\n<p>要解决这个问题的办法，就需要我们进行<strong>迁移数据</strong>，比如节点的数量从 3 变化为 4 时，要基于新的计算公式 hash(key) % 4 ，重新对数据和节点做映射。</p>\n<p>假设总数据条数为 M，哈希算法在面对节点数量变化时，**最坏情况下所有数据都需要迁移，所以它的数据迁移规模是 O(M)**，这样数据的迁移成本太高了。</p>\n<p>所以，我们应该要重新想一个新的算法，来避免分布式系统在扩容或者缩容时，发生过多的数据迁移。</p>\n<h3 id=\"存在的问题\"><a href=\"#存在的问题\" class=\"headerlink\" title=\"存在的问题\"></a>存在的问题</h3><p>一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而<strong>一致哈希算法是对 2^32 进行取模运算，是一个固定的值</strong>。</p>\n<p>我们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环，就像钟表一样，钟表的圆可以理解成由 60 个点组成的圆，而此处我们把这个圆想象成由 2^32 个点组成的圆，这个圆环被称为<strong>哈希环</strong></p>\n<p>一致性哈希要进行两步哈希：</p>\n<ul>\n<li>第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；</li>\n<li>第二步：当对数据进行存储或访问时，对数据进行哈希映射；</li>\n</ul>\n<p>所以，<strong>一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上</strong>。</p>\n<p>问题来了，对「数据」进行哈希映射得到一个结果要怎么找到存储该数据的节点呢？</p>\n<p>答案是，映射的结果值往<strong>顺时针的方向的找到第一个节点</strong>，就是存储该数据的节点。</p>\n<p>接着，对要查询的 key-01 进行哈希计算，确定此 key-01 映射在哈希环的位置，然后从这个位置往顺时针的方向找到第一个节点，就是存储该 key-01 数据的节点。</p>\n<p>比如，下图中的 key-01 映射的位置，往顺时针的方向找到第一个节点就是节点 A。</p>\n<p>所以，当需要对指定 key 的值进行读写的时候，要通过下面 2 步进行寻址：</p>\n<ul>\n<li>首先，对 key 进行哈希计算，确定此 key 在环上的位置；</li>\n<li>然后，从这个位置沿着顺时针方向走，遇到的第一节点就是存储 key 的节点。</li>\n</ul>\n<p>知道了一致哈希寻址的方式，我们来看看，如果增加一个节点或者减少一个节点会发生大量的数据迁移吗？</p>\n<p>你可以看到，key-02 和 key-03 不会受到影响，只有 key-01 需要被迁移节点 B。</p>\n<p>因此，<strong>在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响</strong>。</p>\n<p>上面这些图中 3 个节点映射在哈希环还是比较分散的，所以看起来请求都会「均衡」到每个节点。</p>\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/30c2c70721c12f9c140358fbdc5f2282.4q2b7eg2hri0.webp\"/>\n</div>\n\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/31485046f1303b57d8aaeaab103ea7ab.3owkus2jqrc0.webp\"/>\n</div>\n\n<div align=center>\n<img src=\"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/f8909edef2f3949f8945bb99380baab3.6gjbsjvb20s0.webp\"/>\n</div>\n\n<p>但是<strong>一致性哈希算法并不保证节点能够在哈希环上分布均匀</strong>，这样就会带来一个问题，会有大量的请求集中在一个节点上。</p>\n","text":"本文参考了小林coding,csapp等操作系统教程，以及Websever的一些框架和思路。写了一篇个人的笔记，其中也包含了本人对于一些小问题的记录和思考，以及整体框架的梳理。 进程管理快速了解可以参考： 进程 我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制...","link":"","photos":[],"count_time":{"symbolsCount":"59k","symbolsTime":"54 mins."},"categories":[{"name":"操作系统","slug":"操作系统","count":2,"path":"api/categories/操作系统.json"}],"tags":[{"name":"操作系统","slug":"操作系统","count":2,"path":"api/tags/操作系统.json"},{"name":"基础知识","slug":"基础知识","count":2,"path":"api/tags/基础知识.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86\"><span class=\"toc-text\">进程管理</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%BF%9B%E7%A8%8B\"><span class=\"toc-text\">进程</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%BF%9B%E7%A8%8B%E7%9A%84%E7%8A%B6%E6%80%81\"><span class=\"toc-text\">进程的状态</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%8E%A7%E5%88%B6%E7%BB%93%E6%9E%84\"><span class=\"toc-text\">进程的控制结构</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%8E%A7%E5%88%B6\"><span class=\"toc-text\">进程的控制</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%BF%9B%E7%A8%8B%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2\"><span class=\"toc-text\">进程的上下文切换</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%BA%BF%E7%A8%8B\"><span class=\"toc-text\">线程</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%BA%BF%E7%A8%8B%E4%B8%8E%E8%BF%9B%E7%A8%8B%E7%9A%84%E6%AF%94%E8%BE%83\"><span class=\"toc-text\">线程与进程的比较</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%BA%BF%E7%A8%8B%E7%9A%84%E4%B8%8A%E4%B8%8B%E6%96%87%E5%88%87%E6%8D%A2\"><span class=\"toc-text\">线程的上下文切换</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%BA%BF%E7%A8%8B%E7%9A%84%E5%AE%9E%E7%8E%B0\"><span class=\"toc-text\">线程的实现</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%94%A8%E6%88%B7%E7%BA%BF%E7%A8%8B\"><span class=\"toc-text\">用户线程</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%86%85%E6%A0%B8%E7%BA%BF%E7%A8%8B\"><span class=\"toc-text\">内核线程</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%BD%BB%E9%87%8F%E7%BA%A7%E8%BF%9B%E7%A8%8B\"><span class=\"toc-text\">轻量级进程</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%B0%83%E5%BA%A6\"><span class=\"toc-text\">调度</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%B0%83%E5%BA%A6%E6%97%B6%E6%9C%BA\"><span class=\"toc-text\">调度时机</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%B0%83%E5%BA%A6%E5%8E%9F%E5%88%99\"><span class=\"toc-text\">调度原则</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">调度算法</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%85%88%E6%9D%A5%E5%85%88%E6%9C%8D%E5%8A%A1%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">先来先服务调度算法</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%9C%80%E7%9F%AD%E4%BD%9C%E4%B8%9A%E4%BC%98%E5%85%88%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">最短作业优先调度算法</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E9%AB%98%E5%93%8D%E5%BA%94%E6%AF%94%E4%BC%98%E5%85%88%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">高响应比优先调度算法</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%97%B6%E9%97%B4%E7%89%87%E8%BD%AE%E8%BD%AC%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">时间片轮转调度算法</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%9C%80%E9%AB%98%E4%BC%98%E5%85%88%E7%BA%A7%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">最高优先级调度算法</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%A4%9A%E7%BA%A7%E5%8F%8D%E9%A6%88%E9%98%9F%E5%88%97%E8%B0%83%E5%BA%A6%E7%AE%97%E6%B3%95\"><span class=\"toc-text\">多级反馈队列调度算法</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1\"><span class=\"toc-text\">进程间通信</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AE%A1%E9%81%93\"><span class=\"toc-text\">管道</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97\"><span class=\"toc-text\">消息队列</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98\"><span class=\"toc-text\">共享内存</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BF%A1%E5%8F%B7%E9%87%8F\"><span class=\"toc-text\">信号量</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BF%A1%E5%8F%B7\"><span class=\"toc-text\">信号</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Socket\"><span class=\"toc-text\">Socket</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E9%92%88%E5%AF%B9-TCP-%E5%8D%8F%E8%AE%AE%E9%80%9A%E4%BF%A1%E7%9A%84-socket-%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">针对 TCP 协议通信的 socket 编程模型</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E9%92%88%E5%AF%B9-UDP-%E5%8D%8F%E8%AE%AE%E9%80%9A%E4%BF%A1%E7%9A%84-socket-%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">针对 UDP 协议通信的 socket 编程模型</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E9%92%88%E5%AF%B9%E6%9C%AC%E5%9C%B0%E8%BF%9B%E7%A8%8B%E9%97%B4%E9%80%9A%E4%BF%A1%E7%9A%84-socket-%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">针对本地进程间通信的 socket 编程模型</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%86%B2%E7%AA%81\"><span class=\"toc-text\">多线程冲突</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AB%9E%E4%BA%89%E4%B8%8E%E5%8D%8F%E4%BD%9C\"><span class=\"toc-text\">竞争与协作</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E4%BA%92%E6%96%A5\"><span class=\"toc-text\">互斥</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%90%8C%E6%AD%A5%E7%9A%84%E6%A6%82%E5%BF%B5\"><span class=\"toc-text\">同步的概念</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E4%BA%92%E6%96%A5%E4%B8%8E%E5%90%8C%E6%AD%A5%E7%9A%84%E5%AE%9E%E7%8E%B0\"><span class=\"toc-text\">互斥与同步的实现</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%94%81\"><span class=\"toc-text\">锁</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%BF%99%E7%AD%89%E5%BE%85%E9%94%81\"><span class=\"toc-text\">忙等待锁</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%97%A0%E7%AD%89%E5%BE%85%E9%94%81\"><span class=\"toc-text\">无等待锁</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BF%A1%E5%8F%B7%E9%87%8F-1\"><span class=\"toc-text\">信号量</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%AD%BB%E9%94%81\"><span class=\"toc-text\">死锁</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%88%A9%E7%94%A8%E5%B7%A5%E5%85%B7%E6%8E%92%E6%9F%A5%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98\"><span class=\"toc-text\">利用工具排查死锁问题</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E9%81%BF%E5%85%8D%E6%AD%BB%E9%94%81%E9%97%AE%E9%A2%98%E7%9A%84%E5%8F%91%E7%94%9F\"><span class=\"toc-text\">避免死锁问题的发生</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BA%92%E6%96%A5%E9%94%81%E4%B8%8E%E8%87%AA%E6%97%8B%E9%94%81\"><span class=\"toc-text\">互斥锁与自旋锁</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%AF%BB%E5%86%99%E9%94%81\"><span class=\"toc-text\">读写锁</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%B9%90%E8%A7%82%E9%94%81%E4%B8%8E%E6%82%B2%E8%A7%82%E9%94%81\"><span class=\"toc-text\">乐观锁与悲观锁</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E7%BD%91%E7%BB%9C%E7%B3%BB%E7%BB%9F\"><span class=\"toc-text\">网络系统</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%9B%B6%E6%8B%B7%E8%B4%9D\"><span class=\"toc-text\">零拷贝</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#DMA%E6%8A%80%E6%9C%AF\"><span class=\"toc-text\">DMA技术</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BC%A0%E7%BB%9F%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93\"><span class=\"toc-text\">传统文件传输</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BC%A0%E8%BE%93%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96\"><span class=\"toc-text\">传输性能优化</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%9B%B6%E6%8B%B7%E8%B4%9D%E5%AE%9E%E7%8E%B0\"><span class=\"toc-text\">零拷贝实现</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#mmap-write\"><span class=\"toc-text\">mmap + write</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#sendfile\"><span class=\"toc-text\">sendfile</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#PageCache\"><span class=\"toc-text\">PageCache</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%A4%A7%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E6%96%B9%E5%BC%8F\"><span class=\"toc-text\">大文件传输方式</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#I-x2F-O-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8\"><span class=\"toc-text\">I&#x2F;O 多路复用</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Socket-%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">Socket 模型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%96%87%E4%BB%B6%E6%8F%8F%E8%BF%B0%E7%AC%A6\"><span class=\"toc-text\">*文件描述符</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%A4%9A%E8%BF%9B%E7%A8%8B%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">多进程模型</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%83%B5%E5%B0%B8%E8%BF%9B%E7%A8%8B\"><span class=\"toc-text\">僵尸进程</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%A4%9A%E7%BA%BF%E7%A8%8B%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">多线程模型</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#I-x2F-O-%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8-1\"><span class=\"toc-text\">I&#x2F;O 多路复用</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#select-x2F-poll\"><span class=\"toc-text\">select&#x2F;poll</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#epoll\"><span class=\"toc-text\">epoll</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%AB%98%E6%80%A7%E8%83%BD%E7%BD%91%E7%BB%9C%E6%A8%A1%E5%BC%8F\"><span class=\"toc-text\">高性能网络模式</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Reactor\"><span class=\"toc-text\">Reactor</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%8D%95-Reactor-%E5%8D%95%E8%BF%9B%E7%A8%8B-x2F-%E7%BA%BF%E7%A8%8B\"><span class=\"toc-text\">单 Reactor 单进程 &#x2F; 线程</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%8D%95-Reactor-%E5%A4%9A%E7%BA%BF%E7%A8%8B-x2F-%E5%A4%9A%E8%BF%9B%E7%A8%8B\"><span class=\"toc-text\">单 Reactor 多线程 &#x2F; 多进程</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%A4%9A-Reactor-%E5%A4%9A%E8%BF%9B%E7%A8%8B-x2F-%E7%BA%BF%E7%A8%8B\"><span class=\"toc-text\">多 Reactor 多进程 &#x2F; 线程</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Proactor\"><span class=\"toc-text\">Proactor</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%B8%80%E8%87%B4%E6%80%A7%E5%93%88%E5%B8%8C\"><span class=\"toc-text\">一致性哈希</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%AD%98%E5%9C%A8%E7%9A%84%E9%97%AE%E9%A2%98\"><span class=\"toc-text\">存在的问题</span></a></li></ol></li></ol></li></ol>","author":{"name":"依水何安","slug":"blog-author","avatar":"/img/123.png","link":"/","description":"一个抽象的码农","socials":{"github":"https://github.com/jankin12138","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/img/bilibili.png","link":"https://space.bilibili.com/14624621?spm_id_from=333.1007.0.0"},"leetcode":{"icon":"/img/leetcode.png","link":"https://leetcode.cn/u/yi-shui-he-an-o/"}}}},"mapped":true,"prev_post":{"title":"WebServer项目笔记","uid":"2acfbdc0062c0ef1a792fc0d6a402d2c","slug":"WebServer项目笔记","date":"2022-10-27T07:02:29.000Z","updated":"2022-11-01T13:57:56.278Z","comments":true,"path":"api/articles/WebServer项目笔记.json","keywords":null,"cover":"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20221027152042.6kolkbovop40.webp","text":" 使用C++编写的Liunx系统下的支持多并发的网络服务器，包含Mysql后端和使用 线程池 + 非阻塞socket + epoll(ET和LT均实现) + 事件处理(Reactor和模拟Proactor均实现) 的并发模型，能够使用状态机解析HTTP请求报文，并且实现了同步&#...","link":"","photos":[],"count_time":{"symbolsCount":"2.6k","symbolsTime":"2 mins."},"categories":[{"name":"WebServer","slug":"WebServer","count":1,"path":"api/categories/WebServer.json"}],"tags":[{"name":"网络编程","slug":"网络编程","count":1,"path":"api/tags/网络编程.json"},{"name":"多并发实现","slug":"多并发实现","count":1,"path":"api/tags/多并发实现.json"}],"author":{"name":"依水何安","slug":"blog-author","avatar":"/img/123.png","link":"/","description":"一个抽象的码农","socials":{"github":"https://github.com/jankin12138","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/img/bilibili.png","link":"https://space.bilibili.com/14624621?spm_id_from=333.1007.0.0"},"leetcode":{"icon":"/img/leetcode.png","link":"https://leetcode.cn/u/yi-shui-he-an-o/"}}}}},"next_post":{"title":"计算机网络笔记","uid":"09f2766bd638543cf5a9ec60a938ae77","slug":"计算机网络笔记","date":"2022-10-19T13:57:03.000Z","updated":"2022-11-05T13:56:03.451Z","comments":true,"path":"api/articles/计算机网络笔记.json","keywords":null,"cover":"https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/QQ截图20221019220156.4lypoz67vm60.webp","text":" 本文参考了小林coding以及自顶向下方法等计算机网络教程，写了一篇个人的笔记，其中也包含了本人对于一些小问题的记录和思考，以及整体框架的梳理。 基础知识 对于不同设备间的通信就需要使用网络通信，而设备是多样性的，所以要兼容设备就需要一套通用的网络协议 TCP&#x2F;IP网...","link":"","photos":[],"count_time":{"symbolsCount":"61k","symbolsTime":"56 mins."},"categories":[{"name":"计算机网络","slug":"计算机网络","count":1,"path":"api/categories/计算机网络.json"}],"tags":[{"name":"计算机网络","slug":"计算机网络","count":2,"path":"api/tags/计算机网络.json"},{"name":"基础知识","slug":"基础知识","count":2,"path":"api/tags/基础知识.json"}],"author":{"name":"依水何安","slug":"blog-author","avatar":"/img/123.png","link":"/","description":"一个抽象的码农","socials":{"github":"https://github.com/jankin12138","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"","juejin":"","customs":{"bilibili":{"icon":"/img/bilibili.png","link":"https://space.bilibili.com/14624621?spm_id_from=333.1007.0.0"},"leetcode":{"icon":"/img/leetcode.png","link":"https://leetcode.cn/u/yi-shui-he-an-o/"}}}}}}