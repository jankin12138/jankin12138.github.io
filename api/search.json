[{"id":"3a6ede6b218bb998a3581eebea1dfc3d","title":"事务隔离","content":"\n\n\n\n\n\n\n\n\n之前在字节青训营因为大作业的相关内容也接触过一些数据库方向的知识，但一直苦于没有系统性的学习和整理，所以这系列文章来总结和记录一些，个人觉得比较重要的内容，以便以后复习使用。主要参考文章是极客时间的MySQL45讲：MySQL 实战 45 讲 这次主要是事务和索引方面的内容，感觉写在一起太长了也不方便记录所以分成几个部分来写，如果后续觉得不方便查阅可能会合并。\n事务隔离\n\n\n\n\n\n\n\n\n简单来说，事务是由一条SQL语句，或者一组SQL语句组成的程序执行单元，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。\n\n支付举例\n最经典的例子就是转账，你要给朋友小王转 100 块钱，而此时你的银行卡只有 100 块钱。转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这 100 块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账。因此事务的作用就是保证一组数据库操作保持一致。\n\n\n隔离性\n\n\n\n\n\n\n\n\nACDI事务四大特性\n1.原子性（Atomicity）：指事务内所有操作要么一起执行成功，要么都一起失败(或者说是回滚)；如事务经典转账案例：A给B转账，A把钱扣了，但B没有收到；可见这种错误是不能接受的，最终会回滚，这也是原子性的重要性。\n2.一致性（Consistency）：指事务执行前后的状态一致，如事务经典转账案例：A给B互相转账，不管怎么转，最终两者钱的总和还是不变。\n3.持久性（Durability）：事务一旦提交，数据就已经永久保存了，不能再回滚。\n4.隔离性（Isolation）：指多个并发事务之间的操作互不干扰，但是事务的并发可能会导致数据脏读、不可重复读、幻读问题，根据业务情况，采用事务隔离级别进行对应数据读问题处理。\n隔离级别\n\n\n\n\n\n\n\n\nSQL 标准定义了四种隔离级别，MySQL 全都支持。这4种隔离级别，并行性能依次降低，安全性依次提高：\n\n读未提交（READ UNCOMMITTED）一个事务还没提交时，它做的变更就能被别的事务看到.\n读已提交 （READ COMMITTED）一个事务提交之后，它做的变更才会被其他事务看到。\n可重复读 （REPEATABLE READ）一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n串行化 （SERIALIZABLE）顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n\n视图实现\n在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n\n在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。\n\n在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。\n\n“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；\n\n“串行化”隔离级别下直接用加锁的方式来避免并行访问。\n\n\n\n\n\n可重复读场景\n假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。\n这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。\n\n\n事务隔离实现\n\n\n\n\n\n\n\n\n在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。当系统里没有比这个回滚日志更早的 read-view 的时候，系统会判断没有事务再需要用到这些回滚日志，此时回滚日志会被删除。\n\n\n\n\n\n\n提示\n尽量不要使用长业务\n\n\n长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。\n在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。\n事物的启动方式MySQL 的事务启动方式有以下几种：\n\n显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。\nset autocommit&#x3D;0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。\n\n\n\n\n\n\n\n\n注意\n有些客户端连接框架会默认连接成功后先执行一个 set autocommit&#x3D;0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。\n因此，建议总是使用 set autocommit&#x3D;1, 通过显式语句的方式来启动事务。\n\n\n\n\n\n\n\n\nQuestion\n现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？\n\n\n\nAnswer\n首先，从应用开发端来看：\n\n确认是否使用了 set autocommit&#x3D;0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。\n确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin&#x2F;commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。\n业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）\n\n其次，从数据库端来看：\n\n监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 &#x2F; 或者 kill；\nPercona 的 pt-kill 这个工具不错，推荐使用；\n在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；\n如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。\n\n\n\n","slug":"事务隔离","date":"2022-08-31T12:22:15.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"},{"id":"77b268d8a20b2f9b34be681cdfe52894","title":"MySQL框架&日志系统","content":"\n\n\n\n\n\n\n\n\n之前在字节青训营因为大作业的相关内容也接触过一些数据库方向的知识，但一直苦于没有系统性的学习和整理，所以这系列文章来总结和记录一些，个人觉得比较重要的内容，以便以后复习使用。主要参考文章是极客时间的MySQL45讲：MySQL 实战 45 讲 \nMySQL框架\n\n\n\n连接器\n\n\n\n\n\n\n\n\n连接器负责跟客户端建立链接、获取权限、维持和管理链接。常见的连接命令为：\n&gt;mysql -h$ip -P$port -u$user -p\n连接器在完成连接操作之后会进入Sleep状态表示空闲连接，而wait_timeout参数可以控制连接器自动断开的时间，一般默认为8小时。\n\n解决占用内存过多\n\n定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。\n如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n\n\n\n查询缓存\n\n\n\n\n\n\n\n\nMySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。\n查询缓存往往弊大于利，因为查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。\n分析器\n\n\n\n\n\n\n\n\n分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。\nMySQL 从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。\n做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。\n优化器\n\n\n\n\n\n\n\n\n优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。\n执行器\n\n\n\n\n\n\n\n\nMySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。\n执行器的业务逻辑一般为：\n\n验证权限\n调用引擎接口执行逻辑\n重复逻辑知道表的最后一行\n返回满足条件的的行记录作为结果返回给客户端\n\n\n查询日志\n你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。\n在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。\n\n\n日志系统mysql&gt; create table T(ID int primary key, c int);\n\n这是一条最常见的更新语句，例如我们现在要将ID&#x3D;2 这一行的值加 1，SQL 语句就会这么写：\nmysql&gt; update T set c&#x3D;c+1 where ID&#x3D;2;\n\n在上文中我们已经介绍了查询语句的流程,那么我们来整理一下更新语句的流程：\n\n连接连接器，验证权限\n分析器分析更新语句\n清空缓存结果\n优化器决定ID索引\n执行器执行更新\nredo log（重做日志）&amp; binlog（归档日志）\n\nredo log 重做日志\n\n\n\n\n\n\n\n\n在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了redo log来提升更新效率。\nMySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。下图为 redo log的示意图。\n\n\n\n\nnnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB。从头开始写，写到末尾就又回到开头循环写。\n\nredo log示意图详解\nwrite pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。\nwrite pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。\n\n\ncrash-safe\n\n\n\n\n\n\n\n\n有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。\nbinlog（归档日志）\n\n\n\n\n\n\n\n\n实际上，在框架中我们不难发现MySQL有一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。如果说redo log是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。\n仅仅依靠binlog只能完成归档服务而不能实现crash-safe 能力，因此 MySQL为了实现存储引擎的crash-safe 能力带来了另一套日志系统也就是redo log。这两种日志主要有以下三点不同：\n\nredo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。\nredo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。\nredo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n此时我们就可以总结执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程：\n\n执行器先找引擎取 ID&#x3D;2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID&#x3D;2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。\n执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。\n引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。\n执行器生成这个操作的 binlog，并把 binlog 写入磁盘。\n执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。\n\n两阶段提交\n\n\n\n\n\n\n\n\n仍然用前面的 update 语句来做例子。假设当前 ID&#x3D;2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？\n\n先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。\n先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。\n\n虽然表面上看起来，发生宕机的概率不高，但是在需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。\nredo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。\nsync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。只有持久化的存储才能保证数据一场重启之后不会丢失。\n\n\n\n\n\n\nQuestion\n定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？\n\n\n\nAnswer\n该问题主要取决于binlog的规模，一天一备的binlog规模较小，那么恢复到误删时刻的时间和成本自然也就越短，而一周一备虽然恢复时间较长，但是如果发现问题时距离误操作已经过去了好几天，那么也仍然可以恢复，也就是后悔的容错时间更长。因此可以一天一备或者短周期备份后，再额外全库备份一次，以防止意外的发生也比较兼顾。\n\n\n","slug":"MySQL框架","date":"2022-08-29T10:22:15.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"},{"id":"bc567916c4dc0d8169bd26d18e348d36","title":"test","content":"123123123\n","slug":"test","date":"2022-08-22T10:14:50.000Z","categories_index":"","tags_index":"","author_index":"依水何安"},{"id":"7695fb86b301b9dde860fa1e1e75b828","title":"123321","content":"1231231231\n","slug":"123321","date":"2022-09-02T10:22:09.000Z","categories_index":"","tags_index":"","author_index":"依水何安"}]