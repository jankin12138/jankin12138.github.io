[{"id":"e3447cde20e84ead44a473b80d153b14","title":"hexo+aurora+github+gitalk搭建属于自己的个人博客","content":"\n\n\n\n\n\n\n注意\n本文前八章来自于: 叁鄕浪子原作者写于2022年7月15日本人在基础上有所增加，并适当修改了章节顺序，配套的教学视频可在B站查看。\n\n\n成果展示 \n\n1 node js的安装及环境配置\n\n\n\n\n\n\n\n\n直接访问Node.js的官方网站下载即可\n安装可以无脑下一步，注意安装路径就行，不会有问题，如果不放心的话可以参考原文章的安装过程截图，有详细步骤，由于本文篇幅较长，这里就不再转载了。\n测试成功方法如下：\n\n\n打开windows终端（按下win+R输入cmd）\n\nnode -v\n\nnpm -v\n\n如果安装成功会出现版本号码，如下图所示:\n1.2 配置环境变量以管理员身份-打开cmd，配置路径\nnpm config set prefix \"E:\\develop\\nodejs\\node_global\"\n\nnpm config set cache \"E:\\develop\\nodejs\\node_cache\"\n\n修改全局路径 node_global\n修改缓存路径 node_cache内路径需要根据自己实际情况来进行修改\n\n\n\n\n\n\n\n注意\n修改全局安装路径后，需要在系统环境变量Path中添加该路径，否则之后使用npm install –global xxx，xxx都报错找不到命令。\n\n\n找到电脑环境配置\n\nwin10 &amp; win11：右键此电脑-属性-高级系统设置-高级-环境变量\nwin11 还可以：点设置-系统-关于-高级系统设置-高级-环境变量\n\n2 安装git2.1 下载git访问Git 找到首页下方的Downloads\n下载对应系统（MAC、Windows、Linux&#x2F;Unix）安装包\n\n\n\n\n\n\n\n特别注意\n想省事可以直接无脑 Next(下一步)，带 New(新)的新功能不要选就是了,如果想了解详细的安装过程可以参考文章顶部的原文。\n\n\n3 hexo 下载npm install hexo-cli -g #安装hexo\n\n\n\n\n\n\n\n\n\n\n中间如果出现各种报错，可以先不用管，重新运行上述代码，直至成功因为网络原因导致的报错占大部分（因为墙的问题，也可以适当的使用科技）\n4 检查安装\nnode:\n\nnode -v\n\n\n\nnpm:\n\nnpm -v\n\n\ngit:\n\ngit --version\n\n\nhexo:\n\nhexo -v\n\n\n安装成功后截图：\n\n\n5 创建仓库及配置SSH连接5.1 创建github仓库5.1参考视频教程\n利用github仓库，存放静态网站资源，达到挂载网站的目的。\n需要注意的是作为网站访问的这个仓库，仓库名称一定是，拥有者名+github.io\n5.2 生成ssh keys5.2参考视频教程\n在博客文件夹根目录下，右键，调用git bash here功能\n先输入ssh查看是否已经安装ssh，git默认有安装，如下图所示就是安装过了。\n\n本地生成ssh keys,注意这里的邮箱地址是你github的注册邮箱地址\nssh-keygen -t rsa -C \"邮箱地址\"\n\n\n\n在本地电脑中找到.ssh\n\n\n一般默认都是，C:\\Users\\用户名.ssh\\id_rsa.pub\n找到秘钥的位置，并用记事本打开，复制其内容 (ctrl+a全选，ctrl+c复制，ctrl+v粘贴)\n打开github，头像箭头，下拉选项setting（设置）-SSH与GPG keys -new ssh keys（新建ssh秘钥）,把在本地生成的秘钥内容粘贴至此秘钥处，标题可以随便取。\n\n为了后面流程，在github里顺便设置person access tokens（个人访问令牌）\n(与ssh选项同一列，下面选择Developer setting log -Generate new token)\n\n下面勾选权限，建议全部勾选\n点击生成，生成的序列号\n\n\n\n\n\n\n\n特别注意\n注意保存\n要保存（复制&#x2F;截图）下来在存在本地，他只显示一次，如果忘记了，还需要重新生成一次。\n\n\n测试ssh是否绑定成功（在git里操作）\nssh -T git@github.com\n\n\n6 搭建本地博客创建一个放置博客文件夹的文件，在里面启用git Bash here，这里也可以用vscode打开终端管理。\n\n\n初始化hexo\n\nhexo init\n\n\n\n生成hexo本地页面\n\nhexo s\n\n\n\n复制粘贴该地址到浏览器中，即可访问本地搭建的博客 http://localhost=4000\n\nhexo cl #clean #清理编译文件\nhexo g #generate #编译项目\nhexo s #server #本地预览运行项目\n\n7 上传至本地博客至GitHub7.1 修改配置文件在创建博客文件夹的根目录下修改-config.yml文件\n\ndeploy:\n  type: git\n  repository: 你的github地址（就是你github.io那个仓库的地址）\n  branch: main\n\n7.2 安装hexo-deployer-git 自动部署发布工具npm install hexo-deployer-git --save\n\n7.3 编译文件生成页面hexo g\n\n7.4 本地文件上传到Githubhexo d\n\n\n\n\n\n\n\n提示\n在上传时，浏览器会跳出关于github的验证,要耐心等候\n\n\n\n输入用户名\n\n输入令牌\n\n\n(就是在github生成的那个，切记要保存)\n\n成功后可以直接访问http:&#x2F;&#x2F;你的用户名+.github.io访问\n\n8 安装Aurora主题\n\n\n\n\n\n\n\n\nAurora官方文档参考：https://aurora.tridiamond.tech/zh/guide\n8.1 配置npm install hexo-theme-aurora --save #进入hexo初始化目录用git执行\n\n\n因为主题是使用 NPM 或者 Yarn 安装的，而不是 clone 到 themes 文件夹的。\n所以我们需要自己创建一个配置文件。你只需要在 Hexo 博客的根目录下创建一个_config.aurora.yml 配置文件来配置主题\n此时打开配置文件发现是空的我们可以到node_modules下找到hexo-theme-aurora（.\\node_modules\\hexo-theme-aurora_config.yml），将改文件内容复制到根目录下的_config.aurora.yml。\n\n8.2 修改配置打开_comfig.yml\n由默认主题改为Aurora\n\n\n由于Aurora是vue3项目\n打开根目录下的_config.yml\n修改路由方式\n\n运行\nhexo clean &amp; hexo g &amp; hexo server\n\n\n8.3 上传并覆盖GitHub仓库hexo d\n\n打开仓库地址 主题配置成功\n\n9 参考教程\n\n\n\n\n\n\n\n\n【2021最新版】保姆级Hexo+github搭建个人博客\nHexo博客+Aurora主题安装与配置_神秘布偶猫\nhexo+aurora+github搭建 | 致彩之镜 (sxlz.me)\nAurora主题安装\nhexo+github搭建个人博客\n博客搭建日志\nAurora主题官方文档\n","slug":"hexo-aurora-github搭建属于自己的个人博客","date":"2022-09-27T09:48:24.000Z","categories_index":"技术教程","tags_index":"hexo,博客搭建","author_index":"依水何安"},{"id":"e7ec4f0245ca61bcdc5ddc21332c4d05","title":"MySQL高可用","content":"MySQL 主备的基本原理\n\n\n\n在状态 1 中，客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据是相同的。\n当需要切换的时候，就切成状态 2。这时候客户端读写访问的都是节点 B，而节点 A 是 B 的备库。\n在状态 1 中，虽然节点 B 没有被直接访问，但是我依然建议你把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：\n\n有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；\n防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；\n可以用 readonly 状态，来判断节点的角色。\n\n备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：\n\n在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。\n在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。\n主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。\n备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。\nsql_thread 读取中转日志，解析出日志里的命令，并执行。\n\nbinlog 的三种格式对比statement 格式\n\n\n\n\n第一行 SET @@SESSION.GTID_NEXT&#x3D;’ANONYMOUS’\n第二行是一个 BEGIN，跟第四行的 commit 对应，表示中间是一个事务；\n第三行就是真实执行的语句了。可以看到，在真实执行的 delete 命令之前，还有一个“use ‘test’”命令。这条命令不是我们主动执行的，而是 MySQL 根据当前要操作的表所在的数据库，自行添加的。这样做可以保证日志传到备库去执行的时候，不论当前的工作线程在哪个库里，都能够正确地更新到 test 库的表 t。use ‘test’命令之后的 delete 语句，就是我们输入的 SQL 原文了。可以看到，binlog“忠实”地记录了 SQL 命令，甚至连注释也一并记录了。\n最后一行是一个 COMMIT。你可以看到里面写着 xid&#x3D;61。是用来决定binlog是否完整的。\n\n\n\n\n\n\n\n\n注意\n可以看到，运行这条 delete 命令产生了一个 warning，原因是当前 binlog 设置的是 statement 格式，并且语句中有 limit，所以这个命令可能是 unsafe 的。\n为什么这么说呢？这是因为 delete 带 limit，很可能会出现主备数据不一致的情况。比如上面这个例子：\n\n如果 delete 语句使用的是索引 a，那么会根据索引 a 找到第一个满足条件的行，也就是说删除的是 a&#x3D;4 这一行；\n但如果使用的是索引 t_modified，那么删除的就是 t_modified&#x3D;’2018-11-09’也就是 a&#x3D;5 这一行。\n\n由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的。\n\n\nrow格式\n\n\n\n可以看到，与 statement 格式的 binlog 相比，前后的 BEGIN 和 COMMIT 是一样的。但是，row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。\n\nTable_map event，用于说明接下来要操作的表是 test 库的表 t;\nDelete_rows event，用于定义删除的行为。\n\n\n\n\n\n从这个图中，我们可以看到以下几个信息：\n\nserver id 1，表示这个事务是在 server_id&#x3D;1 的这个库上执行的。\n每个 event 都有 CRC32 的值，这是因为我把参数 binlog_checksum 设置成了 CRC32。\nTable_map event 跟在图 5 中看到的相同，显示了接下来要打开的表，map 到数字 226。现在我们这条 SQL 语句只操作了一张表，如果要操作多张表呢？每个表都有一个对应的 Table_map event、都会 map 到一个单独的数字，用于区分对不同表的操作。\n我们在 mysqlbinlog 的命令中，使用了 -vv 参数是为了把内容都解析出来，所以从结果里面可以看到各个字段的值（比如，@1&#x3D;4、 @2&#x3D;4 这些值）。\nbinlog_row_image 的默认配置是 FULL，因此 Delete_event 里面，包含了删掉的行的所有字段的值。如果把 binlog_row_image 设置为 MINIMAL，则只会记录必要的信息，在这个例子里，就是只会记录 id&#x3D;4 这个信息。\n最后的 Xid event，用于表示事务被正确地提交了。\n\n你可以看到，当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id&#x3D;4 的行，不会有主备删除不同行的问题。\nmixed格式为什么会有 mixed 这种 binlog 格式的存在场景？推论过程是这样的：\n\n因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。\n但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。\n所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。\n\n\n\n\n\n\n\n\n\n\n也就是说，mixed 格式可以利用 statment 格式的优点，同时又避免了数据不一致的风险。\n循环复制问题双 M 结构还有一个问题需要解决。\n业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（我建议你把参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog）。\n那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。这个要怎么解决呢？\n从上面的图 6 中可以看到，MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题：\n\n规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；\n一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；\n每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。\n\n按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样：\n\n从节点 A 更新的事务，binlog 里面记的都是 A 的 server id；\n传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id；\n再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。\n\nMySQL高可用主备延迟主备切换可能是一个主动运维动作，比如软件升级、主库所在机器按计划下线等，也可能是被动操作，比如主库所在机器掉电。\n接下来，我们先一起看看主动切换的场景。\n在介绍主动切换流程的详细步骤之前，我要先跟你说明一个概念，即“同步延迟”。与数据同步有关的时间点主要包括以下三个：\n\n主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;\n之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;\n备库 B 执行完成这个事务，我们把这个时刻记为 T3。\n\n所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。\n你可以在备库上执行 show slave status 命令，它的返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒。\nseconds_behind_master 的计算方法是这样的：\n\n每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间；\n备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master。\n\n可以看到，其实 seconds_behind_master 这个参数计算的就是 T3-T1。所以，我们可以用 seconds_behind_master 来作为主备延迟的值，这个值的时间精度是秒。\n\n\n\n\n\n\n\n\n\n主备延迟的来源\n首先，有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。\n一般情况下，有人这么部署时的想法是，反正备库没有请求，所以可以用差一点儿的机器。或者，他们会把 20 个主库放在 4 台机器上，而把备库集中在一台机器上。\n第二种常见的可能了，即备库的压力大。\n般的想法是，主库既然提供了写能力，那么备库可以提供一些读能力。或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在备库上跑。\n这种情况，我们一般可以这么处理：\n\n一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。\n通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。\n\n这就是第三种可能了，即大事务。\n可靠性优先策略在双 M 结构下，从状态 1 到状态 2 切换的详细过程是这样的：\n\n判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；\n把主库 A 改成只读状态，即把 readonly 设置为 true；\n判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；\n把备库 B 改成可读写状态，也就是把 readonly 设置为 false；\n把业务请求切到备库 B。\n\n可以看到，这个切换流程中是有不可用时间的。因为在步骤 2 之后，主库 A 和备库 B 都处于 readonly 状态，也就是说这时系统处于不可写状态，直到步骤 5 完成后才能恢复。\n在这个不可用状态中，比较耗费时间的是步骤 3，可能需要耗费好几秒的时间。这也是为什么需要在步骤 1 先做判断，确保 seconds_behind_master 的值足够小。\n试想如果一开始主备延迟就长达 30 分钟，而不先做判断直接切换的话，系统的不可用时间就会长达 30 分钟，这种情况一般业务都是不可接受的。\n按照可靠性优先的思路，异常切换会是什么效果？\n假设，主库 A 和备库 B 间的主备延迟是 30 分钟，这时候主库 A 掉电了，HA 系统要切换 B 作为主库。我们在主动切换的时候，可以等到主备延迟小于 5 秒的时候再启动切换，但这时候已经别无选择了。\n采用可靠性优先策略的话，你就必须得等到备库 B 的 seconds_behind_master&#x3D;0 之后，才能切换。但现在的情况比刚刚更严重，并不是系统只读、不可写的问题了，而是系统处于完全不可用的状态。因为，主库 A 掉电后，我们的连接还没有切到备库 B。\n当然，系统的不可用时间，是由这个数据可靠性优先的策略决定的。你也可以选择可用性优先的策略，来把这个不可用时间几乎降为 0。\n可用性优先策略如果我强行把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了。\n我们把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。\n\n\n\n\n\n\n\n\n\nMySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。\n备库并行复制\n\n\n\n\n\n\n\n\n如果备库执行日志的速度持续低于主库生成日志的速度，那这个延迟就有可能成了小时级别。而且对于一个压力持续比较高的主库来说，备库很可能永远都追不上主库的节奏。\n\n\n\n\n\n\n\n注意\n在主库上，影响并发度的原因就是各种锁了。由于 InnoDB 引擎支持行锁，除了所有并发事务都在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的。所以，你在性能测试的时候会发现，并发压测线程 32 就比单线程时，总体吞吐量高。\n而日志在备库上的执行，就是图中备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟。\n\n\n\n\n\n\n在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。\n从单线程复制到最新版本的多线程复制，中间的演化经历了好几个版本。其实说到底，所有的多线程复制机制，都是要把上图中只有一个线程的 sql_thread，拆成多个线程，也就是都符合下面的这个模型：\n\n\n\n\ncoordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了 worker 线程。而 work 线程的个数，就是由参数 slave_parallel_workers 决定的。\n\n\n\n\n\n\n提示\n\n事务能不能按照轮询的方式分发给各个 worker，也就是第一个事务分给 worker_1，第二个事务发给 worker_2 呢？\n\n其实是不行的。因为，事务被分发给 worker 以后，不同的 worker 就独立执行了。但是，由于 CPU 的调度策略，很可能第二个事务最终比第一个事务先执行。而如果这时候刚好这两个事务更新的是同一行，也就意味着，同一行上的两个事务，在主库和备库上的执行顺序相反，会导致主备不一致的问题。\n\n同一个事务的多个更新语句，能不能分给不同的 worker 来执行呢？\n\n答案是，也不行。举个例子，一个事务更新了表 t1 和表 t2 中的各一行，如果这两条更新语句被分到不同 worker 的话，虽然最终的结果是主备一致的，但如果表 t1 执行完成的瞬间，备库上有一个查询，就会看到这个事务“更新了一半的结果”，破坏了事务逻辑的隔离性。\n\n\n所以，coordinator 在分发的时候，需要满足以下这两个基本要求：\n\n不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。\n同一个事务不能被拆开，必须放到同一个 worker 中。\n\n并行复制策略按表分发策略\n\n\n\n\n\n\n\n\n按表分发事务的基本思路是，如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个 worker 不会更新同一行。\n\n\n\n\n可以看到，每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。\n在有事务分配给 worker 时，事务里面涉及的表会被加到对应的 hash 表中。worker 执行完成后，这个表会被从 hash 表中去掉。hash_table_1 表示，现在 worker_1 的“待执行事务队列”里，有 4 个事务涉及到 db1.t1 表，有 1 个事务涉及到 db2.t2 表；hash_table_2 表示，现在 worker_2 中有一个事务会更新到表 t3 的数据。\n\n\n\n\n\n\n提示\n假设在图中的情况下，coordinator 从中转日志中读入一个新事务 T，这个事务修改的行涉及到表 t1 和 t3。\n现在我们用事务 T 的分配流程，来看一下分配规则。\n\n由于事务 T 中涉及修改表 t1，而 worker_1 队列中有事务在修改表 t1，事务 T 和队列中的某个事务要修改同一个表的数据，这种情况我们说事务 T 和 worker_1 是冲突的。\n按照这个逻辑，顺序判断事务 T 和每个 worker 队列的冲突关系，会发现事务 T 跟 worker_2 也冲突。\n事务 T 跟多于一个 worker 冲突，coordinator 线程就进入等待。\n每个 worker 继续执行，同时修改 hash_table。假设 hash_table_2 里面涉及到修改表 t3 的事务先执行完成，就会从 hash_table_2 中把 db1.t3 这一项去掉。\n这样 coordinator 会发现跟事务 T 冲突的 worker 只有 worker_1 了，因此就把它分配给 worker_1。\ncoordinator 继续读下一个中转日志，继续分配事务。\n\n\n\n\n\n\n\n\n\n提示\n也就是说，每个事务在分发的时候，跟所有 worker 的冲突关系包括以下三种情况：\n\n如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker;\n如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；\n如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker。\n\n\n\n按行分发策略\n\n\n\n\n\n\n\n\n要解决热点表的并行复制问题，就需要一个按行并行复制的方案。按行复制的核心思路是：如果两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求 binlog 格式必须是 row。\n这时候，我们判断一个事务 T 和 worker 是否冲突，用的就规则就不是“修改同一个表”，而是“修改同一行”。按行复制和按表复制的数据结构差不多，也是为每个 worker，分配一个 hash 表。只是要实现按行分发，这时候的 key，就必须是“库名 + 表名 + 唯一键的值”。\n\n\n\n\n\n\n\n注意\n基于行的策略，事务 hash 表中还需要考虑唯一键，即 key 应该是“库名 + 表名 + 索引 a 的名字 +a 的值”。\n因此，coordinator 在解析这个语句的 binlog 的时候，这个事务的 hash 表就有三个项:\n\nkey&#x3D;hash_func(db1+t1+“PRIMARY”+2), value&#x3D;2; 这里 value&#x3D;2 是因为修改前后的行 id 值不变，出现了两次。\nkey&#x3D;hash_func(db1+t1+“a”+2), value&#x3D;1，表示会影响到这个表 a&#x3D;2 的行。\nkey&#x3D;hash_func(db1+t1+“a”+1), value&#x3D;1，表示会影响到这个表 a&#x3D;1 的行。\n\n\n\n可见，相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。你可能也发现了，这两个方案其实都有一些约束条件：\n\n要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；\n表必须有主键；\n不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。\n\n对比按表分发和按行分发这两个方案的话，按行分发策略的并行度更高。不过，如果是要操作很多行的大事务的话，按行分发的策略有两个问题：\n\n耗费内存。比如一个语句要删除 100 万行数据，这时候 hash 表就要记录 100 万个项。\n耗费 CPU。解析 binlog，然后计算 hash 值，对于大事务，这个成本还是很高的。\n\n所以，在实现这个策略的时候会设置一个阈值，单个事务如果超过设置的行数阈值（比如，如果单个事务更新的行数超过 10 万行），就暂时退化为单线程模式，退化过程的逻辑大概是这样的：\n\ncoordinator 暂时先 hold 住这个事务；\n等待所有 worker 都执行完成，变成空队列；\ncoordinator 直接执行这个事务；\n恢复并行模式。\n\nMySQL 5.6 版本的并行复制策略官方 MySQL5.6 版本，支持了并行复制，只是支持的粒度是按库并行。理解了上面介绍的按表分发策略和按行分发策略，你就理解了，用于决定分发策略的 hash 表里，key 就是数据库名。\n这个策略的并行效果，取决于压力模型。如果在主库上有多个 DB，并且各个 DB 的压力均衡，使用这个策略的效果会很好。\n相比于按表和按行分发，这个策略有两个优势：\n\n构造 hash 值的时候很快，只需要库名；而且一个实例上 DB 数也不会很多，不会出现需要构造 100 万个项这种情况。\n不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。\n\n但是，如果你的主库上的表都放在同一个 DB 里面，这个策略就没有效果了；或者如果不同 DB 的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。\n理论上你可以创建不同的 DB，把相同热度的表均匀分到这些不同的 DB 中，强行使用这个策略。不过据我所知，由于需要特地移动数据，这个策略用得并不多。\nMariaDB 的并行复制策略redo log 组提交 (group commit) 优化， 而 MariaDB 的并行复制策略利用的就是这个特性：\n\n能够在同一组里提交的事务，一定不会修改同一行；\n主库上可以并行执行的事务，备库上也一定是可以并行执行的。\n\n在实现上，MariaDB 是这么做的：\n\n在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；\ncommit_id 直接写到 binlog 里面；\n传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；\n这一组全部执行完成后，coordinator 再去取下一批。\n\n当时，这个策略出来的时候是相当惊艳的。因为，之前业界的思路都是在“分析 binlog，并拆分到 worker”上。而 MariaDB 的这个策略，目标是“模拟主库的并行模式”。\n但是，这个策略有一个问题，它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的。\n可以看到，在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，这样系统的吞吐量就不够。\n另外，这个方案很容易被大事务拖后腿。假设 trx2 是一个超大事务，那么在备库应用的时候，trx1 和 trx3 执行完成后，就只能等 trx2 完全执行完成，下一组才能开始执行。这段时间，只有一个 worker 线程在工作，是对资源的浪费。\n不过即使如此，这个策略仍然是一个很漂亮的创新。因为，它对原系统的改造非常少，实现也很优雅。\nMySQL 5.7 的并行复制策略\n\n\n\n\n\n\n\n\n在 MariaDB 并行复制实现之后，官方的 MySQL5.7 版本也提供了类似的功能，由参数 slave-parallel-type 来控制并行复制策略：\n\n配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；\n配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。\n\n其实，不用等到 commit 阶段，只要能够到达 redo log prepare 阶段，就表示事务已经通过锁冲突的检验了。\n因此，MySQL 5.7 并行复制策略的思想是：\n\n同时处于 prepare 状态的事务，在备库执行时是可以并行的；\n处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。\n\nbinlog 的组提交的时候，介绍过两个参数：\n\nbinlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;\nbinlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。\n\n这两个参数是用于故意拉长 binlog 从 write 到 fsync 的时间，以此减少 binlog 的写盘次数。在 MySQL 5.7 的并行复制策略里，它们可以用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度。\n也就是说，这两个参数，既可以“故意”让主库提交得慢些，又可以让备库执行得快些。在 MySQL 5.7 处理备库延迟的时候，可以考虑调整这两个参数值，来达到提升备库复制并发度的目的。\nMySQL 5.7.22 的并行复制策略在 2018 年 4 月份发布的 MySQL 5.7.22 版本里，MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。\n相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。\n\nCOMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。\nWRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。\nWRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。\n\n当然为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。\n一主多从切换\n\n\n\n\n\n\n\n图中，虚线箭头表示的是主备关系，也就是 A 和 A’互为主备， 从库 B、C、D 指向的是主库 A。一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。\n相比于一主一备的切换流程，一主多从结构在切换完成后，A’会成为新的主库，从库 B、C、D 也要改接到 A’。正是由于多了从库 B、C、D 重新指向的这个过程，所以主备切换的复杂性也相应增加了。\n基于位点的主备切换这里，我们需要先来回顾一个知识点。\n当我们把节点 B 设置成节点 A’的从库的时候，需要执行一条 change master 命令：\nCHANGE MASTER TO \nMASTER_HOST&#x3D;$host_name \nMASTER_PORT&#x3D;$port \nMASTER_USER&#x3D;$user_name \nMASTER_PASSWORD&#x3D;$password \nMASTER_LOG_FILE&#x3D;$master_log_name \nMASTER_LOG_POS&#x3D;$master_log_pos  \n\n这条命令有这么 6 个参数：\n\nMASTER_HOST、MASTER_PORT、MASTER_USER 和 MASTER_PASSWORD 四个参数，分别代表了主库 A’的 IP、端口、用户名和密码。\n最后两个参数 MASTER_LOG_FILE 和 MASTER_LOG_POS 表示，要从主库的 master_log_name 文件的 master_log_pos 这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。\n\n那么，这里就有一个问题了，节点 B 要设置成 A’的从库，就要执行 change master 命令，就不可避免地要设置位点的这两个参数，但是这两个参数到底应该怎么设置呢？\n原来节点 B 是 A 的从库，本地记录的也是 A 的位点。但是相同的日志，A 的位点和 A’的位点是不同的。因此，从库 B 要切换的时候，就需要先经过“找同步位点”这个逻辑。\n考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库 B 上已经执行过的事务。\n一种取同步位点的方法是这样的：\n\n等待新主库 A’把中转日志（relay log）全部同步完成；\n在 A’上执行 show master status 命令，得到当前 A’上最新的 File 和 Position；\n取原主库 A 故障的时刻 T；\n用 mysqlbinlog 工具解析 A’的 File，得到 T 时刻的位点。\n\n\n\n\n\n\n\n提示\n通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。\n\n一种做法是，主动跳过一个事务。跳过命令的写法是：\n\nset global sql_slave_skip_counter&#x3D;1;\nstart slave;\n\n因为切换过程中，可能会不止重复执行一个事务，所以我们需要在从库 B 刚开始接到新主库 A’时，持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情况，以此来跳过可能涉及的所有事务。\n\n另外一种方式是，通过设置 slave_skip_errors 参数，直接设置跳过指定的错误。\n\n在执行主备切换时，有这么两类错误，是经常会遇到的：\n\n1062 错误是插入数据时唯一键冲突；\n1032 错误是删除数据时找不到行。\n\n因此，我们可以把 slave_skip_errors 设置为 “1032,1062”，这样中间碰到这两个错误时就直接跳过。\n这里需要注意的是，这种直接跳过指定错误的方法，针对的是主备切换时，由于找不到精确的同步位点，所以只能采用这种方法来创建从库和新主库的主备关系。\n这个背景是，我们很清楚在主备切换过程中，直接跳过 1032 和 1062 这两类错误是无损的，所以才可以这么设置 slave_skip_errors 参数。等到主备间的同步关系建立完成，并稳定执行一段时间之后，我们还需要把这个参数设置为空，以免之后真的出现了主从数据不一致，也跳过了。\n\n\nGTID\n\n\n\n\n\n\n\n\n通过 sql_slave_skip_counter 跳过事务和通过 slave_skip_errors 忽略错误的方法，虽然都最终可以建立从库 B 和新主库 A’的主备关系，但这两种操作都很复杂，而且容易出错。所以，MySQL 5.6 版本引入了 GTID，彻底解决了这个困难。\nGTID 的全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。它由两部分组成，格式是：\nGTID&#x3D;server_uuid:gno\n\n其中：\n\nserver_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值；\ngno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1。\n\n在 GTID 模式下，每个事务都会跟一个 GTID 一一对应。这个 GTID 有两种生成方式，而使用哪种方式取决于 session 变量 gtid_next 的值。\n\n如果 gtid_next&#x3D;automatic，代表使用默认值。这时，MySQL 就会把 server_uuid:gno 分配给这个事务。a. 记录 binlog 的时候，先记录一行 SET @@SESSION.GTID_NEXT&#x3D;‘server_uuid:gno’;b. 把这个 GTID 加入本实例的 GTID 集合。\n如果 gtid_next 是一个指定的 GTID 的值，比如通过 set gtid_next&#x3D;’current_gtid’指定为 current_gtid，那么就有两种可能：a. 如果 current_gtid 已经存在于实例的 GTID 集合中，接下来执行的这个事务会直接被系统忽略；b. 如果 current_gtid 没有存在于实例的 GTID 集合中，就将这个 current_gtid 分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的 GTID，因此 gno 也不用加 1。\n\n\n\n\n\n\n\n\n注意\n注意，一个 current_gtid 只能给一个事务使用。这个事务提交后，如果要执行下一个事务，就要执行 set 命令，把 gtid_next 设置成另外一个 gtid 或者 automatic。\n\n\n基于 GTID 的主备切换我们在实例 B 上执行 start slave 命令，取 binlog 的逻辑是这样的：\n\n实例 B 指定主库 A’，基于主备协议建立连接。\n实例 B 把 set_b 发给主库 A’。\n实例 A’算出 set_a 与 set_b 的差集，也就是所有存在于 set_a，但是不存在于 set_b 的 GTID 的集合，判断 A’本地是否包含了这个差集需要的所有 binlog 事务。a. 如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误；b. 如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B；\n之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行。\n\n其实，这个逻辑里面包含了一个设计思想：在基于 GTID 的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。因此，如果实例 B 需要的日志已经不存在，A’就拒绝把日志发给 B。\nGTID 和在线 DDL\n\n\n\n\n\n\n\n\n如果是由于索引缺失引起的性能问题，我们可以通过在线加索引来解决。但是，考虑到要避免新增索引对主库性能造成的影响，我们可以先在备库加索引，然后再切换。\n假设，这两个互为主备关系的库还是实例 X 和实例 Y，且当前主库是 X，并且都打开了 GTID 模式。这时的主备切换流程可以变成下面这样：\n\n在实例 X 上执行 stop slave。\n在实例 Y 上执行 DDL 语句。注意，这里并不需要关闭 binlog。\n执行完成后，查出这个 DDL 语句对应的 GTID，并记为 server_uuid_of_Y:gno。\n\n读写分离架构接下来，就看一下客户端直连和带 proxy 的读写分离架构，各有哪些特点。\n\n客户端直连方案，因为少了一层 proxy 转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便。但是这种方案，由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。你可能会觉得这样客户端也太麻烦了，信息大量冗余，架构很丑。其实也未必，一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如 Zookeeper，尽量让业务端只专注于业务逻辑开发。\n带 proxy 的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由 proxy 完成的。但这样的话，对后端维护团队的要求会更高。而且，proxy 也需要有高可用架构。因此，带 proxy 架构的整体就相对比较复杂。\n\n由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。\n这种“在从库上会读到系统的一个过期状态”的现象，在这篇文章里，我们暂且称之为“过期读”。\n前面我们说过了几种可能导致主备延迟的原因，以及对应的优化策略，但是主从延迟还是不能 100% 避免的。\n不论哪种结构，客户端都希望查询从库的数据结果，跟查主库的数据结果是一样的。\n这些方案包括：\n\n强制走主库方案；\nsleep 方案；\n判断主备无延迟方案；\n配合 semi-sync 方案；\n等主库位点方案；\n等 GTID 方案。\n\n强制走主库方案强制走主库方案其实就是，将查询请求做分类。通常情况下，我们可以将查询请求分为这么两类：\n\n对于必须要拿到最新结果的请求，强制将其发到主库上。比如，在一个交易平台上，卖家发布商品以后，马上要返回主页面，看商品是否发布成功。那么，这个请求需要拿到最新的结果，就必须走主库。\n对于可以读到旧数据的请求，才将其发到从库上。在这个交易平台上，买家来逛商铺页面，就算晚几秒看到最新发布的商品，也是可以接受的。那么，这类请求就可以走从库。\n\n你可能会说，这个方案是不是有点畏难和取巧的意思，但其实这个方案是用得最多的。\n当然，这个方案最大的问题在于，有时候你会碰到“所有查询都不能是过期读”的需求，比如一些金融类的业务。这样的话，你就要放弃读写分离，所有读写压力都在主库，等同于放弃了扩展性。\nSleep 方案主库更新后，读从库之前先 sleep 一下。具体的方案就是，类似于执行一条 select sleep(1) 命令。\n这个方案的假设是，大多数情况下主备延迟在 1 秒之内，做一个 sleep 可以有很大概率拿到最新的数据。\n这个方案给你的第一感觉，很可能是不靠谱儿，应该不会有人用吧？并且，你还可能会说，直接在发起查询时先执行一条 sleep 语句，用户体验很不友好啊。\n但，这个思路确实可以在一定程度上解决问题。为了看起来更靠谱儿，我们可以换一种方式。\n以卖家发布商品为例，商品发布后，用 Ajax（Asynchronous JavaScript + XML，异步 JavaScript 和 XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。\n这样，卖家就可以通过这个显示，来确认产品已经发布成功了。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了 sleep 的目的，进而也就解决了过期读的问题。\n\n\n\n\n\n\n\n注意\n也就是说，这个 sleep 方案确实解决了类似场景下的过期读问题。但，从严格意义上来说，这个方案存在的问题就是不精确。这个不精确包含了两层意思：\n\n如果这个查询请求本来 0.5 秒就可以在从库上拿到正确结果，也会等 1 秒；\n如果延迟超过 1 秒，还是会出现过期读。\n\n\n\n判断主备无延迟方案要确保备库无延迟，通常有三种做法。\n\n第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断 seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求。\n\nseconds_behind_master 的单位是秒，如果你觉得精度不够的话，还可以采用对比位点和 GTID 的方法来确保主备无延迟，也就是我们接下来要说的第二和第三种方法。\n第二种方法，对比位点确保主备无延迟：\n\nMaster_Log_File 和 Read_Master_Log_Pos，表示的是读到的主库的最新位点；\nRelay_Master_Log_File 和 Exec_Master_Log_Pos，表示的是备库执行的最新位点。\n\n如果 Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和 Exec_Master_Log_Pos 这两组值完全相同，就表示接收到的日志已经同步完成。\n第三种方法，对比 GTID 集合确保主备无延迟：\n\nAuto_Position&#x3D;1 ，表示这对主备关系使用了 GTID 协议。\nRetrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；\nExecuted_Gtid_Set，是备库所有已经执行完成的 GTID 集合。\n\n如果这两个集合相同，也表示备库接收到的日志都已经同步完成。\n可见，对比位点和对比 GTID 这两种方法，都要比判断 seconds_behind_master 是否为 0 更准确。\n\n\n\n\n\n\n\n特别注意\n我们上面判断主备无延迟的逻辑，是“备库收到的日志都执行完成了”。但是，从 binlog 在主备之间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。\n\n\n配合 semi-sync\n要解决这个问题，就要引入半同步复制，也就是 semi-sync replication。\nsemi-sync 做了这样的设计：\n\n事务提交的时候，主库把 binlog 发给从库；\n从库收到 binlog 以后，发回给主库一个 ack，表示收到了；\n主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。\n\n也就是说，如果启用了 semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。\n其实，判断同步位点的方案还有另外一个潜在的问题，即：如果在业务更新的高峰期，主库的位点或者 GTID 集合更新很快，那么上面的两个位点等值判断就会一直不成立，很可能出现从库上迟迟无法响应查询请求的情况。\n实际上，回到我们最初的业务逻辑里，当发起一个查询请求以后，我们要得到准确的结果，其实并不需要等到“主备完全同步”。\n\n\n\n\n备库 B 一直到状态 4 都和主库 A 存在延迟，如果用上面必须等到无延迟才能查询的方案，select 语句直到状态 4 都不能被执行。\n但是，其实客户端是在发完 trx1 更新后发起的 select 语句，我们只需要确保 trx1 已经执行完成就可以执行 select 语句了。也就是说，如果在状态 3 执行查询请求，得到的就是预期结果了。\n到这里，我们小结一下，semi-sync 配合判断主备无延迟的方案，存在两个问题：\n\n一主多从的时候，在某些从库执行查询请求会存在过期读的现象；\n在持续延迟的情况下，可能出现过度等待的问题。\n\n等主库位点方案要理解等主库位点方案，需要知道这样一条命令：\nselect master_pos_wait(file, pos[, timeout]);\n\n这条命令的逻辑如下：\n\n它是在从库执行的；\n参数 file 和 pos 指的是主库上的文件名和位置；\ntimeout 可选，设置为正整数 N 表示这个函数最多等待 N 秒。\n\n这个命令正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。\n当然，除了正常返回一个正整数 M 外，这条命令还会返回一些其他结果，包括：\n\n如果执行期间，备库同步线程发生异常，则返回 NULL；\n如果等待超过 N 秒，就返回 -1；\n如果刚开始执行的时候，就发现已经执行过这个位置了，则返回 0。\n\n对于上图中先执行 trx1，再执行一个查询请求的逻辑，要保证能够查到正确的数据，我们可以使用这个逻辑：\n\ntrx1 事务更新完成后，马上执行 show master status 得到当前主库执行到的 File 和 Position；\n选定一个从库执行查询语句；\n在从库上执行 select master_pos_wait(File, Position, 1)；\n如果返回值是 &gt;&#x3D;0 的正整数，则在这个从库执行查询语句；\n否则，到主库执行查询语句。\n\n如果你的数据库开启了 GTID 模式，对应的也有等待 GTID 的方案。\nMySQL 中同样提供了一个类似的命令：\nselect wait_for_executed_gtid_set(gtid_set, 1);\n\n这条命令的逻辑是：\n\n等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；\n超时返回 1。\n\n这时，等 GTID 的执行流程就变成了：\n\ntrx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1；\n选定一个从库执行查询语句；\n在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；\n如果返回值是 0，则在这个从库执行查询语句；\n否则，到主库执行查询语句。\n\n数据库功能性判断select 1 判断实际上，select 1 成功返回，只能说明这个库的进程还在，并不能说明主库没问题。\n我们设置 innodb_thread_concurrency 参数的目的是，控制 InnoDB 的并发线程上限。也就是说，一旦并发线程数达到这个值，InnoDB 在接收到新请求的时候，就会进入等待状态，直到有线程退出。\n这里，我把 innodb_thread_concurrency 设置成 3，表示 InnoDB 只允许 3 个线程并行执行。而在我们的例子中，前三个 session 中的 sleep(100)，使得这三个语句都处于“执行”状态，以此来模拟大查询。\n你看到了， session D 里面，select 1 是能执行成功的，但是查询表 t 的语句会被堵住。也就是说，如果这时候我们用 select 1 来检测实例是否正常的话，是检测不出问题的。\n查表判断为了能够检测 InnoDB 并发线程数过多导致的系统不可用情况，我们需要找一个访问 InnoDB 的场景。一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为 health_check，里面只放一行数据，然后定期执行：\nmysql&gt; select * from mysql.health_check; \n\n使用这个方法，我们可以检测出由于并发线程过多导致的数据库不可用的情况。\n但是，我们马上还会碰到下一个问题，即：空间满了以后，这种方法又会变得不好使。\n我们知道，更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的。\n更新判断既然要更新，就要放个有意义的字段，常见做法是放一个 timestamp 字段，用来表示最后一次执行检测的时间。这条更新语句类似于：\nmysql&gt; update mysql.health_check set t_modified&#x3D;now();\n\n节点可用性的检测都应该包含主库和备库。如果用更新来检测主库的话，那么备库也要进行更新检测。\n但，备库的检测也是要写 binlog 的。由于我们一般会把数据库 A 和 B 的主备关系设计为双 M 结构，所以在备库 B 上执行的检测命令，也要发回给主库 A。\n但是，如果主库 A 和备库 B 都用相同的更新命令，就可能出现行冲突，也就是可能会导致主备同步停止。所以，现在看来 mysql.health_check 这个表就不能只有一行数据了。\n更新语句，如果失败或者超时，就可以发起主备切换了，为什么还会有判定慢的问题呢？\n其实，这里涉及到的是服务器 IO 资源分配的问题。\n首先，所有的检测逻辑都需要一个超时时间 N。执行一条 update 语句，超过 N 秒后还不返回，就认为系统不可用。\n你可以设想一个日志盘的 IO 利用率已经是 100% 的场景。这时候，整个系统响应非常慢，已经需要做主备切换了。\n但是你要知道，IO 利用率 100% 表示系统的 IO 是在工作的，每个请求都有机会获得 IO 资源，执行自己的任务。而我们的检测使用的 update 命令，需要的资源很少，所以可能在拿到 IO 资源的时候就可以提交成功，并且在超时时间 N 秒未到达之前就返回给了检测系统。\n检测系统一看，update 命令没有超时，于是就得到了“系统正常”的结论。\n内部统计\n\n\n\n\n\n\n\n\nMySQL 5.6 版本以后提供的 performance_schema 库，就在 file_summary_by_event_name 表里统计了每次 IO 请求的时间。\n\n\n\n\n图中这一行表示统计的是 redo log 的写入时间，第一列 EVENT_NAME 表示统计的类型。\n接下来的三组数据，显示的是 redo log 操作的时间统计。\n第一组五列，是所有 IO 类型的统计。其中，COUNT_STAR 是所有 IO 的总次数，接下来四列是具体的统计项， 单位是皮秒；前缀 SUM、MIN、AVG、MAX，顾名思义指的就是总和、最小值、平均值和最大值。\n第二组六列，是读操作的统计。最后一列 SUM_NUMBER_OF_BYTES_READ 统计的是，总共从 redo log 里读了多少个字节。\n第三组六列，统计的是写操作。\n最后的第四组数据，是对其他类型数据的统计。在 redo log 里，你可以认为它们就是对 fsync 的统计。\n\n\n\n\n\n\n\n注意\n如果打开所有的 performance_schema 项，性能大概会下降 10% 左右。\n\n\n数据误删\n\n\n\n\n\n\n\n\n为了找到解决误删数据的更高效的方法，需要先对和 MySQL 相关的误删数据，做下分类：\n\n使用 delete 语句误删数据行；\n使用 drop table 或者 truncate table 语句误删数据表；\n使用 drop database 语句误删数据库；\n使用 rm 命令误删整个 MySQL 实例。\n\n误删行如果是使用 delete 语句误删了数据行，可以用 Flashback 工具通过闪回把数据恢复回来。\nFlashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format&#x3D;row 和 binlog_row_image&#x3D;FULL。\n具体恢复数据时，对单个事务做如下处理：\n\n对于 insert 语句，对应的 binlog event 类型是 Write_rows event，把它改成 Delete_rows event 即可；\n同理，对于 delete 语句，也是将 Delete_rows event 改为 Write_rows event；\n而如果是 Update_rows 的话，binlog 里面记录了数据行修改前和修改后的值，对调这两行的位置即可。\n\n\n\n\n\n\n\n\n特别注意\n以上操作不建议直接在主库上执行\n\n\n恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。\n为什么要这么做呢？\n这是因为，一个在执行线上逻辑的主库，数据状态的变更往往是有关联的。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。\n我们不止要说误删数据的事后处理办法，更重要是要做到事前预防。我有以下两个建议：\n\n把 sql_safe_updates 参数设置为 on。这样一来，如果我们忘记在 delete 或者 update 语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错。\n代码上线前，必须经过 SQL 审计。\n\n如果你确定这个删除操作没问题的话，可以在 delete 语句中加上 where 条件，比如 where id&gt;&#x3D;0。\n但是，delete 全表是很慢的，需要生成回滚日志、写 redo、写 binlog。所以，从性能角度考虑，你应该优先考虑使用 truncate table 或者 drop table 命令。\n使用 delete 命令删除的数据，你还可以用 Flashback 来恢复。而使用 truncate &#x2F;drop table 和 drop database 命令删除的数据，就没办法通过 Flashback 来恢复了。为什么呢？\n这是因为，即使我们配置了 binlog_format&#x3D;row，执行这三个命令时，记录的 binlog 还是 statement 格式。binlog 里面就只有一个 truncate&#x2F;drop 语句，这些信息是恢复不出数据的。\n误删库 &#x2F; 表这种情况下，要想恢复数据，就需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份 binlog。\n在这两个条件都具备的情况下，假如有人中午 12 点误删了一个库，恢复数据的流程如下：\n\n取最近一次全量备份，假设这个库是一天一备，上次备份是当天 0 点；\n用备份恢复出一个临时库；\n从日志备份里面，取出凌晨 0 点之后的日志；\n把这些日志，除了误删除数据的语句外，全部应用到临时库。\n\n这个流程的示意图如下所示：\n\n\n\n\n关于这个过程，有以下几点说明：\n\n为了加速数据恢复，如果这个临时库上有多个数据库，你可以在使用 mysqlbinlog 命令时，加上一个–database 参数，用来指定误删表所在的库。这样，就避免了在恢复数据时还要应用其他库日志的情况。\n在应用日志的时候，需要跳过 12 点误操作的那个语句的 binlog（不然不是直接爆炸了，又删了，hhh）：\n如果原实例没有使用 GTID 模式，只能在应用到包含 12 点的 binlog 文件的时候，先用–stop-position 参数执行到误操作之前的日志，然后再用–start-position 从误操作之后的日志继续执行；\n如果实例使用了 GTID 模式，就方便多了。假设误操作命令的 GTID 是 gtid1，那么只需要执行 set gtid_next&#x3D;gtid1;begin;commit; 先把这个 GTID 加到临时实例的 GTID 集合，之后按顺序执行 binlog 的时候，就会自动跳过误操作的语句。\n\n\n\n恢复加速不过，即使这样，使用 mysqlbinlog 方法恢复数据还是不够快，主要原因有两个：\n\n如果是误删表，最好就是只恢复出这张表，也就是只重放这张表的操作，但是 mysqlbinlog 工具并不能指定只解析一个表的日志；\n用 mysqlbinlog 解析出日志应用，应用日志的过程就只能是单线程。\n\n一种加速的方法是，在用备份恢复出临时实例之后，将这个临时实例设置成线上备库的从库，这样：\n\n在 start slave 之前，先通过执行﻿﻿change replication filter replicate_do_table &#x3D; (tbl_name) 命令，就可以让临时库只同步误操作的表；\n这样做也可以用上并行复制技术，来加速整个数据恢复过程。\n\n\n\n\n\n可以看到，图中 binlog 备份系统到线上备库有一条虚线，是指如果由于时间太久，备库上已经删除了临时实例需要的 binlog 的话，我们可以从 binlog 备份系统中找到需要的 binlog，再放回备库中。\n预防误删库 &#x2F; 表的方法第一条建议是，账号分离。这样做的目的是，避免写错命令。比如：\n\n我们只给业务开发同学 DML 权限，而不给 truncate&#x2F;drop 权限。而如果业务开发人员有 DDL 需求的话，也可以通过开发管理系统得到支持。\n即使是 DBA 团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。\n\n第二条建议是，制定操作规范。这样做的目的，是避免写错要删除的表名。比如：\n\n在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。\n改表名的时候，要求给表名加固定的后缀（比如加 _to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表。\n\nrm 删除数据其实，对于一个有高可用机制的 MySQL 集群来说，最不怕的就是 rm 删除数据了。只要不是恶意地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA 系统就会开始工作，选出一个新的主库，从而保证整个集群的正常工作。\n这时，你要做的就是在这个节点上把数据恢复回来，再接入整个集群。\n当然了，现在不止是 DBA 有自动化系统，SA（系统管理员）也有自动化系统，所以也许一个批量下线机器的操作，会让你整个 MySQL 集群的所有节点都全军覆没。\n应对这种情况，我的建议只能是说尽量把你的备份跨机房，或者最好是跨城市保存。\n","slug":"MySQL高可用","date":"2022-09-26T13:48:46.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"},{"id":"1305302b447db5e66b7e5e506037fc4a","title":"hard记录","content":"\n\n\n\n\n\n\n\n\n最近做周赛基本都是三题，哪怕半小时以内做完三题，T4也没什么思路，因此专门记录一下周赛和平常遇到的一些有代表性思路的hard题也算是继续提升一下，希望以后可以成为AK选手。\n动态规划2430. 对字母串可执行的最大删除数（313场周赛T4）\n\n\n\n\n\n\n\n\n本题一开始的思路是准备使用hash来记录下，字符串最长前缀，但是错误的贪心了其实这里必须是On^2的，可以根据数据来判断复杂度，然后dfs来不及写了，但感觉dfs会超时，不过一般可以用dfs就可以用dp，所以这题的标准思路就是先记忆化最长字符串前缀，当最长前缀大于删除长度表示可以删除，然后在基础上再讲规划+1。\nclass Solution &#123;\npublic:\n    int deleteString(string s) &#123;\n        int n &#x3D; s.length();\n        if (equal(s.begin()+1, s.end(), s.begin())) &#x2F;&#x2F; 特判全部相同的情况\n            return n;\n        int lcp[n + 1][n + 1]; &#x2F;&#x2F; lcp[i][j] 表示 s[i:] 和 s[j:] 的最长公共前缀\n        memset(lcp, 0, sizeof(lcp));\n        for (int i &#x3D; n - 1; i &gt;&#x3D; 0; --i)\n            for (int j &#x3D; n - 1; j &gt; i; --j)\n                if (s[i] &#x3D;&#x3D; s[j])\n                    lcp[i][j] &#x3D; lcp[i + 1][j + 1] + 1;\n        int f[n];\n        memset(f, 0, sizeof(f));\n        for (int i &#x3D; 0; i &lt;n; ++i) &#123;\n            for (int j &#x3D; 1; i + j * 2 &lt;&#x3D; n; ++j)\n                if (lcp[i][i + j] &gt;&#x3D; j) &#x2F;&#x2F; 说明 s[i:i+j] &#x3D;&#x3D; s[i+j:i+j*2]\n                    f[i] &#x3D; max(f[i], f[i + j]);\n            ++f[i];\n        &#125;\n        return f[0];\n    &#125;\n&#125;;\n\n801. 使序列递增的最小交换次数（22.10.10每日一题）\n\n\n\n\n\n\n\n\n这题想到了动态规划，但是因为没有把情况搞清楚所以想简单了，这个题居然是以前周赛的第二题实在是不管相信，状态机DP的精髓就是一个限定死的操作，例如本题只有交换和不交换，那么只要保证前面数组的递增性就无后效性，将状态方程把握清楚就可以了。\nclass Solution &#123;\npublic:\n    int minSwap(vector&lt;int>&amp; nums1, vector&lt;int>&amp; nums2) &#123;\n        int n = nums1.size();\n        int a = 0, b = 1;\n        for (int i = 1; i &lt; n; i++) &#123;\n            int at = a, bt = b;\n            a = b = n;\n            if (nums1[i] > nums1[i - 1] &amp;&amp; nums2[i] > nums2[i - 1])  &#123;\n                a = min(a, at);\n                b = min(b, bt + 1);\n            &#125;\n            if (nums1[i] > nums2[i - 1] &amp;&amp; nums2[i] > nums1[i - 1]) &#123;\n                a = min(a, bt);\n                b = min(b, at + 1);\n            &#125;\n        &#125;\n        return min(a, b);\n    &#125;\n&#125;;\n\n\n相关问题\n198. 打家劫舍(和这种偷与不偷我感觉比较类似)\n213. 打家劫舍 II\n\n\n2435. 矩阵中和能被 K 整除的路径（314场周赛T4）\n\n\n\n\n\n\n\n\n标准的记忆化搜索题，奈何T3太难了浪费了很多时间，最接近AK的一次，这题的难点在于三维记忆化要想到取余作为sum不然的话会TEL，然后需要注意的是溢出的处理，说实话int溢出真的很烦尤其有减法，烦的一批！！！吃了好多发WA。（难得有自己写的代码贴上来的很香！）\nclass Solution &#123;\npublic:\n    int numberOfPaths(vector&lt;vector&lt;int&gt;&gt;&amp; grid, int k) &#123;\n        long long res &#x3D;0;\n        vector&lt;vector&lt;vector&lt;long long&gt;&gt;&gt; dp(grid.size(),vector&lt;vector&lt;long long&gt;&gt;(grid[0].size(),vector&lt;long long&gt;(50,-1)));\n        dfs(0,0,grid,k,0,res,dp);\n        res &#x3D; res % 1000000007;\n        return (int)res;\n    &#125;\n    void dfs(int i,int j,vector&lt;vector&lt;int&gt;&gt;&amp; grid, int&amp; k,int sum,long long&amp; res,vector&lt;vector&lt;vector&lt;long long&gt;&gt;&gt;&amp; dp)&#123;\n        sum +&#x3D; grid[i][j];\n        if(dp[i][j][sum%k] !&#x3D; -1)&#123;\n            &#x2F;&#x2F;res &#x3D; res % 1000000007;\n            res +&#x3D; dp[i][j][sum%k];\n            return;\n        &#125;\n        long long tmp &#x3D; res % 1000000007;\n        if(i &#x3D;&#x3D; grid.size()-1 &amp;&amp; j&#x3D;&#x3D;grid[0].size()-1)&#123;\n            if(sum % k &#x3D;&#x3D; 0) res++;\n            return;\n        &#125;\n        if(i &lt; grid.size()-1) dfs(i+1,j,grid,k,sum,res,dp);\n        if(j &lt; grid[0].size()-1) dfs(i,j+1,grid,k,sum,res,dp);\n        dp[i][j][sum%k] &#x3D; (res - tmp)%1000000007;\n    &#125;\n&#125;;\n\n1235. 规划兼职工作（22.10.22每日一题）\n\n\n\n\n\n\n\n\n一开始想法是dfs+记忆化搜索，但其实记忆化的题目都可以dp没有想到很好的状态转移方程，后来看了题解感觉到有一点贪心的味道其实并不算难，但是题解的一些语法特性技巧，非常值得借鉴，也算是个好题目了。\nclass Solution &#123;\npublic:\n    int jobScheduling(vector&lt;int&gt; &amp;startTime, vector&lt;int&gt; &amp;endTime, vector&lt;int&gt; &amp;profit) &#123;\n        int n &#x3D; startTime.size();\n        vector&lt;vector&lt;int&gt;&gt; jobs(n);\n        for (int i &#x3D; 0; i &lt; n; i++) &#123;\n            jobs[i] &#x3D; &#123;startTime[i], endTime[i], profit[i]&#125;;\n        &#125;\n        sort(jobs.begin(), jobs.end(), [](const vector&lt;int&gt; &amp;job1, const vector&lt;int&gt; &amp;job2) -&gt; bool &#123;\n            return job1[1] &lt; job2[1];\n        &#125;);\n        vector&lt;int&gt; dp(n + 1);\n        for (int i &#x3D; 1; i &lt;&#x3D; n; i++) &#123;\n            int k &#x3D; upper_bound(jobs.begin(), jobs.begin() + i - 1, jobs[i - 1][0], [&amp;](int st, const vector&lt;int&gt; &amp;job) -&gt; bool &#123;\n                return st &lt; job[1];\n            &#125;) - jobs.begin();\n            dp[i] &#x3D; max(dp[i - 1], dp[k] + jobs[i - 1][2]);\n        &#125;\n        return dp[n];\n    &#125;\n&#125;;\n\n\n\n树状数组&#x2F;线段树2426. 满足不等式的数对数目（88场双周赛T4）\n\n\n\n\n\n\n\n\n这题的不等式变形我是想到了，然后求出来数组之后没有办法快速的选取满足条件的区间，感觉逻辑出了点问题，知道要用树状数组求和，奈何没有系统的训练，因此最后也没做出来，区间求和问题还是需要熟练掌握这两种结构，因为周赛出现频率极高。这里可以推荐这个视频：五分钟丝滑动画讲解 | 树状数组来学习树状数组的原理，我觉得讲的特别清楚。\nclass BIT &#123;&#x2F;&#x2F;树状数组的标准写法\nprivate:\n    vector&lt;int&gt; tree;\n\npublic:\n    BIT(int n) : tree(n) &#123;&#125;\n\n    void add(int x) &#123;\n        while (x &lt; tree.size()) &#123;\n            ++tree[x];\n            x +&#x3D; x &amp; -x;\n        &#125;\n    &#125;\n\n    int query(int x) &#123;\n        int res &#x3D; 0;\n        while (x &gt; 0) &#123;\n            res +&#x3D; tree[x];\n            x &amp;&#x3D; x - 1;\n        &#125;\n        return res;\n    &#125;\n&#125;;\n\nclass Solution &#123;\npublic:\n    long long numberOfPairs(vector&lt;int&gt; &amp;a, vector&lt;int&gt; &amp;nums2, int diff) &#123;\n        int n &#x3D; a.size();\n        for (int i &#x3D; 0; i &lt; n; ++i)\n            a[i] -&#x3D; nums2[i];\n        auto b &#x3D; a;\n        sort(b.begin(), b.end()); &#x2F;&#x2F; 配合下面的二分，离散化\n\n        long ans &#x3D; 0L;\n        auto t &#x3D; new BIT(n + 1);\n        for (int x : a) &#123;\n            ans +&#x3D; t-&gt;query(upper_bound(b.begin(), b.end(), x + diff) - b.begin());&#x2F;&#x2F;查询第一个大于x+diff\n            t-&gt;add(lower_bound(b.begin(), b.end(), x) - b.begin() + 1);&#x2F;&#x2F;查询第一个大于等于x\n        &#125;\n        return ans;\n    &#125;\n&#125;;\n\n\n相关问题\n327. 区间和的个数\n剑指 Offer 51. 数组中的逆序对\n\n\n单调栈&#x2F;队列&#x2F;双端队列862. 和至少为 K 的最短子数组（22.10.26每日一题）\n\n\n\n\n\n\n\n\n这个题前缀和是想到了，其实子数组很容易想到前缀和，但是想要减枝偷过去天方夜谭了哈哈哈，周赛看到有人偷过去，但是肯定不能抱有侥幸心理啊，所以本质上是双端队列来维护最短的可能性，其实双端队列的头和剪是一样的，但是尾巴的维护单调我没有想到，所以还是学艺不精，尤其是单调队列的使用，单调栈最近感觉还可以。\nclass Solution &#123;\npublic:\n    int shortestSubarray(vector&lt;int&gt;&amp; nums, int k) &#123;\n        int n &#x3D; nums.size();\n        vector&lt;long&gt; preSumArr(n + 1);\n        for (int i &#x3D; 0; i &lt; n; i++) &#123;\n            preSumArr[i + 1] &#x3D; preSumArr[i] + nums[i];\n        &#125;\n        int res &#x3D; n + 1;\n        deque&lt;int&gt; qu;\n        for (int i &#x3D; 0; i &lt;&#x3D; n; i++) &#123;\n            long curSum &#x3D; preSumArr[i];\n            while (!qu.empty() &amp;&amp; curSum - preSumArr[qu.front()] &gt;&#x3D; k) &#123;\n                res &#x3D; min(res, i - qu.front());\n                qu.pop_front();\n            &#125;\n            while (!qu.empty() &amp;&amp; preSumArr[qu.back()] &gt;&#x3D; curSum) &#123;\n                qu.pop_back();\n            &#125;\n            qu.push_back(i);\n        &#125;\n        return res &lt; n + 1 ? res : -1;\n    &#125;\n&#125;;\n\n","slug":"hard记录","date":"2022-09-26T10:08:53.000Z","categories_index":"数据结构","tags_index":"算法刷题,思路记录","author_index":"依水何安"},{"id":"2acfbdc0062c0ef1a792fc0d6a402d2c","title":"WebServer项目笔记","content":"\n\n\n\n\n\n\n\n\n使用C++编写的Liunx系统下的支持多并发的网络服务器，包含Mysql后端和使用 线程池 + 非阻塞socket + epoll(ET和LT均实现) + 事件处理(Reactor和模拟Proactor均实现) 的并发模型，能够使用状态机解析HTTP请求报文，并且实现了同步&#x2F;异步日志系统，记录服务器运行状态。\n快速开始\n安装MySQL以及相关库\ndpkg -l | grep mysql//本体\nsudo apt install mysql-server//服务\nsudo apt-get install libmysqlclient-dev//链接库\n\n测试前确认已安装MySQL数据库\n&#x2F;&#x2F; 建立yourdb库\ncreate database yourdb;\n\n&#x2F;&#x2F; 创建user表\nUSE yourdb;\nCREATE TABLE user(\n    username char(50) NULL,\n    passwd char(50) NULL\n)ENGINE&#x3D;InnoDB;\n\n&#x2F;&#x2F; 添加数据\nINSERT INTO user(username, passwd) VALUES(&#39;name&#39;, &#39;passwd&#39;);\n\n修改main.cpp中的数据库初始化信息\n&#x2F;&#x2F;数据库登录名,密码,库名\nstring user &#x3D; &quot;root&quot;;\nstring passwd &#x3D; &quot;root&quot;;\nstring databasename &#x3D; &quot;yourdb&quot;;\n\nbuild\nsh .&#x2F;build.sh\n\n启动server\n.&#x2F;server\n\n浏览器端\nip:9006\n\n.&#x2F;server [-p port] [-l LOGWrite] [-m TRIGMode] [-o OPT_LINGER] [-s sql_num] [-t thread_num] [-c close_log] [-a actor_model]\n\n温馨提示:以上参数不是非必须，不用全部使用，根据个人情况搭配选用即可.\n\n-p，自定义端口号\n默认9006\n\n\n-l，选择日志写入方式，默认同步写入\n0，同步写入\n1，异步写入\n\n\n-m，listenfd和connfd的模式组合，默认使用LT + LT\n0，表示使用LT + LT\n1，表示使用LT + ET\n2，表示使用ET + LT\n3，表示使用ET + ET\n\n\n-o，优雅关闭连接，默认不使用\n0，不使用\n1，使用\n\n\n-s，数据库连接数量\n默认为8\n\n\n-t，线程数量\n默认为8\n\n\n-c，关闭日志，默认打开\n0，打开日志\n1，关闭日志\n\n\n-a，选择反应堆模型，默认Proactor\n0，Proactor模型\n1，Reactor模型\n\n\n\n测试示例命令与含义\n.&#x2F;server -p 9007 -l 1 -m 0 -o 1 -s 10 -t 10 -c 1 -a 1\n\n成果展示结构分析lock.h 线程同步机制封装类（锁）\n\n\n\n\n\n\n\n\n本项目一共封装了三种类型包括信号量(sem)、互斥锁(量)(locker)以及条件变量(cond),该部分详情可以参考我博客中的另一篇文章操作系统笔记多线程冲突中的内容。\n信号量信号量是一种特殊的变量，它只能取自然数值并且只支持两种操作：等待(P)和信号(V).假设有信号量SV，对其的P、V操作如下：\n\n\n\n\n\n\n\n\n\n\nP，如果SV的值大于0，则将其减一；若SV的值为0，则挂起执行\nV，如果有其他进行因为等待SV而挂起，则唤醒；若没有，则将SV值加一\n\n信号量的取值可以是任何自然数，最常用的，最简单的信号量是二进制信号量，只有0和1两个值.\n\n\n\n\n\n\n\n\n\n\nsem_init函数用于初始化一个未命名的信号量\nsem_destory函数用于销毁信号量\nsem_wait函数将以原子操作方式将信号量减一,信号量为0时,sem_wait阻塞\nsem_post函数以原子操作方式将信号量加一,信号量大于0时,唤醒调用sem_post的线程\n\n以上，成功返回0，失败返回errno\n互斥量互斥锁,也成互斥量,可以保护关键代码段,以确保独占式访问.当进入关键代码段,获得互斥锁将其加锁;离开关键代码段,唤醒等待该互斥锁的线程.\n\n\n\n\n\n\n\n\n\n\npthread_mutex_init函数用于初始化互斥锁\npthread_mutex_destory函数用于销毁互斥锁\npthread_mutex_lock函数以原子操作方式给互斥锁加锁\npthread_mutex_unlock函数以原子操作方式给互斥锁解锁\n\n以上，成功返回0，失败返回errno\n条件变量条件变量提供了一种线程间的通知机制,当某个共享数据达到某个值时,唤醒等待这个共享数据的线程.\n\n\n\n\n\n\n\n\n\n\npthread_cond_init函数用于初始化条件变量\npthread_cond_destory函数销毁条件变量\npthread_cond_broadcast函数以广播的方式唤醒所有等待目标条件变量的线程\npthread_cond_wait函数用于等待目标条件变量.该函数调用时需要传入 mutex参数(加锁的互斥锁) ,函数执行时,先把调用线程放入条件变量的请求队列,然后将互斥锁mutex解锁,当函数成功返回为0时,互斥锁会再次被锁上. 也就是说函数内部会有一次解锁和加锁操作.\n\n部分函数解读pthread_detach****作用：****从状态上实现线程分离，注意不是指该线程独自占用地址空间。\n线程分离状态：指定该状态，线程主动与主控线程断开关系。线程结束后（不会产生僵尸线程），其退出状态不由其他线程获取，而直接自己自动释放（自己清理掉PCB的残留资源）。\n能对一个已经处于detach状态的线程调用pthread_join，这样的调用将返回EINVAL错误（22号错误）。也就是说，如果已经对一个线程调用了pthread_detach就不能再调用pthread_join了。\nTODO List\n网页装修\n支持更多操作\n公网部署\n\n","slug":"WebServer项目笔记","date":"2022-10-27T07:02:29.000Z","categories_index":"WebServer","tags_index":"网络编程,多并发实现","author_index":"依水何安"},{"id":"3a69ec9c6ae67f12a8733f1c82dc14ae","title":"操作系统笔记","content":"本文参考了小林coding,csapp等操作系统教程，以及Websever的一些框架和思路。写了一篇个人的笔记，其中也包含了本人对于一些小问题的记录和思考，以及整体框架的梳理。\n进程管理快速了解可以参考：\n \n\n进程\n\n\n\n\n\n\n\n\n我们编写的代码只是一个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每一条指令，那么这个运行中的程序，就被称为「进程」（Process）。\n现在我们考虑有一个会读取硬盘文件数据的程序被执行了，那么当运行到读取文件的指令时，就会去从硬盘读取数据，但是硬盘的读写速度是非常慢的，那么在这个时候，如果 CPU 傻傻的等硬盘返回数据的话，那 CPU 的利用率是非常低的。\n所以，当进程要从硬盘读取数据时，CPU 不需要阻塞等待数据的返回，而是去执行另外的进程。当硬盘数据返回时，CPU 会收到个中断，于是 CPU 再继续运行这个进程。\n\n\n\n\n这种多个程序、交替执行的思想，就有 CPU 管理多个进程的初步想法。\n对于一个支持多进程的系统，CPU 会从一个进程快速切换至另一个进程，其间每个进程各运行几十或几百个毫秒。\n虽然单核的 CPU 在某一个瞬间，只能运行一个进程。但在 1 秒钟期间，它可能会运行多个进程，这样就产生并行的错觉，实际上这是并发。\n\n\n\n\n进程的状态一般说来，一个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。\n它有时处于运行状态，有时又由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。\n所以，在一个进程的活动期间至少具备三种基本状态，即运行状态、就绪状态、阻塞状态。\n\n\n\n\n上图中各个状态的意义：\n\n运行状态（Running）：该时刻进程占用 CPU；\n就绪状态（Ready）：可运行，由于其他进程处于运行状态而暂时停止运行；\n阻塞状态（Blocked）：该进程正在等待某一事件发生（如等待输入&#x2F;输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行；\n\n当然，进程还有另外两个基本状态：\n\n创建状态（new）：进程正在被创建时的状态；\n结束状态（Exit）：进程正在从系统中消失时的状态；\n\n再来详细说明一下进程的状态变迁：\n\nNULL -&gt; 创建状态：一个新进程被创建时的第一个状态；\n创建状态 -&gt; 就绪状态：当进程被创建完成并初始化后，一切就绪准备运行时，变为就绪状态，这个过程是很快的；\n就绪态 -&gt; 运行状态：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给 CPU 正式运行该进程；\n运行状态 -&gt; 结束状态：当进程已经运行完成或出错时，会被操作系统作结束状态处理；\n运行状态 -&gt; 就绪状态：处于运行状态的进程在运行过程中，由于分配给它的运行时间片用完，操作系统会把该进程变为就绪态，接着从就绪态选中另外一个进程运行；\n运行状态 -&gt; 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I&#x2F;O 事件；\n阻塞状态 -&gt; 就绪状态：当进程要等待的事件完成时，它从阻塞状态变到就绪状态；\n\n如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占用着物理内存就一种浪费物理内存的行为。\n所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换入到物理内存。\n那么，就需要一个新的状态，来描述进程没有占用实际的物理内存空间的情况，这个状态就是挂起状态。这跟阻塞状态是不一样，阻塞状态是等待某个事件的返回。\n另外，挂起状态可以分为两种：\n\n阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现；\n就绪挂起状态：进程在外存（硬盘），但只要进入内存，即刻立刻运行；\n\n导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：\n\n通过 sleep 让进程间歇性挂起，其工作原理是设置一个定时器，到期后唤醒进程。\n用户希望挂起一个程序的执行，比如在 Linux 中用 Ctrl+Z 挂起进程；\n\n\n\n\n\n进程的控制结构在操作系统中，是用进程控制块（process control block，PCB）数据结构来描述进程的。\nPCB 是进程存在的唯一标识，这意味着一个进程的存在，必然会有一个 PCB，如果进程消失了，那么 PCB 也会随之消失。\n进程描述信息：\n\n进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；\n用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；\n\n进程控制和管理信息：\n\n进程当前状态，如 new、ready、running、waiting 或 blocked 等；\n进程优先级：进程抢占 CPU 时的优先级；\n\n资源分配清单：\n\n有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I&#x2F;O 设备信息。\n\nCPU 相关信息：\n\nCPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的 PCB 中，以便进程重新执行时，能从断点处继续执行。\n\n\n\n\n\n\n\n\n\n\n每个 PCB 是如何组织的呢？\n通常是通过链表的方式进行组织，把具有相同状态的进程链在一起，组成各种队列。比如：\n\n将所有处于就绪状态的进程链在一起，称为就绪队列；\n把所有因等待某事件而处于等待状态的进程链在一起就组成各种阻塞队列；\n另外，对于运行队列在单核 CPU 系统中则只有一个运行指针了，因为单核 CPU 在某个时间，只能运行一个程序。\n\n那么，就绪队列和阻塞队列链表的组织形式如下图：\n\n\n\n\n除了链接的组织方式，还有索引方式，它的工作原理：将同一状态的进程组织在一个索引表中，索引表项指向相应的 PCB，不同状态对应不同的索引表。\n一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。\n进程的控制再来看看进程的创建、终止、阻塞、唤醒的过程，这些过程也就是进程的控制。\n01 创建进程\n操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源。\n创建进程的过程如下：\n\n申请一个空白的 PCB，并向 PCB 中填写一些控制和管理进程的信息，比如进程的唯一标识等；\n为该进程分配运行时所必需的资源，比如内存资源；\n将 PCB 插入到就绪队列，等待被调度运行；\n\n02 终止进程\n进程可以有 3 种终止方式：正常结束、异常结束以及外界干预（信号 kill 掉）。\n当子进程被终止时，其在父进程处继承的资源应当还给父进程。而当父进程被终止时，该父进程的子进程就变为孤儿进程，会被 1 号进程收养，并由 1 号进程对它们完成状态收集工作。\n终止进程的过程如下：\n\n查找需要终止的进程的 PCB；\n如果处于执行状态，则立即终止该进程的执行，然后将 CPU 资源分配给其他进程；\n如果其还有子进程，则应将该进程的子进程交给 1 号进程接管；\n将该进程所拥有的全部资源都归还给操作系统；\n将其从 PCB 所在队列中删除；\n\n03 阻塞进程\n当进程需要等待某一事件完成时，它可以调用阻塞语句把自己阻塞等待。而一旦被阻塞等待，它只能由另一个进程唤醒。\n阻塞进程的过程如下：\n\n找到将要被阻塞进程标识号对应的 PCB；\n如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行；\n将该 PCB 插入到阻塞队列中去；\n\n04 唤醒进程\n进程由「运行」转变为「阻塞」状态是由于进程必须等待某一事件的完成，所以处于阻塞状态的进程是绝对不可能叫醒自己的。\n如果某进程正在等待 I&#x2F;O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程用唤醒语句叫醒它。\n唤醒进程的过程如下：\n\n在该事件的阻塞队列中找到相应进程的 PCB；\n将其从阻塞队列中移出，并置其状态为就绪状态；\n把该 PCB 插入到就绪队列中，等待调度程序调度；\n\n进程的阻塞和唤醒是一对功能相反的语句，如果某个进程调用了阻塞语句，则必有一个与之对应的唤醒语句。\n进程的上下文切换各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个一个进程切换到另一个进程运行，称为进程的上下文切换。\n大多数操作系统都是多任务，通常支持大于 CPU 数量的任务同时运行。实际上，这些任务并不是同时运行的，只是因为系统在很短的时间内，让各个任务分别在 CPU 运行，于是就造成同时运行的错觉。\n任务是交给 CPU 运行的，那么在每个任务运行前，CPU 需要知道任务从哪里加载，又从哪里开始运行。\n所以，操作系统需要事先帮 CPU 设置好 CPU 寄存器和程序计数器。\nCPU 寄存器是 CPU 内部一个容量小，但是速度极快的内存（缓存）。我举个例子，寄存器像是你的口袋，内存像你的书包，硬盘则是你家里的柜子，如果你的东西存放到口袋，那肯定是比你从书包或家里柜子取出来要快的多。\n再来，程序计数器则是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置。\n所以说，CPU 寄存器和程序计数是 CPU 在运行任何任务前，所必须依赖的环境，这些环境就叫做 CPU 上下文。\nCPU 上下文切换就是先把前一个任务的 CPU 上下文（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。\n系统内核会存储保持下来的上下文信息，当此任务再次被分配给 CPU 运行时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。\n上面说到所谓的「任务」，主要包含进程、线程和中断。所以，可以根据任务的不同，把 CPU 上下文切换分成：进程上下文切换、线程上下文切换和中断上下文切换。\n进程是由内核管理和调度的，所以进程的切换只能发生在内核态。\n所以，进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。\n通常，会把交换的信息保存在进程的 PCB，当要运行另外一个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执行\n\n\n\n\n\n\n\n注意\n大家需要注意，进程的上下文开销是很关键的，我们希望它的开销越小越好，这样可以使得进程可以把更多时间花费在执行程序上，而不是耗费在上下文切换。\n\n\n\n为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外一个进程运行；\n进程在系统资源不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行；\n当进程通过睡眠函数 sleep 这样的方法将自己主动挂起时，自然也会重新调度；\n当有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行；\n发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序；\n\n线程\n\n\n\n\n\n\n\n\n在早期的操作系统中都是以进程作为独立运行的基本单位，直到后面，计算机科学家们又提出了更小的能独立运行的基本单位，也就是线程。\n需要有一种新的实体，满足以下特性：\n\n实体之间可以并发运行；\n实体之间共享相同的地址空间；\n\n这个新的实体，就是**线程( *Thread* )**，线程之间可以并发运行且共享相同的地址空间。\n线程的优点：\n\n一个进程中可以同时存在多个线程；\n各个线程之间可以并发执行；\n各个线程之间可以共享地址空间和文件等资源；\n\n线程的缺点：\n\n当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃\n\n线程与进程的比较线程与进程的比较如下：\n\n进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；\n进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；\n线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态之间的转换关系；\n线程能减少并发执行的时间和空间开销；\n\n对于，线程相比进程能减少开销，体现在：\n\n线程的创建时间比进程快，因为进程在创建的过程中，还需要资源管理信息，比如内存管理信息、文件管理信息，而线程在创建的过程中，不会涉及这些资源管理信息，而是共享它们；\n线程的终止时间比进程快，因为线程释放的资源相比进程少很多；\n同一个进程内的线程切换比进程切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程都具有同一个页表，那么在切换的时候不需要切换页表。而对于进程之间的切换，切换的时候要把页表给切换掉，而页表的切换过程开销是比较大的；\n由于同一进程的各线程间共享内存和文件资源，那么在线程之间数据传递的时候，就不需要经过内核了，这就使得线程之间的数据交互效率更高了；\n\n线程的上下文切换线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。\n对于线程和进程，我们可以这么理解：\n\n当进程只有一个线程时，可以认为进程就等于线程；\n当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换时是不需要修改的；\n\n\n\n\n\n\n\n\n\n\n线程上下文切换的是什么？\n这还得看线程是不是属于同一个进程：\n\n当两个线程不是属于同一个进程，则切换的过程就跟进程上下文切换一样；\n当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据；\n\n所以，线程的上下文切换相比进程，开销要小很多。\n线程的实现主要有三种线程的实现方式：\n\n用户线程（User Thread）：在用户空间实现的线程，不是由内核管理的线程，是由用户态的线程库来完成线程的管理；\n内核线程（Kernel Thread）：在内核中实现的线程，是由内核管理的线程；\n轻量级进程（LightWeight Process）：在内核中来支持用户线程；\n\n用户线程是基于用户态的线程管理库来实现的，那么线程控制块（*Thread Control Block, TCB*） 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。\n所以，用户线程的整个线程管理和调度，操作系统是不直接参与的，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。\n用户线程用户级线程的模型，也就类似前面提到的多对一的关系，即多个用户线程对应同一个内核线程。\n\n\n\n\n用户线程的优点：\n\n每个进程都需要有它私有的线程控制块（TCB）列表，用来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；\n用户线程的切换也是由线程库函数来完成的，无需用户态与内核态的切换，所以速度特别快；\n\n用户线程的缺点：\n\n由于操作系统不参与线程的调度，如果一个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了。\n\n当一个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的。\n\n由于时间片分配给进程，故与其他进程比，在多线程执行时，每个线程得到的时间片较少，执行会比较慢；\n\n\n内核线程内核线程是由操作系统管理的，线程对应的 TCB 自然是放在操作系统里的，这样线程的创建、终止和管理都是由操作系统负责。\n内核线程的模型，也就类似前面提到的一对一的关系，即一个用户线程对应一个内核线程\n\n\n\n\n内核线程的优点：\n\n在一个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；\n分配给线程，多线程的进程获得更多的 CPU 运行时间；\n\n内核线程的缺点：\n\n在支持内核线程的操作系统中，由内核来维护进程和线程的上下文信息，如 PCB 和 TCB；\n线程的创建、终止和切换都是通过系统调用的方式来进行，因此对于系统来说，系统开销比较大；\n\n轻量级进程轻量级进程（*Light-weight process，LWP*）是内核支持的用户线程，一个进程可有一个或多个 LWP，每个 LWP 是跟内核线程一对一映射的，也就是 LWP 都是由一个内核线程支持，而且 LWP 是由内核管理并像普通进程一样被调度。\n一般来说，一个进程代表程序的一个实例，而 LWP 代表程序的执行线程，因为一个执行线程不像进程那样需要那么多状态信息，所以 LWP 也不带有这样的信息。\n在 LWP 之上也是可以使用用户线程的，那么 LWP 与用户线程的对应关系就有三种：\n\n1 : 1，即一个 LWP 对应 一个用户线程；\nN : 1，即一个 LWP 对应多个用户线程；\nM : N，即多个 LWP 对应多个用户线程；\n\n\n\n\n\n1 : 1 模式\n一个线程对应到一个 LWP 再对应到一个内核线程，如上图的进程 4，属于此模型。\n\n优点：实现并行，当一个 LWP 阻塞，不会影响其他 LWP；\n缺点：每一个用户线程，就产生一个内核线程，创建线程的开销较大。\n\nN : 1 模式\n多个用户线程对应一个 LWP 再对应一个内核线程，如上图的进程 2，线程管理是在用户空间完成的，此模式中用户的线程对操作系统不可见。\n\n优点：用户线程要开几个都没问题，且上下文切换发生用户空间，切换的效率较高；\n缺点：一个用户线程如果阻塞了，则整个进程都将会阻塞，另外在多核 CPU 中，是没办法充分利用 CPU 的。\n\nM : N 模式\n根据前面的两个模型混搭一起，就形成 M:N 模型，该模型提供了两级控制，首先多个用户线程对应到多个 LWP，LWP 再一一对应到内核线程，如上图的进程 3。\n\n优点：综合了前两种优点，大部分的线程上下文发生在用户空间，且多个线程又可以充分利用多核 CPU 的资源。\n\n调度调度时机在进程的生命周期中，当进程从一个运行状态到另外一状态变化的时候，其实会触发一次调度。\n比如，以下状态的变化都会触发操作系统的调度：\n\n从就绪态 -&gt; 运行态：当进程被创建时，会进入到就绪队列，操作系统会从就绪队列选择一个进程运行；\n从运行态 -&gt; 阻塞态：当进程发生 I&#x2F;O 事件而阻塞时，操作系统必须选择另外一个进程运行；\n从运行态 -&gt; 结束态：当进程退出结束后，操作系统得从就绪队列选择另外一个进程运行；\n\n因为，这些状态变化的时候，操作系统需要考虑是否要让新的进程给 CPU 运行，或者是否让当前进程从 CPU 上退出来而换另一个进程运行。\n另外，如果硬件时钟提供某个频率的周期性中断，那么可以根据如何处理时钟中断 ，把调度算法分为两类：\n\n非抢占式调度算法挑选一个进程，然后让该进程运行直到被阻塞，或者直到该进程退出，才会调用另外一个进程，也就是说不会理时钟中断这个事情。\n抢占式调度算法挑选一个进程，然后让该进程只运行某段时间，如果在该时段结束时，该进程仍然在运行时，则会把它挂起，接着调度程序从就绪队列挑选另外一个进程。这种抢占式调度处理，需要在时间间隔的末端发生时钟中断，以便把 CPU 控制返回给调度程序进行调度，也就是常说的时间片机制。\n\n调度原则原则一：如果运行的程序，发生了 I&#x2F;O 事件的请求，那 CPU 使用率必然会很低，因为此时进程在阻塞等待硬盘的数据返回。这样的过程，势必会造成 CPU 突然的空闲。所以，为了提高 CPU 利用率，在这种发送 I&#x2F;O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择一个进程来运行。\n原则二：有的程序执行某个任务花费的时间会比较长，如果这个程序一直占用着 CPU，会造成系统吞吐量（CPU 在单位时间内完成的进程数量）的降低。所以，要提高系统的吞吐率，调度程序要权衡长任务和短任务进程的运行完成数量。\n原则三：从进程开始到结束的过程中，实际上是包含两个时间，分别是进程运行时间和进程等待时间，这两个时间总和就称为周转时间。进程的周转时间越小越好，如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的，调度程序应该避免这种情况发生。\n原则四：处于就绪队列的进程，也不能等太久，当然希望这个等待的时间越短越好，这样可以使得进程更快的在 CPU 中执行。所以，就绪队列中进程的等待时间也是调度程序所需要考虑的原则。\n原则五：对于鼠标、键盘这种交互式比较强的应用，我们当然希望它的响应时间越快越好，否则就会影响用户体验了。所以，对于交互式比较强的应用，响应时间也是调度程序需要考虑的原则。\n针对上面的五种调度原则，总结成如下：\n\nCPU 利用率：调度程序应确保 CPU 是始终匆忙的状态，这可提高 CPU 的利用率；\n系统吞吐量：吞吐量表示的是单位时间内 CPU 完成进程的数量，长作业的进程会占用较长的 CPU 资源，因此会降低吞吐量，相反，短作业的进程会提升系统吞吐量；\n周转时间：周转时间是进程运行+阻塞时间+等待时间的总和，一个进程的周转时间越小越好；\n等待时间：这个等待时间不是阻塞状态的时间，而是进程处于就绪队列的时间，等待的时间越长，用户越不满意；\n响应时间：用户提交请求到系统第一次产生响应所花费的时间，在交互式系统中，响应时间是衡量调度算法好坏的主要标准。\n\n调度算法不同的调度算法适用的场景也是不同的。\n接下来，说说在单核 CPU 系统中常见的调度算法。\n先来先服务调度算法最简单的一个调度算法，就是非抢占式的先来先服务（First Come First Serve, FCFS）算法了。\n\n\n\n\n顾名思义，先来后到，每次从就绪队列选择最先进入队列的进程，然后一直运行，直到进程退出或被阻塞，才会继续从队列中选择第一个进程接着运行。\n这似乎很公平，但是当一个长作业先运行了，那么后面的短作业等待的时间就会很长，不利于短作业。\nFCFS 对长作业有利，适用于 CPU 繁忙型作业的系统，而不适用于 I&#x2F;O 繁忙型作业的系统。\n最短作业优先调度算法最短作业优先（Shortest Job First, SJF）调度算法同样也是顾名思义，它会优先选择运行时间最短的进程来运行，这有助于提高系统的吞吐量。\n\n\n\n\n这显然对长作业不利，很容易造成一种极端现象。\n比如，一个长作业在就绪队列等待运行，而这个就绪队列有非常多的短作业，那么就会使得长作业不断的往后推，周转时间变长，致使长作业长期不会被运行。\n高响应比优先调度算法前面的「先来先服务调度算法」和「最短作业优先调度算法」都没有很好的权衡短作业和长作业。\n那么，高响应比优先 （Highest Response Ratio Next, HRRN）调度算法主要是权衡了短作业和长作业。\n每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：\n\n\n\n\n从上面的公式，可以发现：\n\n如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越高，这样短作业的进程容易被选中运行；\n如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越高，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提高，当其等待时间足够长时，其响应比便可以升到很高，从而获得运行的机会；\n\n时间片轮转调度算法最古老、最简单、最公平且使用最广的算法就是时间片轮转（Round Robin, RR）调度算法。\n\n\n\n\n每个进程被分配一个时间段，称为时间片（Quantum），即允许该进程在该时间段中运行。\n\n如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外一个进程；\n如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；\n\n另外，时间片的长度就是一个很关键的点：\n\n如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；\n如果设得太长又可能引起对短作业进程的响应时间变长。\n\n一般来说，时间片设为 20ms~50ms 通常是一个比较合理的折中值。\n最高优先级调度算法前面的「时间片轮转算法」做了个假设，即让所有的进程同等重要，也不偏袒谁，大家的运行时间都一样。\n但是，对于多用户计算机系统就有不同的看法了，它们希望调度是有优先级的，即希望调度程序能从就绪队列中选择最高优先级的进程进行运行，这称为最高优先级（Highest Priority First，HPF）调度算法。\n进程的优先级可以分为，静态优先级和动态优先级：\n\n静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；\n动态优先级：根据进程的动态变化调整优先级，比如如果进程运行时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则升高其优先级，也就是随着时间的推移增加等待进程的优先级。\n\n该算法也有两种处理优先级高的方法，非抢占式和抢占式：\n\n非抢占式：当就绪队列中出现优先级高的进程，运行完当前进程，再选择优先级高的进程。\n抢占式：当就绪队列中出现优先级高的进程，当前进程挂起，调度优先级高的进程运行。\n\n但是依然有缺点，可能会导致低优先级的进程永远不会运行。\n多级反馈队列调度算法多级反馈队列（*Multilevel Feedback Queue*）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展。\n顾名思义：\n\n「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。\n「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；\n\n\n\n\n\n来看看，它是如何工作的：\n\n设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高时间片越短；\n新的进程会被放入到第一级队列的末尾，按先来先服务的原则排队等待被调度，如果在第一级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；\n当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进入较高优先级的队列，则停止当前运行的进程并将其移入到原队列末尾，接着让较高优先级的进程运行；\n\n可以发现，对于短作业可能可以在第一级队列很快被处理完。对于长作业，如果在第一级队列处理不完，可以移入下次队列等待被执行，虽然等待的时间变长了，但是运行时间也变更长了，所以该算法很好的兼顾了长短作业，同时有较好的响应时间。\n进程间通信每个进程的用户地址空间都是独立的，一般而言是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。\n管道\n\n\n\n同时，我们得知上面这种管道是没有名字，所以「|」表示的管道称为匿名管道，用完了就销毁。\n管道还有另外一个类型是命名管道，也被叫做 FIFO，因为数据是先进先出的传输方式。\n在使用命名管道前，先需要通过 mkfifo 命令来创建，并且指定管道名字：\n$ mkfifo myPipe\n\nmyPipe 就是这个管道的名称，基于 Linux 一切皆文件的理念，所以管道也是以文件的方式存在，我们可以用 ls 看一下，这个文件的类型是 p，也就是 pipe（管道） 的意思：\n$ ls -l\nprw-r--r--. 1 root    root         0 Jul 17 02:45 myPipe\n\n接下来，我们往 myPipe 这个管道写入数据：\n$ echo \"hello\" > myPipe  // 将数据写进管道\n                         // 停住了 ...\n\n你操作了后，你会发现命令执行后就停在这了，这是因为管道里的内容没有被读取，只有当管道里的数据被读完后，命令才可以正常退出。\n于是，我们执行另外一个命令来读取这个管道里的数据：\n$ cat &lt; myPipe  // 读取管道里的数据\nhello\n\n可以看到，管道里的内容被读取出来了，并打印在了终端上，另外一方面，echo 那个命令也正常退出了。\n我们可以看出，管道这种通信方式效率低，不适合进程间频繁地交换数据。当然，它的好处，自然就是简单，同时也我们很容易得知管道里的数据已经被另一个进程读取了。\n消息队列前面说到管道的通信方式是效率低的，因此管道不适合进程间频繁地交换数据。\n对于这个问题，消息队列的通信模式就可以解决。比如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。\n再来，消息队列是保存在内核中的消息链表，在发送数据时，会分成一个一个独立的数据单元，也就是消息体（数据块），消息体是用户自定义的数据类型，消息的发送方和接收方要约定好消息体的数据类型，所以每个消息体都是固定大小的存储块，不像管道是无格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。\n消息队列生命周期随内核，如果没有释放消息队列或者没有关闭操作系统，消息队列会一直存在，而前面提到的匿名管道的生命周期，是随进程的创建而建立，随进程的结束而销毁。\n消息这种模型，两个进程之间的通信就像平时发邮件一样，你来一封，我回一封，可以频繁沟通了。\n但邮件的通信方式存在不足的地方有两点，一是通信不及时，二是附件也有大小限制，这同样也是消息队列通信不足的点。\n消息队列不适合比较大数据的传输，因为在内核中每个消息体都有一个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限。在 Linux 内核中，会有两个宏定义 MSGMAX 和 MSGMNB，它们以字节为单位，分别定义了一条消息的最大长度和一个队列的最大长度。\n消息队列通信过程中，存在用户态与内核态之间的数据拷贝开销，因为进程写入数据到内核中的消息队列时，会发生从用户态拷贝数据到内核态的过程，同理另一进程读取内核中的消息数据时，会发生从内核态拷贝数据到用户态的过程。\n共享内存消息队列的读取和写入的过程，都会有发生用户态与内核态之间的消息拷贝过程。那共享内存的方式，就很好的解决了这一问题。\n现代操作系统，对于内存管理，采用的是虚拟内存技术，也就是每个进程都有自己独立的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是一样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。\n共享内存的机制，就是拿出一块虚拟地址空间来，映射到相同的物理内存中。这样这个进程写入的东西，另外一个进程马上就能看到了，都不需要拷贝来拷贝去，传来传去，大大提高了进程间通信的速度。\n信号量用了共享内存通信方式，带来新的问题，那就是如果多个进程同时修改同一个共享内存，很有可能就冲突了。例如两个进程都同时写一个地址，那先写的那个进程会发现内容被别人覆盖了。\n为了防止多进程竞争共享资源，而造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被一个进程访问。正好，信号量就实现了这一保护机制。\n信号量其实是一个整型的计数器，主要用于实现进程间的互斥与同步，而不是用于缓存进程间通信的数据。\n信号量表示资源的数量，控制信号量的方式有两种原子操作：\n\n一个是 P 操作，这个操作会把信号量减去 1，相减后如果信号量 &lt; 0，则表明资源已被占用，进程需阻塞等待；相减后如果信号量 &gt;&#x3D; 0，则表明还有资源可使用，进程可正常继续执行。\n另一个是 V 操作，这个操作会把信号量加上 1，相加后如果信号量 &lt;&#x3D; 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运行；相加后如果信号量 &gt; 0，则表明当前没有阻塞中的进程；\n\nP 操作是用在进入共享资源之前，V 操作是用在离开共享资源之后，这两个操作是必须成对出现的。\n接下来，举个例子，如果要使得两个进程互斥访问共享内存，我们可以初始化信号量为 1。\n具体的过程如下：\n\n进程 A 在访问共享内存前，先执行了 P 操作，由于信号量的初始值为 1，故在进程 A 执行 P 操作后信号量变为 0，表示共享资源可用，于是进程 A 就可以访问共享内存。\n若此时，进程 B 也想访问共享内存，执行了 P 操作，结果信号量变为了 -1，这就意味着临界资源已被占用，因此进程 B 被阻塞。\n直到进程 A 访问完共享内存，才会执行 V 操作，使得信号量恢复为 0，接着就会唤醒阻塞中的线程 B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执行 V 操作，使信号量恢复到初始值 1。\n\n可以发现，信号初始化为 1，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有一个进程在访问，这就很好的保护了共享内存。\n另外，在多进程里，每个进程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个进程能密切合作，以实现一个共同的任务。\n例如，进程 A 是负责生产数据，而进程 B 是负责读取数据，这两个进程是相互合作、相互依赖的，进程 A 必须先生产了数据，进程 B 才能读取到数据，所以执行是有前后顺序的。\n那么这时候，就可以用信号量来实现多进程同步的方式，我们可以初始化信号量为 0。\n具体过程：\n\n如果进程 B 比进程 A 先执行了，那么执行到 P 操作时，由于信号量初始值为 0，故信号量会变为 -1，表示进程 A 还没生产数据，于是进程 B 就阻塞等待；\n接着，当进程 A 生产完数据后，执行了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；\n最后，进程 B 被唤醒后，意味着进程 A 已经生产了数据，于是进程 B 就可以正常读取数据了。\n\n可以发现，信号初始化为 0，就代表着是同步信号量，它可以保证进程 A 应在进程 B 之前执行。\n信号对于异常情况下的工作模式，就需要用「信号」的方式来通知进程。\n在 Linux 操作系统中， 为了响应各种各样的事件，提供了几十种信号，分别代表不同的意义。我们可以通过 kill -l 命令，查看所有的信号：\n$ kill -l\n 1) SIGHUP       2) SIGINT       3) SIGQUIT      4) SIGILL       5) SIGTRAP\n 6) SIGABRT      7) SIGBUS       8) SIGFPE       9) SIGKILL     10) SIGUSR1\n11) SIGSEGV     12) SIGUSR2     13) SIGPIPE     14) SIGALRM     15) SIGTERM\n16) SIGSTKFLT   17) SIGCHLD     18) SIGCONT     19) SIGSTOP     20) SIGTSTP\n21) SIGTTIN     22) SIGTTOU     23) SIGURG      24) SIGXCPU     25) SIGXFSZ\n26) SIGVTALRM   27) SIGPROF     28) SIGWINCH    29) SIGIO       30) SIGPWR\n31) SIGSYS      34) SIGRTMIN    35) SIGRTMIN+1  36) SIGRTMIN+2  37) SIGRTMIN+3\n38) SIGRTMIN+4  39) SIGRTMIN+5  40) SIGRTMIN+6  41) SIGRTMIN+7  42) SIGRTMIN+8\n43) SIGRTMIN+9  44) SIGRTMIN+10 45) SIGRTMIN+11 46) SIGRTMIN+12 47) SIGRTMIN+13\n48) SIGRTMIN+14 49) SIGRTMIN+15 50) SIGRTMAX-14 51) SIGRTMAX-13 52) SIGRTMAX-12\n53) SIGRTMAX-11 54) SIGRTMAX-10 55) SIGRTMAX-9  56) SIGRTMAX-8  57) SIGRTMAX-7\n58) SIGRTMAX-6  59) SIGRTMAX-5  60) SIGRTMAX-4  61) SIGRTMAX-3  62) SIGRTMAX-2\n63) SIGRTMAX-1  64) SIGRTMAX\n\n运行在 shell 终端的进程，我们可以通过键盘输入某些组合键的时候，给进程发送信号。例如\n\nCtrl+C 产生 SIGINT 信号，表示终止该进程；\nCtrl+Z 产生 SIGTSTP 信号，表示停止该进程，但还未结束；\n\n如果进程在后台运行，可以通过 kill 命令的方式给进程发送信号，但前提需要知道运行中的进程 PID 号，例如：\n\nkill -9 1050 ，表示给 PID 为 1050 的进程发送 SIGKILL 信号，用来立即结束该进程；\n\n所以，信号事件的来源主要有硬件来源（如键盘 Cltr+C ）和软件来源（如 kill 命令）。\n信号是进程间通信机制中唯一的异步通信机制，因为可以在任何时候发送信号给某一进程，一旦有信号产生，我们就有下面这几种，用户进程对信号的处理方式。\n1.执行默认操作。Linux 对每种信号都规定了默认操作，例如，上面列表中的 SIGTERM 信号，就是终止进程的意思。\n2.捕捉信号。我们可以为信号定义一个信号处理函数。当信号发生时，我们就执行相应的信号处理函数。\n3.忽略信号。当我们不希望处理某些信号的时候，就可以忽略该信号，不做任何处理。有两个信号是应用进程无法捕捉和忽略的，即 SIGKILL 和 SEGSTOP，它们用于在任何时候中断或结束某一进程。\nSocket前面提到的管道、消息队列、共享内存、信号量和信号都是在同一台主机上进行进程间通信，那要想跨网络与不同主机上的进程之间通信，就需要 Socket 通信了。\n实际上，Socket 通信不仅可以跨网络与不同主机的进程间通信，还可以在同主机上进程间通信。\n创建 socket 的系统调用：\nint socket(int domain, int type, int protocal)\n\n三个参数分别代表：\n\ndomain 参数用来指定协议族，比如 AF_INET 用于 IPV4、AF_INET6 用于 IPV6、AF_LOCAL&#x2F;AF_UNIX 用于本机；\ntype 参数用来指定通信特性，比如 SOCK_STREAM 表示的是字节流，对应 TCP、SOCK_DGRAM 表示的是数据报，对应 UDP、SOCK_RAW 表示的是原始套接字；\nprotocal 参数原本是用来指定通信协议的，但现在基本废弃。因为协议已经通过前面两个参数指定完成，protocol 目前一般写成 0 即可；\n\n根据创建 socket 类型的不同，通信的方式也就不同：\n\n实现 TCP 字节流通信： socket 类型是 AF_INET 和 SOCK_STREAM；\n实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM；\n实现本地进程间通信： 「本地字节流 socket 」类型是 AF_LOCAL 和 SOCK_STREAM，「本地数据报 socket 」类型是 AF_LOCAL 和 SOCK_DGRAM。另外，AF_UNIX 和 AF_LOCAL 是等价的，所以 AF_UNIX 也属于本地 socket；\n\n针对 TCP 协议通信的 socket 编程模型\n\n\n\n\n服务端和客户端初始化 socket，得到文件描述符；\n服务端调用 bind，将绑定在 IP 地址和端口;\n服务端调用 listen，进行监听；\n服务端调用 accept，等待客户端连接；\n客户端调用 connect，向服务器端的地址和端口发起连接请求；\n服务端 accept 返回用于传输的 socket 的文件描述符；\n客户端调用 write 写入数据；服务端调用 read 读取数据；\n客户端断开连接时，会调用 close，那么服务端 read 读取数据的时候，就会读取到了 EOF，待处理完数据后，服务端调用 close，表示连接关闭。\n\n这里需要注意的是，服务端调用 accept 时，连接成功了会返回一个已完成连接的 socket，后续用来传输数据。\n所以，监听的 socket 和真正用来传送数据的 socket，是「两个」 socket，一个叫作监听 socket，一个叫作已完成连接 socket。\n成功连接建立之后，双方开始通过 read 和 write 函数来读写数据，就像往一个文件流里面写东西一样。\n针对 UDP 协议通信的 socket 编程模型\n\n\n\nUDP 是没有连接的，所以不需要三次握手，也就不需要像 TCP 调用 listen 和 connect，但是 UDP 的交互仍然需要 IP 地址和端口号，因此也需要 bind。\n对于 UDP 来说，不需要要维护连接，那么也就没有所谓的发送方和接收方，甚至都不存在客户端和服务端的概念，只要有一个 socket 多台机器就可以任意通信，因此每一个 UDP 的 socket 都需要 bind。\n另外，每次通信时，调用 sendto 和 recvfrom，都要传入目标主机的 IP 地址和端口。\n针对本地进程间通信的 socket 编程模型本地 socket 被用于在同一台主机上进程间通信的场景：\n\n本地 socket 的编程接口和 IPv4 、IPv6 套接字编程接口是一致的，可以支持「字节流」和「数据报」两种协议；\n本地 socket 的实现效率大大高于 IPv4 和 IPv6 的字节流、数据报 socket 实现；\n\n对于本地字节流 socket，其 socket 类型是 AF_LOCAL 和 SOCK_STREAM。\n对于本地数据报 socket，其 socket 类型是 AF_LOCAL 和 SOCK_DGRAM。\n本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端口，而是绑定一个本地文件，这也就是它们之间的最大区别。\n多线程冲突竞争与协作\n\n\n\n\n\n\n\n\n在单核 CPU 系统里，为了实现多个程序同时运行的假象，操作系统通常以时间片调度的方式，让每个进程执行每次执行一个时间片，时间片用完了，就切换下一个进程运行，由于这个时间片的时间很短，于是就造成了「并发」的现象。\n另外，操作系统也为每个进程创建巨大、私有的虚拟内存的假象，这种地址空间的抽象让每个程序好像拥有自己的内存，而实际上操作系统在背后秘密地让多个地址空间「复用」物理内存或者磁盘。\n如果一个程序只有一个执行流程，也代表它是单线程的。当然一个程序可以有多个执行流程，也就是所谓的多线程程序，线程是调度的基本单位，进程则是资源分配的基本单位。\n多个线程如果竞争共享资源，如果不采取有效的措施，则会造成共享数据的混乱。\n我们做个小实验，创建两个线程，它们分别对共享变量 i 自增 1 执行 10000 次，如下代码：\n#include &quot;iostream&quot;\n#include &lt;thread&gt;\n\nint i &#x3D;0;\nint count &#x3D;0;\n\nvoid test()&#123;\n    int num &#x3D;10000;\n\n    for(int n&#x3D;0;n&lt;num;n++)&#123;\n        i &#x3D; i+1;\n    &#125;\n&#125;\nint main()&#123;\n    for(int j &#x3D;0;j&lt;100000;j++)&#123;\n        i&#x3D;0;\n        &#x2F;&#x2F;std::cout&lt;&lt;&quot;start&quot;&lt;&lt;std::endl;\n\n        std::thread thread_test1(test);\n        std::thread thread_test2(test);\n\n        thread_test1.join();\n        thread_test2.join();\n        if(i!&#x3D;20000) &#123;\n            &#x2F;&#x2F;std::cout&lt;&lt;i&lt;&lt;std::endl;\n            count++;\n        &#125;\n        &#x2F;&#x2F;std::cout&lt;&lt;&quot;all joined&quot;&lt;&lt;std::endl;\n        &#x2F;&#x2F;::cout&lt;&lt;&quot;now i is&quot;&lt;&lt;i&lt;&lt;std::endl;\n    &#125;\n    std::cout&lt;&lt;&quot;count:&quot;&lt;&lt;count&lt;&lt;std::endl;\n    return 0;\n&#125;\n\ncount:2513&#x2F;&#x2F;结果为2513次count并不等于20000\n\n在这个例子中，我们只是想给 i 加上数字 1，那么它对应的汇编指令执行过程是这样的：\n\n\n\n\n可以发现，只是单纯给 i 加上数字 1，在 CPU 运行的时候，实际上要执行 3 条指令。\n设想我们的线程 1 进入这个代码区域，它将 i 的值（假设此时是 50 ）从内存加载到它的寄存器中，然后它向寄存器加 1，此时在寄存器中的 i 值是 51。\n现在，一件不幸的事情发生了：时钟中断发生。因此，操作系统将当前正在运行的线程的状态保存到线程的线程控制块 TCB。\n现在更糟的事情发生了，线程 2 被调度运行，并进入同一段代码。它也执行了第一条指令，从内存获取 i 值并将其放入到寄存器中，此时内存中 i 的值仍为 50，因此线程 2 寄存器中的 i 值也是 50。假设线程 2 执行接下来的两条指令，将寄存器中的 i 值 + 1，然后将寄存器中的 i 值保存到内存中，于是此时全局变量 i 值是 51。\n最后，又发生一次上下文切换，线程 1 恢复执行。还记得它已经执行了两条汇编指令，现在准备执行最后一条指令。回忆一下， 线程 1 寄存器中的 i 值是51，因此，执行最后一条指令后，将值保存到内存，全局变量 i 的值再次被设置为 51。\n简单来说，增加 i （值为 50 ）的代码被运行两次，按理来说，最后的 i 值应该是 52，但是由于不可控的调度，导致最后 i 值却是 51。\n互斥上面展示的情况称为竞争条件（*race condition*），当多线程相互竞争操作共享变量时，由于运气不好，即在执行过程中发生了上下文切换，我们得到了错误的结果，事实上，每次运行都可能得到不同的结果，因此输出的结果存在不确定性（*indeterminate*）。\n由于多线程执行操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为临界区（*critical section*），它是访问共享资源的代码片段，一定不能给多线程同时执行。\n我们希望这段代码是互斥（*mutualexclusion*）的，也就说保证一个线程在临界区执行时，其他线程应该被阻止进入临界区，说白了，就是这段代码执行过程中，最多只能出现一个线程。\n同步的概念互斥解决了并发进程&#x2F;线程对临界区的使用问题。这种基于临界区控制的交互作用是比较简单的，只要一个进程&#x2F;线程进入了临界区，其他试图想进入临界区的进程&#x2F;线程都会被阻塞着，直到第一个进程&#x2F;线程离开了临界区。\n我们都知道在多线程里，每个线程并不一定是顺序执行的，它们基本是以各自独立的、不可预知的速度向前推进，但有时候我们又希望多个线程能密切合作，以实现一个共同的任务。\n例子，线程 1 是负责读入数据的，而线程 2 是负责处理数据的，这两个线程是相互合作、相互依赖的。线程 2 在没有收到线程 1 的唤醒通知时，就会一直阻塞等待，当线程 1 读完数据需要把数据传给线程 2 时，线程 1 会唤醒线程 2，并把数据交给线程 2 处理。\n所谓同步，就是并发进程&#x2F;线程在一些关键点上可能需要互相等待与互通消息，这种相互制约的等待与互通信息称为进程&#x2F;线程同步。\n注意，同步与互斥是两种不同的概念：\n\n同步就好比：「操作 A 应在操作 B 之前执行」，「操作 C 必须在操作 A 和操作 B 都完成之后才能执行」等；\n互斥就好比：「操作 A 和操作 B 不能在同一时刻执行」；\n\n互斥与同步的实现在进程&#x2F;线程并发执行的过程中，进程&#x2F;线程之间存在协作的关系，例如有互斥、同步的关系。\n为了实现进程&#x2F;线程间正确的协作，操作系统必须提供实现进程协作的措施和方法，主要的方法有两种：\n\n锁：加锁、解锁操作；\n信号量：P、V 操作；\n\n这两个都可以方便地实现进程&#x2F;线程互斥，而信号量比锁的功能更强一些，它还可以方便地实现进程&#x2F;线程同步。\n锁使用加锁操作和解锁操作可以解决并发线程&#x2F;进程的互斥问题。\n任何想进入临界区的线程，必须先执行加锁操作。若加锁操作顺利通过，则线程可进入临界区；在完成对临界资源的访问后再执行解锁操作，以释放该临界资源。\n根据锁的实现不同，可以分为「忙等待锁」和「无忙等待锁」。\n忙等待锁在说明「忙等待锁」的实现之前，先介绍现代 CPU 体系结构提供的特殊原子操作指令 —— 测试和置位（*Test-and-Set*）指令。\n测试并设置指令做了下述事情:\n\n把 old_ptr 更新为 new 的新值\n返回 old_ptr 的旧值；\n\n当然，关键是这些代码是原子执行。因为既可以测试旧值，又可以设置新值，所以我们把这条指令叫作「测试并设置」。\n那什么是原子操作呢？原子操作就是要么全部执行，要么都不执行，不能出现执行到一半的中间状态\n#include &quot;iostream&quot;\n#include &lt;thread&gt;\n#include &quot;atomic&quot;\n\nint i &#x3D;0;\nint count &#x3D;0;\nint TestAndSet(int *old_ptr,int ne) &#123;\n    int old &#x3D; *old_ptr;\n    *old_ptr &#x3D; ne;\n    return old;\n&#125;&#x2F;&#x2F;testandset的原型，但是不能直接这么使用，单纯的函数定义无法保证原子性必须调用库函数实现。\n\nclass lock_t&#123;\npublic:\n    lock_t()&#123;&#125;\n    void lock()&#123;\n        while(std::atomic_flag_test_and_set(&amp;flag) &#x3D;&#x3D; 1);\n    &#125;\n    void unlock()&#123;\n        std::atomic_flag_clear(&amp;flag);\n    &#125;\n    std::atomic_flag flag;\n&#125;;\nvoid test(lock_t* lock)&#123;\n    int num &#x3D;10000;\n    for(int n&#x3D;0;n&lt;num;n++)&#123;\n        lock-&gt;lock();\n        i &#x3D; i+1;\n        lock-&gt;unlock();\n    &#125;\n&#125;\nint main()&#123;\n    lock_t lock;\n    for(int j &#x3D;0;j&lt;1000;j++)&#123;\n        i&#x3D;0;\n        &#x2F;&#x2F;std::cout&lt;&lt;&quot;start&quot;&lt;&lt;std::endl;\n\n        std::thread thread_test1(test,&amp;lock);\n        std::thread thread_test2(test,&amp;lock);\n\n        thread_test1.join();\n        thread_test2.join();\n        if(i!&#x3D;20000) &#123;\n            &#x2F;&#x2F;std::cout&lt;&lt;i&lt;&lt;std::endl;\n            count++;\n        &#125;\n        &#x2F;&#x2F;std::cout&lt;&lt;&quot;all joined&quot;&lt;&lt;std::endl;\n        &#x2F;&#x2F;::cout&lt;&lt;&quot;now i is&quot;&lt;&lt;i&lt;&lt;std::endl;\n    &#125;\n    std::cout&lt;&lt;&quot;count:&quot;&lt;&lt;count&lt;&lt;std::endl;\n    return 0;\n&#125;\n\n我们来确保理解为什么这个锁能工作：\n\n第一个场景是，首先假设一个线程在运行，调用 lock()，没有其他线程持有锁，所以 flag 是 0。当调用 TestAndSet(flag, 1) 方法，返回 0，线程会跳出 while 循环，获取锁。同时也会原子的设置 flag 为1，标志锁已经被持有。当线程离开临界区，调用 unlock() 将 flag 清理为 0。\n第二种场景是，当某一个线程已经持有锁（即 flag 为1）。本线程调用 lock()，然后调用 TestAndSet(flag, 1)，这一次返回 1。只要另一个线程一直持有锁，TestAndSet() 会重复返回 1，本线程会一直忙等。当 flag 终于被改为 0，本线程会调用 TestAndSet()，返回 0 并且原子地设置为 1，从而获得锁，进入临界区。\n\n很明显，当获取不到锁时，线程就会一直 while 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为自旋锁（*spin lock*）。\n这是最简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。在单处理器上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。\n无等待锁无等待锁顾明思议就是获取不到锁的时候，不用自旋。\n既然不想自旋，那当没获取到锁的时候，就把当前线程放入到锁的等待队列，然后执行调度程序，把 CPU 让给其他线程执行。\n\n\n\n\n信号量信号量是操作系统提供的一种协调共享资源访问的方法。\n通常信号量表示资源的数量，对应的变量是一个整型（sem）变量。\n另外，还有两个原子操作的系统调用函数来控制信号量的，分别是：\n\nP 操作：将 sem 减 1，相减后，如果 sem &lt; 0，则进程&#x2F;线程进入阻塞等待，否则继续，表明 P 操作可能会阻塞；\nV 操作：将 sem 加 1，相加后，如果 sem &lt;= 0，唤醒一个等待中的进程&#x2F;线程，表明 V 操作不会阻塞；\n\n\n\n\n\n信号量不仅可以实现临界区的互斥访问控制，还可以线程间的事件同步。\n我们先来说说如何使用信号量实现临界区的互斥访问。\n为每类共享资源设置一个信号量 s，其初值为 1，表示该临界资源未被占用。\n只要把进入临界区的操作置于 P(s) 和 V(s) 之间，即可实现进程&#x2F;线程互斥：\n此时，任何想进入临界区的线程，必先在互斥信号量上执行 P 操作，在完成对临界资源的访问后再执行 V 操作。由于互斥信号量的初始值为 1，故在第一个线程执行 P 操作后 s 值变为 0，表示临界资源为空闲，可分配给该线程，使之进入临界区。\n若此时又有第二个线程想进入临界区，也应先执行 P 操作，结果使 s 变为负值，这就意味着临界资源已被占用，因此，第二个线程被阻塞。\n并且，直到第一个线程执行 V 操作，释放临界资源而恢复 s 值为 0 后，才唤醒第二个线程，使之进入临界区，待它完成临界资源的访问后，又执行 V 操作，使 s 恢复到初始值 1。\n对于两个并发线程，互斥信号量的值仅取 1、0 和 -1 三个值，分别表示：\n\n如果互斥信号量为 1，表示没有线程进入临界区；\n如果互斥信号量为 0，表示有一个线程进入临界区；\n如果互斥信号量为 -1，表示一个线程进入临界区，另一个线程等待进入。\n\n通过互斥信号量的方式，就能保证临界区任何时刻只有一个线程在执行，就达到了互斥的效果。\n生产者-消费者问题描述：\n\n生产者在生成数据后，放在一个缓冲区中；\n消费者从缓冲区取出数据处理；\n任何时刻，只能有一个生产者或消费者可以访问缓冲区；\n\n我们对问题分析可以得出：\n\n任何时刻只能有一个线程操作缓冲区，说明操作缓冲区是临界代码，需要互斥；\n缓冲区空时，消费者必须等待生产者生成数据；缓冲区满时，生产者必须等待消费者取出数据。说明生产者和消费者需要同步。\n\n那么我们需要三个信号量，分别是：\n\n互斥信号量 mutex：用于互斥访问缓冲区，初始化值为 1；\n资源信号量 fullBuffers：用于消费者询问缓冲区是否有数据，有数据则读取数据，初始化值为 0（表明缓冲区一开始为空）；\n资源信号量 emptyBuffers：用于生产者询问缓冲区是否有空位，有空位则生成数据，初始化值为 n （缓冲区大小）；\n\n#include &quot;iostream&quot;\n#include &quot;thread&quot;\n#include &lt;mutex&gt;\n#include &quot;condition_variable&quot;\nclass MySemaphore\n&#123;\nprivate:\n    int count;\n    std::mutex mx;\n    std::condition_variable cv;\npublic:\n    MySemaphore(int val &#x3D; 1) :count(val) &#123;&#125;&#x2F;&#x2F;默认实参\n    void P()\n    &#123;\n        std::unique_lock&lt;std::mutex&gt; lock(mx);\n        if (--count &lt; 0)\n        &#123;\n            cv.wait(lock);\n        &#125;\n    &#125;\n    void V()\n    &#123;\n        std::unique_lock&lt;std::mutex&gt; lock(mx);\n        if (++count &lt;&#x3D; 0)\n        &#123;\n            cv.notify_one();\n        &#125;\n    &#125;\n&#125;;\nint g_num &#x3D; 0;\nMySemaphore semp(1);&#x2F;&#x2F;生产\nMySemaphore sems(0);&#x2F;&#x2F;消费\n\nvoid P(int id)\n&#123;\n    for (int i &#x3D; 0; i &lt; 10; ++i)\n    &#123;\n        semp.P();\n        g_num &#x3D; i;\n        std::cout &lt;&lt; &quot;P &quot; &lt;&lt; g_num &lt;&lt; std::endl;\n        sems.V();\n    &#125;\n&#125;\nvoid S(int id)\n&#123;\n    for (int i &#x3D; 0; i &lt; 10; ++i)\n    &#123;\n        sems.P();\n        std::cout &lt;&lt; &quot;S&quot; &lt;&lt; g_num &lt;&lt; std::endl;\n        semp.V();\n    &#125;\n&#125;\nint main()\n&#123;\n    std::thread thp(P,1);\n    std::thread ths(S,1);\n    thp.join();\n    ths.join();\n    return 0;\n&#125;\n\n如果消费者线程一开始执行 P(fullBuffers)，由于信号量 fullBuffers 初始值为 0，则此时 fullBuffers 的值从 0 变为 -1，说明缓冲区里没有数据，消费者只能等待。\n接着，轮到生产者执行 P(emptyBuffers)，表示减少 1 个空槽，如果当前没有其他生产者线程在临界区执行代码，那么该生产者线程就可以把数据放到缓冲区，放完后，执行 V(fullBuffers) ，信号量 fullBuffers 从 -1 变成 0，表明有「消费者」线程正在阻塞等待数据，于是阻塞等待的消费者线程会被唤醒。\n消费者线程被唤醒后，如果此时没有其他消费者线程在读数据，那么就可以直接进入临界区，从缓冲区读取数据。最后，离开临界区后，把空槽的个数 + 1。\n死锁\n\n\n\n\n\n\n\n\n那么，当两个线程为了保护两个不同的共享资源而使用了两个互斥锁，那么这两个互斥锁应用不当的时候，可能会造成两个线程都在等待对方释放锁，在没有外力的作用下，这些线程会一直相互等待，就没办法继续运行，这种情况就是发生了死锁。\n死锁只有同时满足以下四个条件才会发生：\n\n互斥条件；\n\n持有并等待条件；\n\n不可剥夺条件；\n\n环路等待条件；\n\n互斥条件\n\n\n互斥条件是指多个线程不能同时使用同一个资源。\n比如下图，如果线程 A 已经持有的资源，不能再同时被线程 B 持有，如果线程 B 请求获取线程 A 已经占用的资源，那线程 B 只能等待，直到线程 A 释放了资源。\n\n持有并等待条件\n\n持有并等待条件是指，当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是线程 A 在等待资源 2 的同时并不会释放自己已经持有的资源 1。\n\n不可剥夺条件\n\n不可剥夺条件是指，当线程已经持有了资源 ，在自己使用完之前不能被其他线程获取，线程 B 如果也想使用此资源，则只能在线程 A 使用完并释放后才能获取。\n\n环路等待条件\n\n环路等待条件指的是，在死锁发生的时候，两个线程获取资源的顺序构成了环形链。\n比如，线程 A 已经持有资源 2，而想请求资源 1， 线程 B 已经获取了资源 1，而想请求资源 2，这就形成资源请求等待的环形图。\n#include &quot;thread&quot;\n#include &quot;iostream&quot;\n#include &quot;mutex&quot;\n#include &quot;unistd.h&quot;\n\npthread_mutex_t mutex_A &#x3D; PTHREAD_MUTEX_INITIALIZER;\npthread_mutex_t mutex_B &#x3D; PTHREAD_MUTEX_INITIALIZER;\n\n\nvoid *threadB_proc(void *data)\n&#123;\n    printf(&quot;thread B waiting get ResourceB \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_B);\n    printf(&quot;thread B got ResourceB \\n&quot;);\n\n    sleep(1);\n\n    printf(&quot;thread B waiting  get ResourceA \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_A);\n    printf(&quot;thread B got ResourceA \\n&quot;);\n\n    pthread_mutex_unlock(&amp;mutex_A);\n    pthread_mutex_unlock(&amp;mutex_B);\n    return (void *)0;\n&#125;\n\nvoid *threadA_proc(void *data)\n&#123;\n    printf(&quot;thread A waiting get ResourceA \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_A);\n    printf(&quot;thread A got ResourceA \\n&quot;);\n\n    sleep(1);\n\n    printf(&quot;thread A waiting get ResourceB \\n&quot;);\n    pthread_mutex_lock(&amp;mutex_B);\n    printf(&quot;thread A got ResourceB \\n&quot;);\n\n    pthread_mutex_unlock(&amp;mutex_B);\n    pthread_mutex_unlock(&amp;mutex_A);\n    return (void *)0;\n&#125;\n\nint main()\n&#123;\n    pthread_t tidA, tidB;\n\n    &#x2F;&#x2F;创建两个线程\n    pthread_create(&amp;tidA, NULL, threadA_proc, NULL);\n    pthread_create(&amp;tidB, NULL, threadB_proc, NULL);\n\n    pthread_join(tidA, NULL);\n    pthread_join(tidB, NULL);\n\n    printf(&quot;exit\\n&quot;);\n\n    return 0;\n&#125;\n\n可以看到线程 B 在等待互斥锁 A 的释放，线程 A 在等待互斥锁 B 的释放，双方都在等待对方资源的释放，很明显，产生了死锁问题。\n\n利用工具排查死锁问题在 Linux 下，我们可以使用 pstack + gdb 工具来定位死锁问题。\npstack 命令可以显示每个线程的栈跟踪信息（函数调用过程），它的使用方式也很简单，只需要 pstack &lt;pid&gt; 就可以了。\n那么，在定位死锁问题时，我们可以多次执行 pstack 命令查看线程的函数调用过程，多次对比结果，确认哪几个线程一直没有变化，且是因为在等待锁，那么大概率是由于死锁问题导致的。\n我用 pstack 输出了我前面模拟死锁问题的进程的所有线程的情况，我多次执行命令后，其结果都一样，如下：\n$ pstack 87746\nThread 3 (Thread 0x7f60a610a700 (LWP 87747)):\n#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0\n#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0\n#3  0x0000000000400725 in threadA_proc ()\n#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0\n#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6\nThread 2 (Thread 0x7f60a5709700 (LWP 87748)):\n#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0\n#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0\n#3  0x0000000000400792 in threadB_proc ()\n#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0\n#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6\nThread 1 (Thread 0x7f60a610c700 (LWP 87746)):\n#0  0x0000003720e080e5 in pthread_join () from /lib64/libpthread.so.0\n#1  0x0000000000400806 in main ()\n\n....\n\n$ pstack 87746\nThread 3 (Thread 0x7f60a610a700 (LWP 87747)):\n#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0\n#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0\n#3  0x0000000000400725 in threadA_proc ()\n#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0\n#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6\nThread 2 (Thread 0x7f60a5709700 (LWP 87748)):\n#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0\n#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0\n#3  0x0000000000400792 in threadB_proc ()\n#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0\n#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6\nThread 1 (Thread 0x7f60a610c700 (LWP 87746)):\n#0  0x0000003720e080e5 in pthread_join () from /lib64/libpthread.so.0\n#1  0x0000000000400806 in main ()\n\n可以看到，Thread 2 和 Thread 3 一直阻塞获取锁（pthread_mutex_lock）的过程，而且 pstack 多次输出信息都没有变化，那么可能大概率发生了死锁。\n但是，还不能够确认这两个线程是在互相等待对方的锁的释放，因为我们看不到它们是等在哪个锁对象，于是我们可以使用 gdb 工具进一步确认。\n整个 gdb 调试过程，如下：\n// gdb 命令\n$ gdb -p 87746\n\n// 打印所有的线程信息\n(gdb) info thread\n  3 Thread 0x7f60a610a700 (LWP 87747)  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n  2 Thread 0x7f60a5709700 (LWP 87748)  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n* 1 Thread 0x7f60a610c700 (LWP 87746)  0x0000003720e080e5 in pthread_join () from /lib64/libpthread.so.0\n//最左边的 * 表示 gdb 锁定的线程，切换到第二个线程去查看\n\n// 切换到第2个线程\n(gdb) thread 2\n[Switching to thread 2 (Thread 0x7f60a5709700 (LWP 87748))]#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0 \n\n// bt 可以打印函数堆栈，却无法看到函数参数，跟 pstack 命令一样 \n(gdb) bt\n#0  0x0000003720e0da1d in __lll_lock_wait () from /lib64/libpthread.so.0\n#1  0x0000003720e093ca in _L_lock_829 () from /lib64/libpthread.so.0\n#2  0x0000003720e09298 in pthread_mutex_lock () from /lib64/libpthread.so.0\n#3  0x0000000000400792 in threadB_proc (data=0x0) at dead_lock.c:25\n#4  0x0000003720e07893 in start_thread () from /lib64/libpthread.so.0\n#5  0x00000037206f4bfd in clone () from /lib64/libc.so.6\n\n// 打印第三帧信息，每次函数调用都会有压栈的过程，而 frame 则记录栈中的帧信息\n(gdb) frame 3\n#3  0x0000000000400792 in threadB_proc (data=0x0) at dead_lock.c:25\n27    printf(\"thread B waiting get ResourceA \\n\");\n28    pthread_mutex_lock(&amp;mutex_A);\n\n// 打印mutex_A的值 ,  __owner表示gdb中标示线程的值，即LWP\n(gdb) p mutex_A\n$1 = &#123;__data = &#123;__lock = 2, __count = 0, __owner = 87747, __nusers = 1, __kind = 0, __spins = 0, __list = &#123;__prev = 0x0, __next = 0x0&#125;&#125;, \n  __size = \"\\002\\000\\000\\000\\000\\000\\000\\000\\303V\\001\\000\\001\", '\\000' &lt;repeats 26 times>, __align = 2&#125;\n\n// 打印mutex_B的值 ,  __owner表示gdb中标示线程的值，即LWP\n(gdb) p mutex_B\n$2 = &#123;__data = &#123;__lock = 2, __count = 0, __owner = 87748, __nusers = 1, __kind = 0, __spins = 0, __list = &#123;__prev = 0x0, __next = 0x0&#125;&#125;, \n  __size = \"\\002\\000\\000\\000\\000\\000\\000\\000\\304V\\001\\000\\001\", '\\000' &lt;repeats 26 times>, __align = 2&#125;  \n\n我来解释下，上面的调试过程：\n\n通过 info thread 打印了所有的线程信息，可以看到有 3 个线程，一个是主线程（LWP 87746），另外两个都是我们自己创建的线程（LWP 87747 和 87748）；\n通过 thread 2，将切换到第 2 个线程（LWP 87748）；\n通过 bt，打印线程的调用栈信息，可以看到有 threadB_proc 函数，说明这个是线程 B 函数，也就说 LWP 87748 是线程 B;\n通过 frame 3，打印调用栈中的第三个帧的信息，可以看到线程 B 函数，在获取互斥锁 A 的时候阻塞了；\n通过 p mutex_A，打印互斥锁 A 对象信息，可以看到它被 LWP 为 87747（线程 A） 的线程持有着；\n通过 p mutex_B，打印互斥锁 B 对象信息，可以看到他被 LWP 为 87748 （线程 B） 的线程持有着；\n\n因为线程 B 在等待线程 A 所持有的 mutex_A, 而同时线程 A 又在等待线程 B 所拥有的mutex_B, 所以可以断定该程序发生了死锁。\n避免死锁问题的发生前面我们提到，产生死锁的四个必要条件是：互斥条件、持有并等待条件、不可剥夺条件、环路等待条件。\n那么避免死锁问题就只需要破环其中一个条件就可以，最常见的并且可行的就是使用资源有序分配法，来破环环路等待条件。\n那什么是资源有序分配法呢？\n线程 A 和 线程 B 获取资源的顺序要一样，当线程 A 是先尝试获取资源 A，然后尝试获取资源 B 的时候，线程 B 同样也是先尝试获取资源 A，然后尝试获取资源 B。也就是说，线程 A 和 线程 B 总是以相同的顺序申请自己想要的资源。\n我们使用资源有序分配法的方式来修改前面发生死锁的代码，我们可以不改动线程 A 的代码。\n我们先要清楚线程 A 获取资源的顺序，它是先获取互斥锁 A，然后获取互斥锁 B。\n所以我们只需将线程 B 改成以相同顺序的获取资源，就可以打破死锁了。\n互斥锁与自旋锁最底层的两种就是会「互斥锁和自旋锁」，有很多高级的锁都是基于它们实现的，你可以认为它们是各种锁的地基，所以我们必须清楚它俩之间的区别和应用。\n加锁的目的就是保证共享资源在任意时间里，只有一个线程访问，这样就可以避免多线程导致共享数据错乱的问题。\n当已经有一个线程加锁后，其他线程加锁则就会失败，互斥锁和自旋锁对于加锁失败后的处理方式是不一样的：\n\n互斥锁加锁失败后，线程会释放 CPU ，给其他线程；\n自旋锁加锁失败后，线程会忙等待，直到它拿到锁；\n\n互斥锁是一种「独占锁」，比如当线程 A 加锁成功后，此时互斥锁已经被线程 A 独占了，只要线程 A 没有释放手中的锁，线程 B 加锁就会失败，于是就会释放 CPU 让给其他线程，既然线程 B 释放掉了 CPU，自然线程 B 加锁的代码就会被阻塞。\n对于互斥锁加锁失败而阻塞的现象，是由操作系统内核实现的。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。\n\n\n\n\n所以，互斥锁加锁失败时，会从用户态陷入到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在一定的性能开销成本。\n那这个开销成本是什么呢？会有两次线程上下文切换的成本：\n\n当线程加锁失败时，内核会把线程的状态从「运行」状态设置为「睡眠」状态，然后把 CPU 切换给其他线程运行；\n接着，当锁被释放时，之前「睡眠」状态的线程会变为「就绪」状态，然后内核会在合适的时间，把 CPU 切换给该线程运行。\n\n线程的上下文切换的是什么？当两个线程是属于同一个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的私有数据、寄存器等不共享的数据。\n上下切换的耗时有大佬统计过，大概在几十纳秒到几微秒之间，如果你锁住的代码执行时间比较短，那可能上下文切换的时间都比你锁住的代码执行时间还要长。\n所以，如果你能确定被锁住的代码执行时间很短，就不应该用互斥锁，而应该选用自旋锁，否则使用互斥锁。\n自旋锁是通过 CPU 提供的 CAS 函数（Compare And Swap），在「用户态」完成加锁和解锁操作，不会主动产生线程上下文切换，所以相比互斥锁来说，会快一些，开销也小一些。\n一般加锁的过程，包含两个步骤：\n\n第一步，查看锁的状态，如果锁是空闲的，则执行第二步；\n第二步，将锁设置为当前线程持有；\n\nCAS 函数就把这两个步骤合并成一条硬件级指令，形成原子指令，这样就保证了这两个步骤是不可分割的，要么一次性执行完两个步骤，要么两个步骤都不执行。\n比如，设锁为变量 lock，整数 0 表示锁是空闲状态，整数 pid 表示线程 ID，那么 CAS(lock, 0, pid) 就表示自旋锁的加锁操作，CAS(lock, pid, 0) 则表示解锁操作。\n使用自旋锁的时候，当发生多线程竞争锁的情况，加锁失败的线程会「忙等待」，直到它拿到锁。这里的「忙等待」可以用 while 循环等待实现，不过最好是使用 CPU 提供的 PAUSE 指令来实现「忙等待」，因为可以减少循环等待时的耗电量。\n自旋锁是最比较简单的一种锁，一直自旋，利用 CPU 周期，直到锁可用。需要注意，在单核 CPU 上，需要抢占式的调度器（即不断通过时钟中断一个线程，运行其他线程）。否则，自旋锁在单 CPU 上无法使用，因为一个自旋的线程永远不会放弃 CPU。\n自旋锁开销少，在多核系统下一般不会主动产生线程切换，适合异步、协程等在用户态切换请求的编程方式，但如果被锁住的代码执行时间过长，自旋的线程会长时间占用 CPU 资源，所以自旋的时间和被锁住的代码执行的时间是成「正比」的关系，我们需要清楚的知道这一点。\n自旋锁与互斥锁使用层面比较相似，但实现层面上完全不同：当加锁失败时，互斥锁用「线程切换」来应对，自旋锁则用「忙等待」来应对。\n它俩是锁的最基本处理方式，更高级的锁都会选择其中一个来实现，比如读写锁既可以选择互斥锁实现，也可以基于自旋锁实现。\n读写锁读写锁从字面意思我们也可以知道，它由「读锁」和「写锁」两部分构成，如果只读取共享资源用「读锁」加锁，如果要修改共享资源则用「写锁」加锁。\n所以，读写锁适用于能明确区分读操作和写操作的场景。\n读写锁的工作原理是：\n\n当「写锁」没有被线程持有时，多个线程能够并发地持有读锁，这大大提高了共享资源的访问效率，因为「读锁」是用于读取共享资源的场景，所以多个线程同时持有读锁也不会破坏共享资源的数据。\n但是，一旦「写锁」被线程持有后，读线程的获取读锁的操作会被阻塞，而且其他写线程的获取写锁的操作也会被阻塞。\n\n所以说，写锁是独占锁，因为任何时刻只能有一个线程持有写锁，类似互斥锁和自旋锁，而读锁是共享锁，因为读锁可以被多个线程同时持有。\n知道了读写锁的工作原理后，我们可以发现，读写锁在读多写少的场景，能发挥出优势。\n另外，根据实现的不同，读写锁可以分为「读优先锁」和「写优先锁」。\n读优先锁期望的是，读锁能被更多的线程持有，以便提高读线程的并发性，它的工作方式是：当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取写锁。\n读优先锁对于读线程并发性更好，但也不是没有问题。我们试想一下，如果一直有读线程获取读锁，那么写线程将永远获取不到写锁，这就造成了写线程「饥饿」的现象。\n写优先锁可以保证写线程不会饿死，但是如果一直有写线程获取写锁，读线程也会被「饿死」。\n既然不管优先读锁还是写锁，对方可能会出现饿死问题，那么我们就不偏袒任何一方，搞个「公平读写锁」。\n公平读写锁比较简单的一种方式是：用队列把获取锁的线程排队，不管是写线程还是读线程都按照先进先出的原则加锁即可，这样读线程仍然可以并发，也不会出现「饥饿」的现象。\n互斥锁和自旋锁都是最基本的锁，读写锁可以根据场景来选择这两种锁其中的一个进行实现。\n乐观锁与悲观锁悲观锁做事比较悲观，它认为多线程同时修改共享资源的概率比较高，于是很容易出现冲突，所以访问共享资源前，先要上锁。\n那相反的，如果多线程同时修改共享资源的概率比较低，就可以采用乐观锁。\n乐观锁做事比较乐观，它假定冲突的概率很低，它的工作方式是：先修改完共享资源，再验证这段时间内有没有发生冲突，如果没有其他线程在修改资源，那么操作完成，如果发现有其他线程已经修改过这个资源，就放弃本次操作。\n放弃后如何重试，这跟业务场景息息相关，虽然重试的成本很高，但是冲突的概率足够低的话，还是可以接受的。\n可见，乐观锁的心态是，不管三七二十一，先改了资源再说。另外，你会发现乐观锁全程并没有加锁，所以它也叫无锁编程。\n服务端要怎么验证是否冲突了呢？通常方案如下：\n\n由于发生冲突的概率比较低，所以先让用户编辑文档，但是浏览器在下载文档时会记录下服务端返回的文档版本号；\n当用户提交修改时，发给服务端的请求会带上原始文档版本号，服务器收到后将它与当前版本号进行比较，如果版本号不一致则提交失败，如果版本号一致则修改成功，然后服务端版本号更新到最新的版本号。\n\n实际上，我们常见的 SVN 和 Git 也是用了乐观锁的思想，先让用户编辑代码，然后提交的时候，通过版本号来判断是否产生了冲突，发生了冲突的地方，需要我们自己修改后，再重新提交。\n乐观锁虽然去除了加锁解锁的操作，但是一旦发生冲突，重试的成本非常高，所以只有在冲突概率非常低，且加锁成本非常高的场景时，才考虑使用乐观锁。\n网络系统零拷贝DMA技术在没有 DMA 技术前，I&#x2F;O 的过程是这样的：\n\nCPU 发出对应的指令给磁盘控制器，然后返回；\n磁盘控制器收到指令后，于是就开始准备数据，会把数据放入到磁盘控制器的内部缓冲区中，然后产生一个中断；\nCPU 收到中断信号后，停下手头的工作，接着把磁盘控制器的缓冲区的数据一次一个字节地读进自己的寄存器，然后再把寄存器里的数据写入到内存，而在数据传输的期间 CPU 是无法执行其他任务的。\n\n\n\n\n\n可以看到，整个数据的传输过程，都要需要 CPU 亲自参与搬运数据的过程，而且这个过程，CPU 是不能做其他事情的。\n简单的搬运几个字符数据那没问题，但是如果我们用千兆网卡或者硬盘传输大量数据的时候，都用 CPU 来搬运的话，肯定忙不过来。\n计算机科学家们发现了事情的严重性后，于是就发明了 DMA 技术，也就是直接内存访问（*Direct Memory Access*） 技术。\n什么是 DMA 技术？简单理解就是，在进行 I&#x2F;O 设备和内存的数据传输的时候，数据搬运的工作全部交给 DMA 控制器，而 CPU 不再参与任何与数据搬运相关的事情，这样 CPU 就可以去处理别的事务。\n\n\n\n\n具体过程：\n\n用户进程调用 read 方法，向操作系统发出 I&#x2F;O 请求，请求读取数据到自己的内存缓冲区中，进程进入阻塞状态；\n操作系统收到请求后，进一步将 I&#x2F;O 请求发送 DMA，然后让 CPU 执行其他任务；\nDMA 进一步将 I&#x2F;O 请求发送给磁盘；\n磁盘收到 DMA 的 I&#x2F;O 请求，把数据从磁盘读取到磁盘控制器的缓冲区中，当磁盘控制器的缓冲区被读满后，向 DMA 发起中断信号，告知自己缓冲区已满；\nDMA 收到磁盘的信号，将磁盘控制器缓冲区中的数据拷贝到内核缓冲区中，此时不占用 CPU，CPU 可以执行其他任务；\n当 DMA 读取了足够多的数据，就会发送中断信号给 CPU；\nCPU 收到 DMA 的信号，知道数据已经准备好，于是将数据从内核拷贝到用户空间，系统调用返回；\n\n可以看到， 整个数据传输的过程，CPU 不再参与数据搬运的工作，而是全程由 DMA 完成，但是 CPU 在这个过程中也是必不可少的，因为传输什么数据，从哪里传输到哪里，都需要 CPU 来告诉 DMA 控制器。\n早期 DMA 只存在在主板上，如今由于 I&#x2F;O 设备越来越多，数据传输的需求也不尽相同，所以每个 I&#x2F;O 设备里面都有自己的 DMA 控制器。\n传统文件传输如果服务端要提供文件传输的功能，我们能想到的最简单的方式是：将磁盘上的文件读取出来，然后通过网络协议发送给客户端。\n传统 I&#x2F;O 的工作方式是，数据读取和写入是从用户空间到内核空间来回复制，而内核空间的数据是通过操作系统层面的 I&#x2F;O 接口从磁盘读取或写入。\n代码通常如下，一般会需要两个系统调用：\nread(file, tmp_buf, len);\nwrite(socket, tmp_buf, len);\n\n\n\n\n\n首先，期间共发生了 4 次用户态与内核态的上下文切换，因为发生了两次系统调用，一次是 read() ，一次是 write()，每次系统调用都得先从用户态切换到内核态，等内核完成任务后，再从内核态切换回用户态。\n上下文切换到成本并不小，一次切换需要耗时几十纳秒到几微秒，虽然时间看上去很短，但是在高并发的场景下，这类时间容易被累积和放大，从而影响系统的性能。\n其次，还发生了 4 次数据拷贝，其中两次是 DMA 的拷贝，另外两次则是通过 CPU 拷贝的，下面说一下这个过程：\n\n第一次拷贝，把磁盘上的数据拷贝到操作系统内核的缓冲区里，这个拷贝的过程是通过 DMA 搬运的。\n第二次拷贝，把内核缓冲区的数据拷贝到用户的缓冲区里，于是我们应用程序就可以使用这部分数据了，这个拷贝到过程是由 CPU 完成的。\n第三次拷贝，把刚才拷贝到用户的缓冲区里的数据，再拷贝到内核的 socket 的缓冲区里，这个过程依然还是由 CPU 搬运的。\n第四次拷贝，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程又是由 DMA 搬运的。\n\n我们回过头看这个文件传输的过程，我们只是搬运一份数据，结果却搬运了 4 次，过多的数据拷贝无疑会消耗 CPU 资源，大大降低了系统性能。\n这种简单又传统的文件传输方式，存在冗余的上文切换和数据拷贝，在高并发系统里是非常糟糕的，多了很多不必要的开销，会严重影响系统性能。\n所以，要想提高文件传输的性能，就需要减少「用户态与内核态的上下文切换」和「内存拷贝」的次数。\n传输性能优化\n\n\n\n\n\n\n\n\n先来看看，如何减少「用户态与内核态的上下文切换」的次数呢？\n读取磁盘数据的时候，之所以要发生上下文切换，这是因为用户空间没有权限操作磁盘或网卡，内核的权限最高，这些操作设备的过程都需要交由操作系统内核来完成，所以一般要通过内核去完成某些任务的时候，就需要使用操作系统提供的系统调用函数。\n而一次系统调用必然会发生 2 次上下文切换：首先从用户态切换到内核态，当内核执行完任务后，再切换回用户态交由进程代码执行。\n所以，要想减少上下文切换到次数，就要减少系统调用的次数。\n\n\n\n\n\n\n\n\n\n再来看看，如何减少「数据拷贝」的次数？\n在前面我们知道了，传统的文件传输方式会历经 4 次数据拷贝，而且这里面，「从内核的读缓冲区拷贝到用户的缓冲区里，再从用户的缓冲区里拷贝到 socket 的缓冲区里」，这个过程是没有必要的。\n因为文件传输的应用场景中，在用户空间我们并不会对数据「再加工」，所以数据实际上可以不用搬运到用户空间，因此用户的缓冲区是没有必要存在的。\n零拷贝实现零拷贝技术实现的方式通常有 2 种：\n\nmmap + write\nsendfile\n\n下面就谈一谈，它们是如何减少「上下文切换」和「数据拷贝」的次数。\nmmap + write在前面我们知道，read() 系统调用的过程中会把内核缓冲区的数据拷贝到用户的缓冲区里，于是为了减少这一步开销，我们可以用 mmap() 替换 read() 系统调用函数。\nbuf = mmap(file, len);\nwrite(sockfd, buf, len);\n\nmmap() 系统调用函数会直接把内核缓冲区里的数据「映射」到用户空间，这样，操作系统内核与用户空间就不需要再进行任何的数据拷贝操作。\n\n\n\n\n具体过程如下：\n\n应用进程调用了 mmap() 后，DMA 会把磁盘的数据拷贝到内核的缓冲区里。接着，应用进程跟操作系统内核「共享」这个缓冲区；\n应用进程再调用 write()，操作系统直接将内核缓冲区的数据拷贝到 socket 缓冲区中，这一切都发生在内核态，由 CPU 来搬运数据；\n最后，把内核的 socket 缓冲区里的数据，拷贝到网卡的缓冲区里，这个过程是由 DMA 搬运的。\n\n我们可以得知，通过使用 mmap() 来代替 read()， 可以减少一次数据拷贝的过程。\n但这还不是最理想的零拷贝，因为仍然需要通过 CPU 把内核缓冲区的数据拷贝到 socket 缓冲区里，而且仍然需要 4 次上下文切换，因为系统调用还是 2 次。\nsendfile在 Linux 内核版本 2.1 中，提供了一个专门发送文件的系统调用函数 sendfile()，函数形式如下：\n#include &lt;sys/socket.h>\nssize_t sendfile(int out_fd, int in_fd, off_t *offset, size_t count);\n\n它的前两个参数分别是目的端和源端的文件描述符，后面两个参数是源端的偏移量和复制数据的长度，返回值是实际复制数据的长度。\n首先，它可以替代前面的 read() 和 write() 这两个系统调用，这样就可以减少一次系统调用，也就减少了 2 次上下文切换的开销。\n其次，该系统调用，可以直接把内核缓冲区里的数据拷贝到 socket 缓冲区里，不再拷贝到用户态，这样就只有 2 次上下文切换，和 3 次数据拷贝。如下图：\n\n\n\n\n但是这还不是真正的零拷贝技术，如果网卡支持 SG-DMA（The Scatter-Gather Direct Memory Access）技术（和普通的 DMA 有所不同），我们可以进一步减少通过 CPU 把内核缓冲区里的数据拷贝到 socket 缓冲区的过程。\n于是，从 Linux 内核 2.4 版本开始起，对于支持网卡支持 SG-DMA 技术的情况下， sendfile() 系统调用的过程发生了点变化，具体过程如下：\n\n第一步，通过 DMA 将磁盘上的数据拷贝到内核缓冲区里；\n第二步，缓冲区描述符和数据长度传到 socket 缓冲区，这样网卡的 SG-DMA 控制器就可以直接将内核缓存中的数据拷贝到网卡的缓冲区里，此过程不需要将数据从操作系统内核缓冲区拷贝到 socket 缓冲区中，这样就减少了一次数据拷贝；\n\n这就是所谓的零拷贝（*Zero-copy*）技术，因为我们没有在内存层面去拷贝数据，也就是说全程没有通过 CPU 来搬运数据，所有的数据都是通过 DMA 来进行传输的。。\n零拷贝技术的文件传输方式相比传统文件传输的方式，减少了 2 次上下文切换和数据拷贝次数，只需要 2 次上下文切换和数据拷贝次数，就可以完成文件的传输，而且 2 次的数据拷贝过程，都不需要通过 CPU，2 次都是由 DMA 来搬运。\n所以，总体来看，零拷贝技术可以把文件传输的性能提高至少一倍以上。\nPageCache回顾前面说道文件传输过程，其中第一步都是先需要先把磁盘文件数据拷贝「内核缓冲区」里，这个「内核缓冲区」实际上是磁盘高速缓存（*PageCache*）。\n由于零拷贝使用了 PageCache 技术，可以使得零拷贝进一步提升了性能，我们接下来看看 PageCache 是如何做到这一点的。\n读写磁盘相比读写内存的速度慢太多了，所以我们应该想办法把「读写磁盘」替换成「读写内存」。于是，我们会通过 DMA 把磁盘里的数据搬运到内存里，这样就可以用读内存替换读磁盘。\n我们都知道程序运行的时候，具有「局部性」，所以通常，刚被访问的数据在短时间内再次被访问的概率很高，于是我们可以用 PageCache 来缓存最近被访问的数据，当空间不足时淘汰最久未被访问的缓存。\n所以，读磁盘数据的时候，优先在 PageCache 找，如果数据存在则可以直接返回；如果没有，则从磁盘中读取，然后缓存 PageCache 中。\n还有一点，读取磁盘数据的时候，需要找到数据所在的位置，但是对于机械磁盘来说，就是通过磁头旋转到数据所在的扇区，再开始「顺序」读取数据，但是旋转磁头这个物理动作是非常耗时的，为了降低它的影响，PageCache 使用了「预读功能」。\n比如，假设 read 方法每次只会读 32 KB 的字节，虽然 read 刚开始只会读 0 ～ 32 KB 的字节，但内核会把其后面的 32～64 KB 也读取到 PageCache，这样后面读取 32～64 KB 的成本就很低，如果在 32～64 KB 淘汰出 PageCache 前，进程读取到它了，收益就非常大。\n所以，PageCache 的优点主要是两个：\n\n缓存最近被访问的数据；\n预读功能；\n\n但是，在传输大文件（GB 级别的文件）的时候，PageCache 会不起作用，那就白白浪费 DMA 多做的一次数据拷贝，造成性能的降低，即使使用了 PageCache 的零拷贝也会损失性能\n这是因为如果你有很多 GB 级别文件需要传输，每当用户访问这些大文件的时候，内核就会把它们载入 PageCache 中，于是 PageCache 空间很快被这些大文件占满。\n另外，由于文件太大，可能某些部分的文件数据被再次访问的概率比较低，这样就会带来 2 个问题：\n\nPageCache 由于长时间被大文件占据，其他「热点」的小文件可能就无法充分使用到 PageCache，于是这样磁盘读写的性能就会下降了；\nPageCache 中的大文件数据，由于没有享受到缓存带来的好处，但却耗费 DMA 多拷贝到 PageCache 一次；\n\n所以，针对大文件的传输，不应该使用 PageCache，也就是说不应该使用零拷贝技术，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache，这样在高并发的环境下，会带来严重的性能问题。\n大文件传输方式绕开 PageCache 的 I&#x2F;O 叫直接 I&#x2F;O，使用 PageCache 的 I&#x2F;O 则叫缓存 I&#x2F;O。通常，对于磁盘，异步 I&#x2F;O 只支持直接 I&#x2F;O。\n前面也提到，大文件的传输不应该使用 PageCache，因为可能由于 PageCache 被大文件占据，而导致「热点」小文件无法利用到 PageCache。\n于是，在高并发的场景下，针对大文件的传输的方式，应该使用「异步 I&#x2F;O + 直接 I&#x2F;O」来替代零拷贝技术。\n直接 I&#x2F;O 应用场景常见的两种：\n\n应用程序已经实现了磁盘数据的缓存，那么可以不需要 PageCache 再次缓存，减少额外的性能损耗。在 MySQL 数据库中，可以通过参数设置开启直接 I&#x2F;O，默认是不开启；\n传输大文件的时候，由于大文件难以命中 PageCache 缓存，而且会占满 PageCache 导致「热点」文件无法充分利用缓存，从而增大了性能开销，因此，这时应该使用直接 I&#x2F;O。\n\n另外，由于直接 I&#x2F;O 绕过了 PageCache，就无法享受内核的这两点的优化：\n\n内核的 I&#x2F;O 调度算法会缓存尽可能多的 I&#x2F;O 请求在 PageCache 中，最后「合并」成一个更大的 I&#x2F;O 请求再发给磁盘，这样做是为了减少磁盘的寻址操作；\n内核也会「预读」后续的 I&#x2F;O 请求放在 PageCache 中，一样是为了减少对磁盘的操作；\n\n于是，传输大文件的时候，使用「异步 I&#x2F;O + 直接 I&#x2F;O」了，就可以无阻塞地读取文件了。\n所以，传输文件的时候，我们要根据文件的大小来使用不同的方式：\n\n传输大文件的时候，使用「异步 I&#x2F;O + 直接 I&#x2F;O」；\n传输小文件的时候，则使用「零拷贝技术」；\n\n在 nginx 中，我们可以用如下配置，来根据文件的大小来使用不同的方式：\nlocation /video/ &#123; \n    sendfile on; \n    aio on; \n    directio 1024m; \n&#125;\n\n当文件大小大于 directio 值后，使用「异步 I&#x2F;O + 直接 I&#x2F;O」，否则使用「零拷贝技术」。\n\n\n\n\nI&#x2F;O 多路复用Socket 模型要想客户端和服务器能在网络中通信，那必须得使用 Socket 编程，它是进程间通信里比较特别的方式，特别之处在于它是可以跨主机间通信。\nSocket 的中文名叫作插口，咋一看还挺迷惑的。事实上，双方要进行网络通信前，各自得创建一个 Socket，这相当于客户端和服务器都开了一个“口子”，双方读取和发送数据的时候，都通过这个“口子”。这样一看，是不是觉得很像弄了一根网线，一头插在客户端，一头插在服务端，然后进行通信。\n创建 Socket 的时候，可以指定网络层使用的是 IPv4 还是 IPv6，传输层使用的是 TCP 还是 UDP。\n\n服务端\n\n服务端首先调用 socket() 函数，创建网络协议为 IPv4，以及传输协议为 TCP 的 Socket ，接着调用 bind() 函数，给这个 Socket 绑定一个 IP 地址和端口，绑定这两个的目的是什么？\n\n绑定端口的目的：当内核收到 TCP 报文，通过 TCP 头里面的端口号，来找到我们的应用程序，然后把数据传递给我们。\n绑定 IP 地址的目的：一台机器是可以有多个网卡的，每个网卡都有对应的 IP 地址，当绑定一个网卡时，内核在收到该网卡上的包，才会发给我们；\n\n绑定完 IP 地址和端口后，就可以调用 listen() 函数进行监听，此时对应 TCP 状态图中的 listen，如果我们要判定服务器中一个网络程序有没有启动，可以通过 netstat 命令查看对应的端口号是否有被监听。\n服务端进入了监听状态后，通过调用 accept() 函数，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来。\n\n客户端\n\n客户端在创建好 Socket 后，调用 connect() 函数发起连接，该函数的参数要指明服务端的 IP 地址和端口号，然后万众期待的 TCP 三次握手就开始了。\n在 TCP 连接的过程中，服务器的内核实际上为每个 Socket 维护了两个队列：\n\n一个是「还没完全建立」连接的队列，称为 TCP 半连接队列，这个队列都是没有完成三次握手的连接，此时服务端处于 syn_rcvd 的状态；\n一个是「已经建立」连接的队列，称为 TCP 全连接队列，这个队列都是完成了三次握手的连接，此时服务端处于 established 状态；\n\n当 TCP 全连接队列不为空后，服务端的 accept() 函数，就会从内核中的 TCP 全连接队列里拿出一个已经完成连接的 Socket 返回应用程序，后续数据传输都用这个 Socket。\n注意，监听的 Socket 和真正用来传数据的 Socket 是两个：\n\n一个叫作监听 Socket；\n一个叫作已连接 Socket；\n\n连接建立后，客户端和服务端就开始相互传输数据了，双方都可以通过 read() 和 write() 函数来读写数据。\n*文件描述符文件描述符的作用是什么？每一个进程都有一个数据结构 task_struct，该结构体里有一个指向「文件描述符数组」的成员指针。该数组里列出这个进程打开的所有文件的文件描述符。数组的下标是文件描述符，是一个整数，而数组的内容是一个指针，指向内核中所有打开的文件的列表，也就是说内核可以通过文件描述符找到对应打开的文件。\n然后每个文件都有一个 inode，Socket 文件的 inode 指向了内核中的 Socket 结构，在这个结构体里有两个队列，分别是发送队列和接收队列，这个两个队列里面保存的是一个个 struct sk_buff，用链表的组织形式串起来。\nsk_buff 可以表示各个层的数据包，在应用层数据包叫 data，在 TCP 层我们称为 segment，在 IP 层我们叫 packet，在数据链路层称为 frame。\n你可能会好奇，为什么全部数据包只用一个结构体来描述呢？协议栈采用的是分层结构，上层向下层传递数据时需要增加包头，下层向上层数据时又需要去掉包头，如果每一层都用一个结构体，那在层之间传递数据的时候，就要发生多次拷贝，这将大大降低 CPU 效率。\n于是，为了在层级之间传递数据时，不发生拷贝，只用 sk_buff 一个结构体来描述所有的网络包，那它是如何做到的呢？是通过调整 sk_buff 中 data 的指针，比如：\n\n当接收报文时，从网卡驱动开始，通过协议栈层层往上传送数据报，通过增加 skb-&gt;data 的值，来逐步剥离协议首部。\n当要发送报文时，创建 sk_buff 结构体，数据缓存区的头部预留足够的空间，用来填充各层首部，在经过各下层协议时，通过减少 skb-&gt;data 的值来增加协议首部。\n\n你可以从下面这张图看到，当发送报文时，data 指针的移动过程。\n\n\n\n\n前面提到的 TCP Socket 调用流程是最简单、最基本的，它基本只能一对一通信，因为使用的是同步阻塞的方式，当服务端在还没处理完一个客户端的网络 I&#x2F;O 时，或者 读写操作发生阻塞时，其他客户端是无法与服务端连接的。\n可如果我们服务器只能服务一个客户，那这样就太浪费资源了，于是我们要改进这个网络 I&#x2F;O 模型，以支持更多的客户端。\n在改进网络 I&#x2F;O 模型前，我先来提一个问题，你知道服务器单机理论最大能连接多少个客户端？\n相信你知道 TCP 连接是由四元组唯一确认的，这个四元组就是：本机IP, 本机端口, 对端IP, 对端端口。\n服务器作为服务方，通常会在本地固定监听一个端口，等待客户端的连接。因此服务器的本地 IP 和端口是固定的，于是对于服务端 TCP 连接的四元组只有对端 IP 和端口是会变化的，所以最大 TCP 连接数 &#x3D; 客户端 IP 数×客户端端口数。\n对于 IPv4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数约为 2 的 48 次方。\n这个理论值相当“丰满”，但是服务器肯定承载不了那么大的连接数，主要会受两个方面的限制：\n\n文件描述符，Socket 实际上是一个文件，也就会对应一个文件描述符。在 Linux 下，单个进程打开的文件描述符数是有限制的，没有经过修改的值一般都是 1024，不过我们可以通过 ulimit 增大文件描述符的数目；\n系统内存，每个 TCP 连接在内核中都有对应的数据结构，意味着每个连接都是会占用一定内存的；\n\n那如果服务器的内存只有 2 GB，网卡是千兆的，能支持并发 1 万请求吗？\n并发 1 万请求，也就是经典的 C10K 问题 ，C 是 Client 单词首字母缩写，C10K 就是单机同时处理 1 万个请求的问题。\n从硬件资源角度看，对于 2GB 内存千兆网卡的服务器，如果每个请求处理占用不到 200KB 的内存和 100Kbit 的网络带宽就可以满足并发 1 万个请求。\n不过，要想真正实现 C10K 的服务器，要考虑的地方在于服务器的网络 I&#x2F;O 模型，效率低的模型，会加重系统开销，从而会离 C10K 的目标越来越远。\n多进程模型基于最原始的阻塞网络 I&#x2F;O， 如果服务器要支持多个客户端，其中比较传统的方式，就是使用多进程模型，也就是为每个客户端分配一个进程来处理请求。\n服务器的主进程负责监听客户的连接，一旦与客户端连接完成，accept() 函数就会返回一个「已连接 Socket」，这时就通过 fork() 函数创建一个子进程，实际上就把父进程所有相关的东西都复制一份，包括文件描述符、内存地址空间、程序计数器、执行的代码等。\n这两个进程刚复制完的时候，几乎一模一样。不过，会根据返回值来区分是父进程还是子进程，如果返回值是 0，则是子进程；如果返回值是其他的整数，就是父进程。\n正因为子进程会复制父进程的文件描述符，于是就可以直接使用「已连接 Socket 」和客户端通信了，\n可以发现，子进程不需要关心「监听 Socket」，只需要关心「已连接 Socket」；父进程则相反，将客户服务交给子进程来处理，因此父进程不需要关心「已连接 Socket」，只需要关心「监听 Socket」。\n\n\n\n\n另外，当「子进程」退出时，实际上内核里还会保留该进程的一些信息，也是会占用内存的，如果不做好“回收”工作，就会变成僵尸进程，随着僵尸进程越多，会慢慢耗尽我们的系统资源。\n因此，父进程要“善后”好自己的孩子，怎么善后呢？那么有两种方式可以在子进程退出后回收资源，分别是调用 wait() 和 waitpid() 函数。\n这种用多个进程来应付多个客户端的方式，在应对 100 个客户端还是可行的，但是当客户端数量高达一万时，肯定扛不住的，因为每产生一个进程，必会占据一定的系统资源，而且进程间上下文切换的“包袱”是很重的，性能会大打折扣。\n进程的上下文切换不仅包含了虚拟内存、栈、全局变量等用户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。\n僵尸进程如果子进程先退出，父进程还没退出，那么子进程必须等到父进程捕获到了子进 程的退出状态才真正结束，否则这个时候子进程就成为僵尸进程。 \n设置僵尸进程的目的是维护子进程的信息，以便父进程在以后某个时候获取。这些信息 至少包括进程 ID，进程的终止状态，以及该进程使用的 CPU 时间，所以当终止子进程的父 进程调用 wait 或 waitpid 时就可以得到这些信息。如果一个进程终止时该进程有子进程处于 僵尸状态，那么它的所有僵尸子进程的父进程将被重置为 init 进程并且清理它们。\n\n如何避免僵尸进程\n\n\n父进程可将 SIGCHLD 的处理函数设为 SIG_IGN（亦为默认设定）通知内核对子进程的结束 不关心，由内核回收。这种忽略 SIGCHLD 信号的方法，常用于并发服务器的性能的一个技巧 因为并发服务器常常 fork 很多子进程，子进程终结之后需要服务器进程去 wait 清理资源。 如果将此信号的处理方式设为忽略，可让内核把僵尸子进程转交给 init 进程去处理，省去了 大量僵尸进程占用系统资源。 \n如果父进程很忙可以用 signal 注册信号处理函数，在信号处理函数调用 wait&#x2F;waitpid 等待 子进程退出。 \n通过两次调用 fork。父进程首先调用 fork 创建一个子进程然后 waitpid 等待子进程退出， 子进程再 fork 一个子孙进程后退出。这样子进程退出后会被父进程等待回收，而对于子孙 进程其父进程已经退出所以子孙进程成为一个孤儿进程，孤儿进程由 init 进程接管，子孙进 程结束后，init 会回收。\n\n多线程模型既然进程间上下文切换的“包袱”很重，那我们就搞个比较轻量级的模型来应对多用户的请求 —— 多线程模型。\n线程是运行在进程中的一个“逻辑流”，单进程中可以运行多个线程，同进程里的线程可以共享进程的部分资源，比如文件描述符列表、进程空间、代码、全局数据、堆、共享库等，这些共享些资源在上下文切换时不需要切换，而只需要切换线程的私有数据、寄存器等不共享的数据，因此同一个进程下的线程上下文切换的开销要比进程小得多。\n当服务器与客户端 TCP 完成连接后，通过 pthread_create() 函数创建线程，然后将「已连接 Socket」的文件描述符传递给线程函数，接着在线程里和客户端进行通信，从而达到并发处理的目的。\n如果每来一个连接就创建一个线程，线程运行完后，还得操作系统还得销毁线程，虽说线程切换的上写文开销不大，但是如果频繁创建和销毁线程，系统开销也是不小的。\n那么，我们可以使用线程池的方式来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建若干个线程，这样当由新连接建立时，将这个已连接的 Socket 放入到一个队列里，然后线程池里的线程负责从队列中取出「已连接 Socket 」进行处理。\n\n\n\n\n需要注意的是，这个队列是全局的，每个线程都会操作，为了避免多线程竞争，线程在操作这个队列前要加锁。\n上面基于进程或者线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程，那么如果要达到 C10K，意味着要一台机器维护 1 万个连接，相当于要维护 1 万个进程&#x2F;线程，操作系统就算死扛也是扛不住的。\nI&#x2F;O 多路复用既然为每个请求分配一个进程&#x2F;线程的方式不合适，那有没有可能只使用一个进程来维护多个 Socket 呢？答案是有的，那就是 I&#x2F;O 多路复用技术。\n一个进程虽然任一时刻只能处理一个请求，但是处理每个请求的事件时，耗时控制在 1 毫秒以内，这样 1 秒内就可以处理上千个请求，把时间拉长来看，多个请求复用了一个进程，这就是多路复用，这种思想很类似一个 CPU 并发多个进程，所以也叫做时分多路复用。\n我们熟悉的 select&#x2F;poll&#x2F;epoll 内核提供给用户态的多路复用系统调用，进程可以通过一个系统调用函数从内核中获取多个事件。\nselect&#x2F;poll&#x2F;epoll 是如何获取网络事件的呢？在获取事件时，先把所有连接（文件描述符）传给内核，再由内核返回产生了事件的连接，然后在用户态中再处理这些连接对应的请求即可。\nselect&#x2F;poll&#x2F;epoll 这是三个多路复用接口，都能实现 C10K 吗？接下来，我们分别说说它们。\nselect&#x2F;pollselect 实现多路复用的方式是，将已连接的 Socket 都放到一个文件描述符集合，然后调用 select 函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件产生，检查的方式很粗暴，就是通过遍历文件描述符集合的方式，当检查到有事件产生后，将此 Socket 标记为可读或可写， 接着再把整个文件描述符集合拷贝回用户态里，然后用户态还需要再通过遍历的方法找到可读或可写的 Socket，然后再对其处理。\n所以，对于 select 这种方式，需要进行 2 次「遍历」文件描述符集合，一次是在内核态里，一个次是在用户态里 ，而且还会发生 2 次「拷贝」文件描述符集合，先从用户空间传入内核空间，由内核修改后，再传出到用户空间中。\nselect 使用固定长度的 BitsMap，表示文件描述符集合，而且所支持的文件描述符的个数是有限制的，在 Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最大值为 1024，只能监听 0~1023 的文件描述符。\npoll 不再用 BitsMap 来存储所关注的文件描述符，取而代之用动态数组，以链表形式来组织，突破了 select 的文件描述符个数限制，当然还会受到系统文件描述符限制。\n但是 poll 和 select 并没有太大的本质区别，都是使用「线性结构」存储进程关注的 Socket 集合，因此都需要遍历文件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，而且也需要在用户态与内核态之间拷贝文件描述符集合，这种方式随着并发数上来，性能的损耗会呈指数级增长。\nepoll先复习下 epoll 的用法。如下的代码中，先用e poll_create 创建一个 epol l对象 epfd，再通过 epoll_ctl 将需要监视的 socket 添加到epfd中，最后调用 epoll_wait 等待数据。\nint s = socket(AF_INET, SOCK_STREAM, 0);\nbind(s, ...);\nlisten(s, ...)\n\nint epfd = epoll_create(...);\nepoll_ctl(epfd, ...); //将所有需要监听的socket添加到epfd中\n\nwhile(1) &#123;\n    int n = epoll_wait(...);\n    for(接收到数据的socket)&#123;\n        //处理\n    &#125;\n&#125;\n\nepoll 通过两个方面，很好解决了 select&#x2F;poll 的问题。\n第一点，epoll 在内核里使用红黑树来跟踪进程所有待检测的文件描述字，把需要监控的 socket 通过 epoll_ctl() 函数加入内核中的红黑树里，红黑树是个高效的数据结构，增删改一般时间复杂度是 O(logn)。而 select&#x2F;poll 内核里没有类似 epoll 红黑树这种保存所有待检测的 socket 的数据结构，所以 select&#x2F;poll 每次操作时都传入整个 socket 集合给内核，而 epoll 因为在内核维护了红黑树，可以保存所有待检测的 socket ，所以只需要传入一个待检测的 socket，减少了内核和用户空间大量的数据拷贝和内存分配。\n\n\n\n\n\n\n\n\n\nEpoll 在内核里面有一个相应的数据结构去存储数据，这个数据结构就是 eventpoll，它主 要存储两方面的信息：需要监听的 fd（文件描述符）集合（红黑树实现，因为要利于添加和 删除，还要便于搜索以免重复添加）和就绪列表（双向链表）用来存放就绪的 socket 集合。 Eventpoll 主要采用了回调的方式去代替轮询检查，当在 eventpoll 中注册一个 socket 时，会 在等待队列保存 eventpoll 的引用，如果 socket 读缓存区写入数据后会采用回调的方式将其 放入 eventpoll 中的就绪队列。 所以当调用 epoll_wait 检测是否有事件发生时只需要检测 eventpoll 中的就绪队列是否为 空即可。\n第二点， epoll 使用事件驱动的机制，内核里维护了一个链表来记录就绪事件，当某个 socket 有事件发生时，通过回调函数内核会将其加入到这个就绪事件列表中，当用户调用 epoll_wait() 函数时，只会返回有事件发生的文件描述符的个数，不需要像 select&#x2F;poll 那样轮询扫描整个 socket 集合，大大提高了检测的效率。\n\n\n\n\nepoll 支持两种事件触发模式，分别是**边缘触发（*edge-triggered，ET*）**和**水平触发（*level-triggered，LT*）**。\n这两个术语还挺抽象的，其实它们的区别还是很好理解的。\n\n使用边缘触发模式时，当被监控的 Socket 描述符上有可读事件发生时，服务器端只会从 epoll_wait 中苏醒一次，即使进程没有调用 read 函数从内核读取数据，也依然只苏醒一次，因此我们程序要保证一次性将内核缓冲区的数据读取完；\n\n\n\n\n\n\n\n\n\n\nepoll 边沿触发时，假设一个客户端发送 100 字节的数据，而服务器设定 read 每次读取 20 字 节，那么一次触发只能读取 20 个字节， 然后内核调用 epoll_wait 直到下一次事件发生，才会继续从剩下的 80 字节读取 20 个字节， 由此可见，这种模式其工作效率非常低且无法保证数据的完整性，因此边沿触发不会单独使 用。边沿触发通常与非阻塞 IO 一起使用，其工作模式为：epoll_wait 触发一次，在 while（1） 循环内非阻塞 IO 读取数据，直到缓冲区数据为空（保证了数据的完整性），内核才会继续 调用 epoll_wait 等待事件发生。\n\n使用水平触发模式时，当被监控的 Socket 上有可读事件发生时，服务器端不断地从 epoll_wait 中苏醒，直到内核缓冲区数据被 read 函数读完才结束，目的是告诉我们有数据需要读取；\n\n如果使用水平触发模式，当内核通知文件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要一次执行尽可能多的读写操作。\n如果使用边缘触发模式，I&#x2F;O 事件发生时只会通知一次，而且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从文件描述符读写数据，那么如果文件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那里，程序就没办法继续往下执行。所以，边缘触发模式一般和非阻塞 I&#x2F;O 搭配使用，程序会一直执行 I&#x2F;O 操作，直到系统调用（如 read 和 write）返回错误，错误类型为 EAGAIN 或 EWOULDBLOCK。\n一般来说，边缘触发的效率比水平触发的效率要高，因为边缘触发可以减少 epoll_wait 的系统调用次数，系统调用也是有一定的开销的的，毕竟也存在上下文的切换。\nselect&#x2F;poll 只有水平触发模式，epoll 默认的触发模式是水平触发，但是可以根据应用场景设置为边缘触发模式。\n另外，使用 I&#x2F;O 多路复用时，最好搭配非阻塞 I&#x2F;O 一起使用\n多路复用 API 返回的事件并不一定可读写的，如果使用阻塞 I&#x2F;O， 那么在调用 read&#x2F;write 时则会发生程序阻塞，因此最好搭配非阻塞 I&#x2F;O，以便应对极少数的特殊情况。\n\n\n\n\n\n\n\n\n\n通常的，对一个文件描述符指定的文件或设备*,* 有两种工作方式*:* 阻塞 与非阻塞 。所谓阻塞方式的意思是指*,* 当试图对该文件描述符进行读写时*,* 如果当时没有东西可读*,或者暂时不可写,* 程序就进入等待 状态, 直到有东西可读或者可写为止。而对于非阻塞状态*,* 如果没有东西可读*,* 或者不可写*,* 读写函数马上返回, 而不会等待 。\n高性能网络模式Reactor这里的反应指的是「对事件反应」，也就是来了一个事件，Reactor 就有相对应的反应&#x2F;响应。\n事实上，Reactor 模式也叫 Dispatcher 模式，我觉得这个名字更贴合该模式的含义，即 I&#x2F;O 多路复用监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 &#x2F; 线程。\nReactor 模式主要由 Reactor 和处理资源池这两个核心部分组成，它俩负责的事情如下：\n\nReactor 负责监听和分发事件，事件类型包含连接事件、读写事件；\n处理资源池负责处理事件，如 read -&gt; 业务逻辑 -&gt; send；\n\nReactor 模式是灵活多变的，可以应对不同的业务场景，灵活在于：\n\nReactor 的数量可以只有一个，也可以有多个；\n处理资源池可以是单个进程 &#x2F; 线程，也可以是多个进程 &#x2F;线程；\n\n将上面的两个因素排列组设一下，理论上就可以有 4 种方案选择：\n\n单 Reactor 单进程 &#x2F; 线程；\n单 Reactor 多进程 &#x2F; 线程；\n多 Reactor 单进程 &#x2F; 线程；\n多 Reactor 多进程 &#x2F; 线程；\n\n其中，「多 Reactor 单进程 &#x2F; 线程」实现方案相比「单 Reactor 单进程 &#x2F; 线程」方案，不仅复杂而且也没有性能优势，因此实际中并没有应用。\n剩下的 3 个方案都是比较经典的，且都有应用在实际的项目中：\n\n单 Reactor 单进程 &#x2F; 线程；\n单 Reactor 多线程 &#x2F; 进程；\n多 Reactor 多进程 &#x2F; 线程；\n\n方案具体使用进程还是线程，要看使用的编程语言以及平台有关：\n\nJava 语言一般使用线程，比如 Netty;\nC 语言使用进程和线程都可以，例如 Nginx 使用的是进程，Memcache 使用的是线程。\n\n接下来，分别介绍这三个经典的 Reactor 方案。\n单 Reactor 单进程 &#x2F; 线程一般来说，C 语言实现的是「单 Reactor 单进程」的方案，因为 C 语编写完的程序，运行后就是一个独立的进程，不需要在进程中再创建线程。\n而 Java 语言实现的是「单 Reactor 单线程」的方案，因为 Java 程序是跑在 Java 虚拟机这个进程上面的，虚拟机中有很多线程，我们写的 Java 程序只是其中的一个线程而已。\n我们来看看「单 Reactor 单进程」的方案示意图：\n\n\n\n\n可以看到进程里有 Reactor、Acceptor、Handler 这三个对象：\n\nReactor 对象的作用是监听和分发事件；\nAcceptor 对象的作用是获取连接；\nHandler 对象的作用是处理业务；\n\n对象里的 select、accept、read、send 是系统调用函数，dispatch 和 「业务处理」是需要完成的操作，其中 dispatch 是分发事件操作。\n接下来，介绍下「单 Reactor 单进程」这个方案：\n\nReactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；\n如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；\n如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；\nHandler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。\n\n单 Reactor 单进程的方案因为全部工作都在同一个进程内完成，所以实现起来比较简单，不需要考虑进程间通信，也不用担心多进程竞争。\n但是，这种方案存在 2 个缺点：\n\n第一个缺点，因为只有一个进程，无法充分利用 多核 CPU 的性能；\n第二个缺点，Handler 对象在业务处理时，整个进程是无法处理其他连接的事件的，如果业务处理耗时比较长，那么就造成响应的延迟；\n\n所以，单 Reactor 单进程的方案不适用计算机密集型的场景，只适用于业务处理非常快速的场景。\nRedis 是由 C 语言实现的，在 Redis 6.0 版本之前采用的正是「单 Reactor 单进程」的方案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的方案。\n单 Reactor 多线程 &#x2F; 多进程如果要克服「单 Reactor 单线程 &#x2F; 进程」方案的缺点，那么就需要引入多线程 &#x2F; 多进程，这样就产生了单 Reactor 多线程 &#x2F; 多进程的方案。\n\n\n\n\n详细说一下这个方案：\n\nReactor 对象通过 select （IO 多路复用接口） 监听事件，收到事件后通过 dispatch 进行分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；\n如果是连接建立的事件，则交由 Acceptor 对象进行处理，Acceptor 对象会通过 accept 方法 获取连接，并创建一个 Handler 对象来处理后续的响应事件；\n如果不是连接建立事件， 则交由当前连接对应的 Handler 对象来进行响应；\n\n上面的三个步骤和单 Reactor 单线程方案是一样的，接下来的步骤就开始不一样了：\n\nHandler 对象不再负责业务处理，只负责数据的接收和发送，Handler 对象通过 read 读取到数据后，会将数据发给子线程里的 Processor 对象进行业务处理；\n子线程里的 Processor 对象就进行业务处理，处理完后，将结果发给主线程中的 Handler 对象，接着由 Handler 通过 send 方法将响应结果发送给 client；\n\n单 Reator 多线程的方案优势在于能够充分利用多核 CPU 的能，那既然引入多线程，那么自然就带来了多线程竞争资源的问题。\n例如，子线程完成业务处理后，要把结果传递给主线程的 Handler 进行发送，这里涉及共享数据的竞争。\n要避免多线程由于竞争共享资源而导致数据错乱的问题，就需要在操作共享资源前加上互斥锁，以保证任意时间里只有一个线程在操作共享资源，待该线程操作完释放互斥锁后，其他线程才有机会操作共享数据。\n另外，「单 Reactor」的模式还有个问题，因为一个 Reactor 对象承担所有事件的监听和响应，而且只在主线程中运行，在面对瞬间高并发的场景时，容易成为性能的瓶颈的地方。\n多 Reactor 多进程 &#x2F; 线程要解决「单 Reactor」的问题，就是将「单 Reactor」实现成「多 Reactor」，这样就产生了第 多 Reactor 多进程 &#x2F; 线程的方案。\n\n\n\n\n方案详细说明如下：\n\n主线程中的 MainReactor 对象通过 select 监控连接建立事件，收到事件后通过 Acceptor 对象中的 accept 获取连接，将新的连接分配给某个子线程；\n子线程中的 SubReactor 对象将 MainReactor 对象分配的连接加入 select 继续进行监听，并创建一个 Handler 用于处理连接的响应事件。\n如果有新的事件发生时，SubReactor 对象会调用当前连接对应的 Handler 对象来进行响应。\nHandler 对象通过 read -&gt; 业务处理 -&gt; send 的流程来完成完整的业务流程。\n\n多 Reactor 多线程的方案虽然看起来复杂的，但是实际实现时比单 Reactor 多线程的方案要简单的多，原因如下：\n\n主线程和子线程分工明确，主线程只负责接收新连接，子线程负责完成后续的业务处理。\n主线程和子线程的交互很简单，主线程只需要把新连接传给子线程，子线程无须返回数据，直接就可以在子线程将处理结果发送给客户端。\n\n大名鼎鼎的两个开源软件 Netty 和 Memcache 都采用了「多 Reactor 多线程」的方案。\n采用了「多 Reactor 多进程」方案的开源软件是 Nginx，不过方案与标准的多 Reactor 多进程有些差异。\n具体差异表现在主进程中仅仅用来初始化 socket，并没有创建 mainReactor 来 accept 连接，而是由子进程的 Reactor 来 accept 连接，通过锁来控制一次只有一个子进程进行 accept（防止出现惊群现象），子进程 accept 新连接后就放到自己的 Reactor 进行处理，不会再分配给其他子进程。\n关于惊群现象可以参考这篇文章什么是惊群，如何有效避免惊群? \nProactor前面提到的 Reactor 是非阻塞同步网络模式，而 Proactor 是异步网络模式。\n先来看看阻塞 I&#x2F;O，当用户程序执行 read ，线程会被阻塞，一直等到内核数据准备好，并把数据从内核缓冲区拷贝到应用程序的缓冲区中，当拷贝过程完成，read 才会返回。\n注意，阻塞等待的是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程。\n知道了阻塞 I&#x2F;O ，来看看非阻塞 I&#x2F;O，非阻塞的 read 请求在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区，read 调用才可以获取到结果。\n注意，这里最后一次 read 调用，获取数据的过程，是一个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷贝到用户程序的缓存区这个过程。\n举个例子，如果 socket 设置了 O_NONBLOCK 标志，那么就表示使用的是非阻塞 I&#x2F;O 的方式访问，而不做任何设置的话，默认是阻塞 I&#x2F;O。\n因此，无论 read 和 send 是阻塞 I&#x2F;O，还是非阻塞 I&#x2F;O 都是同步调用。因为在 read 调用时，内核将数据从内核空间拷贝到用户空间的过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷贝效率不高，read 调用就会在这个同步过程中等待比较长的时间。\n而真正的异步 I&#x2F;O 是「内核数据准备好」和「数据从内核态拷贝到用户态」这两个过程都不用等待。\n当我们发起 aio_read （异步 I&#x2F;O） 之后，就立即返回，内核自动将数据从内核空间拷贝到用户空间，这个拷贝过程同样是异步的，内核自动完成的，和前面的同步操作不一样，应用程序并不需要主动发起拷贝动作。过程如下图：\n\n\n\n\n很明显，异步 I&#x2F;O 比同步 I&#x2F;O 性能更好，因为异步 I&#x2F;O 在「内核数据准备好」和「数据从内核空间拷贝到用户空间」这两个过程都不用等待。\nProactor 正是采用了异步 I&#x2F;O 技术，所以被称为异步网络模型。\n现在我们再来理解 Reactor 和 Proactor 的区别，就比较清晰了。\n\nReactor 是非阻塞同步网络模式，感知的是就绪可读写事件。在每次感知到有事件发生（比如可读就绪事件）后，就需要应用进程主动调用 read 方法来完成数据的读取，也就是要应用进程主动将 socket 接收缓存中的数据读到应用进程内存中，这个过程是同步的，读取完数据后应用进程才能处理数据。\nProactor 是异步网络模式， 感知的是已完成的读写事件。在发起异步读写请求时，需要传入数据缓冲区的地址（用来存放结果数据）等信息，这样系统内核才可以自动帮我们把数据的读写工作完成，这里的读写工作全程由操作系统来做，并不需要像 Reactor 那样还需要应用进程主动发起 read&#x2F;write 来读写数据，操作系统完成读写工作后，就会通知应用进程直接处理数据。\n\n因此，Reactor 可以理解为「来了事件操作系统通知应用进程，让应用进程来处理」，而 Proactor 可以理解为「来了事件操作系统来处理，处理完再通知应用进程」。这里的「事件」就是有新连接、有数据可读、有数据可写的这些 I&#x2F;O 事件这里的「处理」包含从驱动读取到内核以及从内核读取到用户空间。\n无论是 Reactor，还是 Proactor，都是一种基于「事件分发」的网络编程模式，区别在于 Reactor 模式是基于「待完成」的 I&#x2F;O 事件，而 Proactor 模式则是基于「已完成」的 I&#x2F;O 事件。\n\n\n\n\n介绍一下 Proactor 模式的工作流程：\n\nProactor Initiator 负责创建 Proactor 和 Handler 对象，并将 Proactor 和 Handler 都通过 Asynchronous Operation Processor 注册到内核；\nAsynchronous Operation Processor 负责处理注册请求，并处理 I&#x2F;O 操作；\nAsynchronous Operation Processor 完成 I&#x2F;O 操作后通知 Proactor；\nProactor 根据不同的事件类型回调不同的 Handler 进行业务处理；\nHandler 完成业务处理；\n\n可惜的是，在 Linux 下的异步 I&#x2F;O 是不完善的， aio 系列函数是由 POSIX 定义的异步操作接口，不是真正的操作系统级别支持的，而是在用户空间模拟出来的异步，并且仅仅支持基于本地文件的 aio 异步操作，网络编程中的 socket 是不支持的，这也使得基于 Linux 的高性能网络程序都是使用 Reactor 方案。\n而 Windows 里实现了一套完整的支持 socket 的异步编程接口，这套接口就是 IOCP，是由操作系统级别实现的异步 I&#x2F;O，真正意义上异步 I&#x2F;O，因此在 Windows 里实现高性能网络程序可以使用效率更高的 Proactor 方案。\n一致性哈希有的同学可能很快就想到了：哈希算法。因为对同一个关键字进行哈希计算，每次计算都是相同的值，这样就可以将某个 key 确定到一个节点了，可以满足分布式系统的负载均衡需求。\n哈希算法最简单的做法就是进行取模运算，比如分布式系统中有 3 个节点，基于 hash(key) % 3 公式对数据进行了映射。\n如果客户端要获取指定 key 的数据，通过下面的公式可以定位节点：\nhash(key) % 3\n\n如果经过上面这个公式计算后得到的值是 0，就说明该 key 需要去第一个节点获取。\n但是有一个很致命的问题，如果节点数量发生了变化，也就是在对系统做扩容或者缩容时，必须迁移改变了映射关系的数据，否则会出现查询不到数据的问题。\n同样的道理，如果我们对分布式系统进行缩容，比如移除一个节点，也会因为取模哈希函数中基数的变化，可能出现查询不到数据的问题。\n要解决这个问题的办法，就需要我们进行迁移数据，比如节点的数量从 3 变化为 4 时，要基于新的计算公式 hash(key) % 4 ，重新对数据和节点做映射。\n假设总数据条数为 M，哈希算法在面对节点数量变化时，**最坏情况下所有数据都需要迁移，所以它的数据迁移规模是 O(M)**，这样数据的迁移成本太高了。\n所以，我们应该要重新想一个新的算法，来避免分布式系统在扩容或者缩容时，发生过多的数据迁移。\n存在的问题一致哈希算法也用了取模运算，但与哈希算法不同的是，哈希算法是对节点的数量进行取模运算，而一致哈希算法是对 2^32 进行取模运算，是一个固定的值。\n我们可以把一致哈希算法是对 2^32 进行取模运算的结果值组织成一个圆环，就像钟表一样，钟表的圆可以理解成由 60 个点组成的圆，而此处我们把这个圆想象成由 2^32 个点组成的圆，这个圆环被称为哈希环\n一致性哈希要进行两步哈希：\n\n第一步：对存储节点进行哈希计算，也就是对存储节点做哈希映射，比如根据节点的 IP 地址进行哈希；\n第二步：当对数据进行存储或访问时，对数据进行哈希映射；\n\n所以，一致性哈希是指将「存储节点」和「数据」都映射到一个首尾相连的哈希环上。\n问题来了，对「数据」进行哈希映射得到一个结果要怎么找到存储该数据的节点呢？\n答案是，映射的结果值往顺时针的方向的找到第一个节点，就是存储该数据的节点。\n接着，对要查询的 key-01 进行哈希计算，确定此 key-01 映射在哈希环的位置，然后从这个位置往顺时针的方向找到第一个节点，就是存储该 key-01 数据的节点。\n比如，下图中的 key-01 映射的位置，往顺时针的方向找到第一个节点就是节点 A。\n所以，当需要对指定 key 的值进行读写的时候，要通过下面 2 步进行寻址：\n\n首先，对 key 进行哈希计算，确定此 key 在环上的位置；\n然后，从这个位置沿着顺时针方向走，遇到的第一节点就是存储 key 的节点。\n\n知道了一致哈希寻址的方式，我们来看看，如果增加一个节点或者减少一个节点会发生大量的数据迁移吗？\n你可以看到，key-02 和 key-03 不会受到影响，只有 key-01 需要被迁移节点 B。\n因此，在一致哈希算法中，如果增加或者移除一个节点，仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。\n上面这些图中 3 个节点映射在哈希环还是比较分散的，所以看起来请求都会「均衡」到每个节点。\n\n\n\n\n\n\n\n\n\n\n\n\n但是一致性哈希算法并不保证节点能够在哈希环上分布均匀，这样就会带来一个问题，会有大量的请求集中在一个节点上。\n","slug":"操作系统笔记","date":"2022-10-24T13:03:48.000Z","categories_index":"操作系统","tags_index":"操作系统,基础知识","author_index":"依水何安"},{"id":"09f2766bd638543cf5a9ec60a938ae77","title":"计算机网络笔记","content":"\n\n\n\n\n\n\n\n\n本文参考了小林coding以及自顶向下方法等计算机网络教程，写了一篇个人的笔记，其中也包含了本人对于一些小问题的记录和思考，以及整体框架的梳理。\n基础知识\n\n\n\n\n\n\n\n\n对于不同设备间的通信就需要使用网络通信，而设备是多样性的，所以要兼容设备就需要一套通用的网络协议\nTCP&#x2F;IP网络模型应用层最上层的，也是我们能直接接触到的就是应用层（Application Layer），我们电脑或手机使用的应用软件都是在应用层实现。那么，当两个不同设备的应用需要通信的时候，应用就把应用数据传给下一层，也就是传输层。应用层是不用去关心数据是如何传输的，而且应用层是工作在操作系统中的用户态，传输层及以下则工作在内核态。\n所以，应用层只需要专注于为用户提供应用功能，比如 HTTP、FTP、Telnet、DNS、SMTP等。\n传输层应用层的数据包会传给传输层，传输层（Transport Layer）是为应用层提供网络支持的。在传输层会有两个传输协议，分别是 TCP 和 UDP。\n\n\n\n\n\n\n\n\n\nTCP 的全称叫传输控制协议（Transmission Control Protocol），大部分应用使用的正是 TCP 传输层协议，比如 HTTP 应用层协议。TCP 相比 UDP 多了很多特性，比如流量控制、超时重传、拥塞控制等，这些都是为了保证数据包能可靠地传输给对方。\nUDP 相对来说就很简单，简单到只负责发送数据包，不保证数据包是否能抵达对方，但它实时性相对更好，传输效率也高。当然，UDP 也可以实现可靠传输，把 TCP 的特性在应用层上实现就可以，不过要实现一个商用的可靠 UDP 传输协议，也不是一件简单的事情。\n应用需要传输的数据可能会非常大，如果直接传输就不好控制，因此当传输层的数据包大小超过 MSS（TCP 最大报文段长度） ，就要将数据包分块，这样即使中途有一个分块丢失或损坏了，只需要重新发送这一个分块，而不用重新发送整个数据包。在 TCP 协议中，我们把每个分块称为一个 TCP 段（TCP Segment）。\n当设备作为接收方时，传输层则要负责把数据包传给应用，但是一台设备上可能会有很多应用在接收或者传输数据，因此需要用一个编号将应用区分开来，这个编号就是端口。\n比如 80 端口通常是 Web 服务器用的，22 端口通常是远程登录服务器用的。而对于浏览器（客户端）中的每个标签栏都是一个独立的进程，操作系统会为这些进程分配临时的端口号。\n由于传输层的报文中会携带端口号，因此接收方可以识别出该报文是发送给哪个应用。\n网络层实际的传输功能就交给下一层，也就是网络层（Internet Layer）。\n网络层最常使用的是 IP 协议（Internet Protocol），IP 协议会将传输层的报文作为数据部分，再加上 IP 包头组装成 IP 报文，如果 IP 报文大小超过 MTU（以太网中一般为 1500 字节）就会再次进行分片，得到一个即将发送到网络的 IP 报文。\n\n\n\n\nIP 地址分成两种意义：\n\n一个是网络号，负责标识该 IP 地址是属于哪个「子网」的；\n一个是主机号，负责标识同一「子网」下的不同主机；\n\n需要配合子网掩码才能算出 IP 地址 的网络号和主机号。将 10.100.122.2 和 255.255.255.0 进行按位与运算，就可以得到网络号。\n在线子网掩码计算器\n这里就可以感知可用地址（主机号）和网络号之间的关系了。PS：ipv4如果是24位掩码才2^16太少了，难怪要变成ipv6。\n除了寻址能力， IP 协议还有另一个重要的能力就是路由。实际场景中，两台设备并不是用一条网线连接起来的，而是通过很多网关、路由器、交换机等众多网络设备连接起来的，那么就会形成很多条网络的路径，因此当数据包到达一个网络节点，就需要通过路由算法决定下一步走哪条路径。\n路由器寻址工作中，就是要找到目标地址的子网，找到后进而把数据包转发给对应的网络内。\n\n\n\n\n所以，IP 协议的寻址作用是告诉我们去往下一个目的地该朝哪个方向走，路由则是根据「下一个目的地」选择路径。寻址更像在导航，路由更像在操作方向盘。\n网络接口层生成了 IP 头部之后，接下来要交给网络接口层（Link Layer）在 IP 头部的前面加上 MAC 头部，并封装成数据帧（Data frame）发送到网络上。\n以太网在判断网络包目的地时和 IP 的方式不同，因此必须采用相匹配的方式才能在以太网中将包发往目的地，而 MAC 头部就是干这个用的，所以，在以太网进行通讯要用到 MAC 地址。\nMAC 头部是以太网使用的头部，它包含了接收方和发送方的 MAC 地址等信息，我们可以通过 ARP 协议获取对方的 MAC 地址。\n所以说，网络接口层主要为网络层提供「链路级别」传输的服务，负责在以太网、WiFi 这样的底层网络上发送原始数据包，工作在网卡这个层次，使用 MAC 地址来标识网络上的设备。\n\n\n\n\n\n\n提示\n这里有个疑惑就是mac既然是针对局域网的为什么不是先解析ip而是先解析mac，后来找到了答案：因为从主机到网关这条路上也是逃不过数据链路层的啊。\n而且解析的 MAC 地址并不是远程主机的，而是网关的，如果有 ARP 缓存的话也只用解析一次。\n\n\n总结\n\n\n\n\n\n\n网络接口层的传输单位是帧（frame），IP 层的传输单位是包（packet），TCP 层的传输单位是段（segment），HTTP 的传输单位则是消息或报文（message）。但这些名词并没有什么本质的区分，可以统称为数据包。\n\n从输入网址到页面显示过程1.解析URL\n\n\n\n当没有路径名时，就代表访问根目录下事先设置的默认文件，也就是 /index.html 或者 /default.html 这些文件，这样就不会发生混乱了。\n2.生成HTTP请求信息\n\n\n\n\nPOST和GET的区别\n\nPOST 和GET本质都是一样一样的。\n\nPOST和GET都是HTTP请求的基本方法。\n\n区别主要有以下几个：\n\nGET请求在浏览器刷新或者回退的时候是无害的。POST的话数据会被重新提交。\n\nGET可以被书签收藏，POST不行\n\nGET可以存在缓存中。POST不行\n\nGET 会将数据存在浏览器的历史中，POST不会\n\nGET 编码格式只能用ASCII码，POST没有限制\n\nGET 数据类型urlencode,POST是URLENCODE，form-data\n\n可见性 GET的参数在URL用户可以看见，POST的参数在REQUSET BODY中不会被用户看见\n\n安全性 GET相对不安全 POST相对安全些\n\n长度 GET的参数一般限制2048（和WEB服务器相关），POST的参数无限制。\n\n\n\nGET 和POST在请求的时候\n\nGET 是将数据中的hearder 和 data 一起发送给服务端，返回200code\nPOST 是先将hearder发给服务器返回100continue，再发送data给到服务器，返回200\nGET 就发送了一个TCP数据包给服务器而POST发送了两次TCP数据包给服务器\nGET和POST是已经有定义好的说明的，最好不要混用。\n\n\nGET和POST本质上是一样一样的，GET可以加Request Body ，POST也可以在URL中添加参数。实现是可以的。\n  \n  \n  \n\n\n\n3.真实地址查询-DNS通过浏览器解析 URL 并生成 HTTP 消息后，需要委托操作系统将消息发送给 Web 服务器。\n但在发送之前，还有一项工作需要完成，那就是查询服务器域名对应的 IP 地址，因为委托操作系统发送消息时，必须提供通信对象的 IP 地址。\nDNS 中的域名都是用句点来分隔的，比如 www.server.com，这里的句点代表了不同层次之间的界限。\n在域名中，越靠右的位置表示其层级越高。\n\n\n\n\n\n\n\n\n\n域名解析的工作流程\n\n客户端首先会发出一个 DNS 请求，问www.server.com 的 IP 是啥，并发给本地 DNS 服务器（也就是客户端的 TCP&#x2F;IP 设置中填写的 DNS 服务器地址）。\n本地域名服务器收到客户端的请求后，如果缓存里的表格能找到www.server.com，则它直接返回 IP 地址。如果没有，本地 DNS 会去问它的根域名服务器：“老大， 能告诉我www.server.com的 IP 地址吗？” 根域名服务器是最高层次的，它不直接用于域名解析，但能指明一条道路。\n根 DNS 收到来自本地 DNS 的请求后，发现后置是 .com，说：www.server.com这个域名归 .com 区域管理”，我给你 .com 顶级域名服务器地址给你，你去问问它吧。”\n本地 DNS 收到顶级域名服务器的地址后，发起请求问“老二， 你能告诉我 www.server.com的 IP 地址吗？”\n顶级域名服务器说：“我给你负责www.server.com区域的权威 DNS 服务器的地址，你去问它应该能问到”。\n本地 DNS 于是转向问权威 DNS 服务器：“老三，www.server.com对应的IP是啥呀？” server.com 的权威 DNS 服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。\n权威 DNS 服务器查询后将对应的 IP 地址 X.X.X.X 告诉本地 DNS。\n本地 DNS 再将 IP 地址返回客户端，客户端和目标建立连接。\n\n\n\n\n\n浏览器会先看自身有没有对这个域名的缓存，如果有，就直接返回，如果没有，就去问操作系统，操作系统也会去看自己的缓存，如果有，就直接返回，如果没有，再去 hosts 文件看，也没有，才会去问「本地 DNS 服务器」。\n4.协议栈通过 DNS 获取到 IP 后，就可以把 HTTP 的传输工作交给操作系统中的协议栈。\n协议栈的内部分为几个部分，分别承担不同的工作。上下关系是有一定的规则的，上面的部分会向下面的部分委托工作，下面的部分收到委托的工作并执行。\n应用程序（浏览器）通过调用 Socket 库，来委托协议栈工作。协议栈的上半部分有两块，分别是负责收发数据的 TCP 和 UDP 协议，这两个传输协议会接受应用层的委托执行收发数据的操作。\n协议栈的下面一半是用 IP 协议控制网络包收发操作，在互联网上传数据时，数据会被切分成一块块的网络包，而将网络包发送给对方的操作就是由 IP 负责的。\n此外 IP 中还包括 ICMP 协议和 ARP 协议。\n\nICMP 用于告知网络包传送过程中产生的错误以及各种控制信息。\nARP 用于根据 IP 地址查询相应的以太网 MAC 地址。\n\nIP 下面的网卡驱动程序负责控制网卡硬件，而最下面的网卡则负责完成实际的收发操作，也就是对网线中的信号执行发送和接收操作。\n5.TCP\n\n\n\n首先，源端口号和目标端口号是不可少的，如果没有这两个端口号，数据就不知道应该发给哪个应用。\n接下来有包的序号，这个是为了解决包乱序的问题。\n还有应该有的是确认号，目的是确认发出去对方是否有收到。如果没有收到就应该重新发送，直到送达，这个是为了解决不丢包的问题。\n接下来还有一些状态位。例如 SYN 是发起一个连接，ACK 是回复，RST 是重新连接，FIN 是结束连接等。TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更。\n还有一个重要的就是窗口大小。TCP 要做流量控制，通信双方各声明一个窗口（缓存大小），标识自己当前能够的处理能力，别发送的太快，撑死我，也别发的太慢，饿死我。\n除了做流量控制以外，TCP还会做拥塞控制，对于真正的通路堵车不堵车，它无能为力，唯一能做的就是控制自己，也即控制发送的速度。不能改变世界，就改变自己嘛。\n\n\n\n\n\n\n\n\n\nTCP 传输数据之前，要先三次握手建立连接\n在 HTTP 传输数据之前，首先需要 TCP 建立连接，TCP 连接的建立，通常称为三次握手。\n这个所谓的「连接」，只是双方计算机里维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像这样。\n\n\n\n\n\n一开始，客户端和服务端都处于 CLOSED 状态。先是服务端主动监听某个端口，处于 LISTEN 状态。\n然后客户端主动发起连接 SYN，之后处于 SYN-SENT 状态。\n服务端收到发起的连接，返回 SYN，并且 ACK 客户端的 SYN，之后处于 SYN-RCVD 状态。\n客户端收到服务端发送的 SYN 和 ACK 之后，发送对 SYN 确认的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。\n服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了。\n\n所以三次握手目的是保证双方都有发送和接收的能力。\n如果 HTTP 请求消息比较长，超过了 MSS 的长度，这时 TCP 就需要把 HTTP 的数据拆解成一块块的数据发送，而不是一次性发送所有数据。\n\nMTU：一个网络包的最大长度，以太网中一般为 1500 字节。\nMSS：除去 IP 和 TCP 头部之后，一个网络包所能容纳的 TCP 数据的最大长度。\n\n数据会被以 MSS 的长度为单位进行拆分，拆分出来的每一块数据都会被放进单独的网络包中。也就是在每个被拆分的数据加上 TCP 头信息，然后交给 IP 模块来发送数据。\n6.IPTCP 模块在执行连接、收发、断开等各阶段操作时，都需要委托 IP 模块将数据封装成网络包发送给通信对象。\n\n\n\n\n在 IP 协议里面需要有源地址 IP 和 目标地址 IP：\n\n源地址IP，即是客户端输出的 IP 地址；\n目标地址，即通过 DNS 域名解析得到的 Web 服务器 IP。\n\n因为 HTTP 是经过 TCP 传输的，所以在 IP 包头的协议号，要填写为 06（十六进制），表示协议为 TCP。\n\n\n\n\n\n\n假设客户端有多个网卡，就会有多个 IP 地址，那 IP 头部的源地址应该选择哪个 IP 呢？\n\n\n\n\n\n\n\n首先先和第一条目的子网掩码（Genmask）进行 与运算，得到结果为 192.168.10.0，但是第一个条目的 Destination 是 192.168.3.0，两者不一致所以匹配失败。\n再与第二条目的子网掩码进行 与运算，得到的结果为 192.168.10.0，与第二条目的 Destination 192.168.10.0 匹配成功，所以将使用 eth1 网卡的 IP 地址作为 IP 包头的源地址。\n\n\n\n那么假设 Web 服务器的目标地址是 10.100.20.100，那么依然依照上面的路由表规则判断，判断后的结果是和第三条目匹配。\n第三条目比较特殊，它目标地址和子网掩码都是 0.0.0.0，这表示默认网关，如果其他所有条目都无法匹配，就会自动匹配这一行。并且后续就把包发给路由器，Gateway 即是路由器的 IP 地址。\n7.MAC生成了 IP 头部之后，接下来网络包还需要在 IP 头部的前面加上 MAC 头部。\n在 MAC 包头里需要发送方 MAC 地址和接收方目标 MAC 地址，用于两点之间的传输。\n一般在 TCP&#x2F;IP 通信里，MAC 包头的协议类型只使用：\n\n0800 ： IP 协议\n0806 ： ARP 协议\n\n\n\n\n\n\n\n\n\n\nMAC 发送方和接收方如何确认?\n发送方的 MAC 地址获取就比较简单了，MAC 地址是在网卡生产时写入到 ROM 里的，只要将这个值读取出来写入到 MAC 头部就可以了。\n接收方的 MAC 地址就有点复杂了，只要告诉以太网对方的 MAC 的地址，以太网就会帮我们把包发送过去，那么很显然这里应该填写对方的 MAC 地址。\n\n\n\n\n\n\n\n\n\n既然知道要发给谁，按如何获取对方的 MAC 地址呢？\n所以先得搞清楚应该把包发给谁，这个只要查一下路由表就知道了。在路由表中找到相匹配的条目，然后把包发给 Gateway 列中的 IP 地址就可以了。\nARP 协议会在以太网中以广播的形式，对以太网所有的设备喊出：“这个 IP 地址是谁的？请把你的 MAC 地址告诉我”。\n然后就会有人回答：“这个 IP 地址是我的，我的 MAC 地址是 XXXX”。\n如果对方和自己处于同一个子网中，那么通过上面的操作就可以得到对方的 MAC 地址。然后，我们将这个 MAC 地址写入 MAC 头部，MAC 头部就完成了。\n\n\n\n\n\n\n如果在公网中如何获取MAC地址\n这里我犯了一个错误，犯了同一个错误，就是把广域网（或者叫公网）的网络请求中的目标地址当成是真正的 MAC 地址了。\n这从 Microsoft Network Monitor 中抓取的请求信息来看，向目标站点的请求头中的 MAC 地址是存在的是吧？但实际上这是我的局域网内的网关的 MAC 地址，对广域网的请求只能从网关走，那么我的目标就只能是网关。\n\n\n8.网卡网络包只是存放在内存中的一串二进制数字信息，没有办法直接发送给对方。因此，我们需要将数字信息转换为电信号，才能在网线上传输，也就是说，这才是真正的数据发送过程。\n负责执行这一操作的是网卡，要控制网卡还需要靠网卡驱动程序。\n网卡驱动获取网络包之后，会将其复制到网卡内的缓存区中，接着会在其开头加上报头和起始帧分界符，在末尾加上用于检测错误的帧校验序列。\n9.交换机下面来看一下包是如何通过交换机的。交换机的设计是将网络包原样转发到目的地。交换机工作在 MAC 层，也称为二层网络设备。\n\n\n\n\n\n\n\n\n\n交换机的包接收操作\n首先，电信号到达网线接口，交换机里的模块进行接收，接下来交换机里的模块将电信号转换为数字信号。\n然后通过包末尾的 FCS 校验错误，如果没问题则放到缓冲区。这部分操作基本和计算机的网卡相同，但交换机的工作方式和网卡不同。\n计算机的网卡本身具有 MAC 地址，并通过核对收到的包的接收方 MAC 地址判断是不是发给自己的，如果不是发给自己的则丢弃；相对地，交换机的端口不核对接收方 MAC 地址，而是直接接收所有的包并存放到缓冲区中。因此，和网卡不同，交换机的端口不具有 MAC 地址。\n将包存入缓冲区后，接下来需要查询一下这个包的接收方 MAC 地址是否已经在 MAC 地址表中有记录了。\n交换机的 MAC 地址表主要包含两个信息：\n\n一个是设备的 MAC 地址，\n另一个是该设备连接在交换机的哪个端口上。\n\n所以，交换机根据 MAC 地址表查找 MAC 地址，然后将信号发送到相应的端口。\n\n\n\n\n\n\n\n\n\n当 MAC 地址表找不到指定的 MAC 地址会怎么样？\n地址表中找不到指定的 MAC 地址。这可能是因为具有该地址的设备还没有向交换机发送过包，或者这个设备一段时间没有工作导致地址被从地址表中删除了。\n这种情况下，交换机无法判断应该把包转发到哪个端口，只能将包转发到除了源端口之外的所有端口上，无论该设备连接在哪个端口上都能收到这个包。\n这样做不会产生什么问题，因为以太网的设计本来就是将包发送到整个网络的，然后只有相应的接收者才接收包，而其他设备则会忽略这个包。\n有人会说：“这样做会发送多余的包，会不会造成网络拥塞呢？”\n其实完全不用过于担心，因为发送了包之后目标设备会作出响应，只要返回了响应包，交换机就可以将它的地址写入 MAC 地址表，下次也就不需要把包发到所有端口了。\n局域网中每秒可以传输上千个包，多出一两个包并无大碍。\n此外，如果接收方 MAC 地址是一个广播地址，那么交换机会将包发送到除源端口之外的所有端口。\n以下两个属于广播地址：\n\nMAC 地址中的 FF:FF:FF:FF:FF:FF\nIP 地址中的 255.255.255.255\n\n\n\n\n\n\n\n提示\n如果目标ip不在公网是如何找到路由mac的，答案就是查路由表，命令为netstat -r，如果是公网ip就会直接default然后下一跳到路由ip从而找到路由器。\n在发送数据包时，如果目标主机不是本地局域网，填入的MAC地址是路由器，也就是把数据包转发给路由器，路由器一直转发下一个路由器，直到转发到目标主机的路由器，发现 IP 地址是自己局域网内的主机，就会 arp 请求获取目标主机的 MAC 地址，从而转发到这个服务器主机。\n转发的过程中，源IP地址和目标IP地址是不会变的（前提：没有使用 NAT 网络的），源 MAC 地址和目标 MAC 地址是会变化的。\n\n\n10.路由器网络包经过交换机之后，现在到达了路由器，并在此被转发到下一个路由器或目标设备。\n这一步转发的工作原理和交换机类似，也是通过查表判断包转发的目标。\n不过在具体的操作过程上，路由器和交换机是有区别的。\n\n因为路由器是基于 IP 设计的，俗称三层网络设备，路由器的各个端口都具有 MAC 地址和 IP 地址；\n而交换机是基于以太网设计的，俗称二层网络设备，交换机的端口不具有 MAC 地址。\n\n\n\n\n\n\n\n\n\n\n路由器的包接收操作\n首先，电信号到达网线接口部分，路由器中的模块会将电信号转成数字信号，然后通过包末尾的 FCS 进行错误校验。\n如果没问题则检查 MAC 头部中的接收方 MAC 地址，看看是不是发给自己的包，如果是就放到接收缓冲区中，否则就丢弃这个包。\n总的来说，路由器的端口都具有 MAC 地址，只接收与自身地址匹配的包，遇到不匹配的包则直接丢弃。\n\n\n\n\n\n\n\n\n\n查询路由表确定输出端口\n完成包接收操作之后，路由器就会去掉包开头的 MAC 头部。\nMAC 头部的作用就是将包送达路由器，其中的接收方 MAC 地址就是路由器端口的 MAC 地址。因此，当包到达路由器之后，MAC 头部的任务就完成了，于是 MAC 头部就会被丢弃。\n接下来，路由器会根据 MAC 头部后方的 IP 头部中的内容进行包的转发操作。\n转发操作分为几个阶段，首先是查询路由表判断转发目标。\n首先，我们需要根据路由表的网关列判断对方的地址。\n\n如果网关是一个 IP 地址，则这个IP 地址就是我们要转发到的目标地址，还未抵达终点，还需继续需要路由器转发。\n如果网关为空，则 IP 头部中的接收方 IP 地址就是要转发到的目标地址，也是就终于找到 IP 包头里的目标地址了，说明已抵达终点。\n\n知道对方的 IP 地址之后，接下来需要通过 ARP 协议根据 IP 地址查询 MAC 地址，并将查询的结果作为接收方 MAC 地址。\n路由器也有 ARP 缓存，因此首先会在 ARP 缓存中查询，如果找不到则发送 ARP 查询请求。\n接下来是发送方 MAC 地址字段，这里填写输出端口的 MAC 地址。还有一个以太类型字段，填写 0800 （十六进制）表示 IP 协议。\n网络包完成后，接下来会将其转换成电信号并通过端口发送出去。这一步的工作过程和计算机也是相同的。\n发送出去的网络包会通过交换机到达下一个路由器。由于接收方 MAC 地址就是下一个路由器的地址，所以交换机会根据这一地址将包传输到下一个路由器。\n接下来，下一个路由器会将包转发给再下一个路由器，经过层层转发之后，网络包就到达了最终的目的地。\n不知你发现了没有，在网络包传输的过程中，源 IP 和目标 IP 始终是不会变的，一直变化的是 MAC 地址，因为需要 MAC 地址在以太网内进行两个设备之间的包传输。\n11.数据包拆解\n\n\n\n数据包抵达服务器后，服务器会先扒开数据包的 MAC 头部，查看是否和服务器自己的 MAC 地址符合，符合就将包收起来。\n接着继续扒开数据包的 IP 头，发现 IP 地址符合，根据 IP 头中协议项，知道自己上层是 TCP 协议。\n于是，扒开 TCP 的头，里面有序列号，需要看一看这个序列包是不是我想要的，如果是就放入缓存中然后返回一个 ACK，如果不是就丢弃。TCP头部里面还有端口号， HTTP 的服务器正在监听这个端口号。\n于是，服务器自然就知道是 HTTP 进程想要这个包，于是就将包发给 HTTP 进程。\n服务器的 HTTP 进程看到，原来这个请求是要访问一个页面，于是就把这个网页封装在 HTTP 响应报文里。\nHTTP 响应报文也需要穿上 TCP、IP、MAC 头部，不过这次是源地址是服务器 IP 地址，目的地址是客户端 IP 地址。\n穿好头部衣服后，从网卡出去，交由交换机转发到出城的路由器，路由器就把响应数据包发到了下一个路由器，就这样跳啊跳。\n最后跳到了客户端的城门把守的路由器，路由器扒开 IP 头部发现是要找城内的人，于是又把包发给了城内的交换机，再由交换机转发到客户端。\n客户端收到了服务器的响应数据包后，同样也非常的高兴，客户能拆快递了！\n于是，客户端开始扒皮，把收到的数据包的皮扒剩 HTTP 响应报文后，交给浏览器去渲染页面，一份特别的数据包快递，就这样显示出来了！\n最后，客户端要离开了，向服务器发起了 TCP 四次挥手，至此双方的连接就断开了。\nLiunx系统收发网络包OSI七层网络模型为了使得多种设备能通过网络相互通信，和为了解决各种不同设备在网络互联中的兼容性问题，国际标准化组织制定了开放式系统互联通信参考模型（Open System Interconnection Reference Model），也就是 OSI 网络模型，该模型主要有 7 层，分别是应用层、表示层、会话层、传输层、网络层、数据链路层以及物理层。\n每一层负责的职能都不同，如下：\n\n应用层，负责给应用程序提供统一的接口；\n表示层，负责把数据转换成兼容另一个系统能识别的格式；\n会话层，负责建立、管理和终止表示层实体之间的通信会话；\n传输层，负责端到端的数据传输；\n网络层，负责数据的路由、转发、分片；\n数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；\n物理层，负责在物理网络中传输数据帧；\n\nLiunx网络协议栈\n\n\n\n从上图的的网络协议栈，你可以看到：\n\n应用程序需要通过系统调用，来跟 Socket 层进行数据交互；\nSocket 层的下面就是传输层、网络层和网络接口层；\n最下面的一层，则是网卡驱动程序和硬件网卡设备；\n\nLinux 接收网络包的流程网卡是计算机里的一个硬件，专门负责接收和发送网络包，当网卡接收到一个网络包后，会通过 DMA 技术，将网络包写入到指定的内存地址，也就是写入到 Ring Buffer ，这个是一个环形缓冲区，接着就会告诉操作系统这个网络包已经到达。\n操作系统如何感知网络包到达最简单的一种方式就是触发中断，也就是每当网卡收到一个网络包，就触发一个中断告诉操作系统。\n但是，这存在一个问题，在高性能网络场景下，网络包的数量会非常多，那么就会触发非常多的中断，要知道当 CPU 收到了中断，就会停下手里的事情，而去处理这些网络包，处理完毕后，才会回去继续其他事情，那么频繁地触发中断，则会导致 CPU 一直没完没了的处理中断，而导致其他任务可能无法继续前进，从而影响系统的整体效率。\n所以为了解决频繁中断带来的性能开销，Linux 内核在 2.6 版本中引入了 NAPI 机制，它是混合「中断和轮询」的方式来接收网络包，它的核心概念就是不采用中断的方式读取数据，而是首先采用中断唤醒数据接收的服务程序，然后 poll 的方法来轮询数据。\n因此，当有网络包到达时，会通过 DMA 技术，将网络包写入到指定的内存地址，接着网卡向 CPU 发起硬件中断，当 CPU 收到硬件中断请求后，根据中断表，调用已经注册的中断处理函数。\n硬件中断处理函数会做如下的事情：\n\n需要先「暂时屏蔽中断」，表示已经知道内存中有数据了，告诉网卡下次再收到数据包直接写内存就可以了，不要再通知 CPU 了，这样可以提高效率，避免 CPU 不停的被中断。\n接着，发起「软中断」，然后恢复刚才屏蔽的中断。\n\n至此，硬件中断处理函数的工作就已经完成。\n硬件中断处理函数做的事情很少，主要耗时的工作都交给软中断处理函数了。\n内核中的 ksoftirqd 线程专门负责软中断的处理，当 ksoftirqd 内核线程收到软中断后，就会来轮询处理数据。\nksoftirqd 线程会从 Ring Buffer 中获取一个数据帧，用 sk_buff 表示，从而可以作为一个网络包交给网络协议栈进行逐层处理。\n这里的具体流程可以参考Linux内核源码分析–详谈NAPI原理机制（超详细）\n网络协议栈首先，会先进入到网络接口层，在这一层会检查报文的合法性，如果不合法则丢弃，合法则会找出该网络包的上层协议的类型，比如是 IPv4，还是 IPv6，接着再去掉帧头和帧尾，然后交给网络层。\n到了网络层，则取出 IP 包，判断网络包下一步的走向，比如是交给上层处理还是转发出去。当确认这个网络包要发送给本机后，就会从 IP 头里看看上一层协议的类型是 TCP 还是 UDP，接着去掉 IP 头，然后交给传输层。\n传输层取出 TCP 头或 UDP 头，根据四元组「源 IP、源端口、目的 IP、目的端口」 作为标识，找出对应的 Socket，并把数据放到 Socket 的接收缓冲区。\n最后，应用层程序调用 Socket 接口，将内核的 Socket 接收缓冲区的数据「拷贝」到应用层的缓冲区，然后唤醒用户进程。\n至此，一个网络包的接收过程就已经结束了，你也可以从下图左边部分看到网络包接收的流程，右边部分刚好反过来，它是网络包发送的流程。\n\n\n\n\nLinux 发送网络包的流程首先，应用程序会调用 Socket 发送数据包的接口，由于这个是系统调用，所以会从用户态陷入到内核态中的 Socket 层，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。\n接下来，网络协议栈从 Socket 发送缓冲区中取出 sk_buff，并按照 TCP&#x2F;IP 协议栈从上到下逐层处理。\n如果使用的是 TCP 传输协议发送数据，那么先拷贝一个新的 sk_buff 副本 ，这是因为 sk_buff 后续在调用网络层，最后到达网卡发送完成的时候，这个 sk_buff 会被释放掉。而 TCP 协议是支持丢失重传的，在收到对方的 ACK 之前，这个 sk_buff 不能被删除。所以内核的做法就是每次调用网卡发送的时候，实际上传递出去的是 sk_buff 的一个拷贝，等收到 ACK 再真正删除。\n接着，对 sk_buff 填充 TCP 头。这里提一下，sk_buff 可以表示各个层的数据包，在应用层数据包叫 data，在 TCP 层我们称为 segment，在 IP 层我们叫 packet，在数据链路层称为 frame。\n为什么全部数据包只用一个结构体来描述呢？协议栈采用的是分层结构，上层向下层传递数据时需要增加包头，下层向上层数据时又需要去掉包头，如果每一层都用一个结构体，那在层之间传递数据的时候，就要发生多次拷贝，这将大大降低 CPU 效率。\n于是，为了在层级之间传递数据时，不发生拷贝，只用 sk_buff 一个结构体来描述所有的网络包，那它是如何做到的呢？是通过调整 sk_buff 中 data 的指针，比如：\n\n当接收报文时，从网卡驱动开始，通过协议栈层层往上传送数据报，通过增加 skb-&gt;data 的值，来逐步剥离协议首部。\n当要发送报文时，创建 sk_buff 结构体，数据缓存区的头部预留足够的空间，用来填充各层首部，在经过各下层协议时，通过减少 skb-&gt;data 的值来增加协议首部。\n\n\n\n\n\n然后交给网络层，在网络层里会做这些工作：选取路由（确认下一跳的 IP）、填充 IP 头、netfilter 过滤、对超过 MTU 大小的数据包进行分片。处理完这些工作后会交给网络接口层处理。\n网络接口层会通过 ARP 协议获得下一跳的 MAC 地址，然后对 sk_buff 填充帧头和帧尾，接着将 sk_buff 放到网卡的发送队列中。\n这一些工作准备好后，会触发「软中断」告诉网卡驱动程序，这里有新的网络包需要发送，驱动程序会从发送队列中读取 sk_buff，将这个 sk_buff 挂到 RingBuffer 中，接着将 sk_buff 数据映射到网卡可访问的内存 DMA 区域，最后触发真实的发送。\n当数据发送完成以后，其实工作并没有结束，因为内存还没有清理。当发送完成的时候，网卡设备会触发一个硬中断来释放内存，主要是释放 sk_buff 内存和清理 RingBuffer 内存。\n最后，当收到这个 TCP 报文的 ACK 应答时，传输层就会释放原始的 sk_buff 。\n\n\n\n\n\n\n\n\n\n发送网络数据的时候，涉及几次内存拷贝操作？\n第一次，调用发送数据的系统调用的时候，内核会申请一个内核态的 sk_buff 内存，将用户待发送的数据拷贝到 sk_buff 内存，并将其加入到发送缓冲区。\n第二次，在使用 TCP 传输协议的情况下，从传输层进入网络层的时候，每一个 sk_buff 都会被克隆一个新的副本出来。副本 sk_buff 会被送往网络层，等它发送完的时候就会释放掉，然后原始的 sk_buff 还保留在传输层，目的是为了实现 TCP 的可靠传输，等收到这个数据包的 ACK 时，才会释放原始的 sk_buff 。\n第三次，当 IP 层发现 sk_buff 大于 MTU 时才需要进行。会再申请额外的 sk_buff，并将原来的 sk_buff 拷贝为多个小的 sk_buff。\nHTTPHTTP 基本概念HTTP 是超文本传输协议，也就是HyperText Transfer Protocol。\n协议HTTP 是一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范（两个以上的参与者），以及相关的各种控制和错误处理方式（行为约定和规范）。\n传输HTTP 协议是一个双向协议。而在 HTTP 里，需要中间人遵从 HTTP 协议，只要不打扰基本的数据传输，就可以添加任意额外的东西。\n针对传输，我们可以进一步理解了 HTTP。\nHTTP 是一个在计算机世界里专门用来在两点之间传输数据的约定和规范。\n超文本HTTP 传输的内容是「超文本」。\n我们先来理解「文本」，在互联网早期的时候只是简单的字符文字，但现在「文本」的涵义已经可以扩展为图片、视频、压缩包等，在 HTTP 眼里这些都算作「文本」。\n再来理解「超文本」，它就是超越了普通文本的文本，它是文字、图片、视频等的混合体，最关键有超链接，能从一个超文本跳转到另外一个超文本。\nHTML 就是最常见的超文本了，它本身只是纯文字文件，但内部用很多标签定义了图片、视频等的链接，再经过浏览器的解释，呈现给我们的就是一个文字、有画面的网页了。\nHTTP 常见的状态码有哪些？1xx 类状态码属于提示信息，是协议处理中的一种中间状态，实际用到的比较少。\n2xx 类状态码表示服务器成功处理了客户端的请求，也是我们最愿意看到的状态。\n\n「200 OK」是最常见的成功状态码，表示一切正常。如果是非 HEAD 请求，服务器返回的响应头都会有 body 数据。\n「204 No Content」也是常见的成功状态码，与 200 OK 基本相同，但响应头没有 body 数据。\n「206 Partial Content」是应用于 HTTP 分块下载或断点续传，表示响应返回的 body 数据并不是资源的全部，而是其中的一部分，也是服务器处理成功的状态。\n\n3xx 类状态码表示客户端请求的资源发生了变动，需要客户端用新的 URL 重新发送请求获取资源，也就是重定向。\n\n「301 Moved Permanently」表示永久重定向，说明请求的资源已经不存在了，需改用新的 URL 再次访问。\n「302 Found」表示临时重定向，说明请求的资源还在，但暂时需要用另一个 URL 来访问。\n\n301 和 302 都会在响应头里使用字段 Location，指明后续要跳转的 URL，浏览器会自动重定向新的 URL。\n\n「304 Not Modified」不具有跳转的含义，表示资源未修改，重定向已存在的缓冲文件，也称缓存重定向，也就是告诉客户端可以继续使用缓存资源，用于缓存控制。\n\n4xx 类状态码表示客户端发送的报文有误，服务器无法处理，也就是错误码的含义。\n\n「400 Bad Request」表示客户端请求的报文有错误，但只是个笼统的错误。\n「403 Forbidden」表示服务器禁止访问资源，并不是客户端的请求出错。\n「404 Not Found」表示请求的资源在服务器上不存在或未找到，所以无法提供给客户端。\n\n5xx 类状态码表示客户端请求报文正确，但是服务器处理时内部发生了错误，属于服务器端的错误码。\n\n「500 Internal Server Error」与 400 类型，是个笼统通用的错误码，服务器发生了什么错误，我们并不知道。\n「501 Not Implemented」表示客户端请求的功能还不支持，类似“即将开业，敬请期待”的意思。\n「502 Bad Gateway」通常是服务器作为网关或代理时返回的错误码，表示服务器自身工作正常，访问后端服务器发生了错误。\n「503 Service Unavailable」表示服务器当前很忙，暂时无法响应客户端，类似“网络服务正忙，请稍后重试”的意思。\n\nHTTP 常见字段有哪些？\n\n\n\n\n\n\n\n\n先贴一段我在开发中实际遇到的报文\n2022-11-01 00:02:17.075083 [info]: POST /5 HTTP/1.1\n2022-11-01 00:02:17.075265 [info]: Host: localhost:9006\n2022-11-01 00:02:17.075102 [info]: adjust timer once\n2022-11-01 00:02:17.075408 [info]: Connection: keep-alive\n2022-11-01 00:02:17.075624 [info]: Content-Length: 0\n2022-11-01 00:02:17.075775 [info]: Cache-Control: max-age=0\n2022-11-01 00:02:17.076017 [info]: sec-ch-ua: \"Not?A_Brand\";v=\"8\", \"Chromium\";v=\"108\", \"Microsoft Edge\";v=\"108\"\n2022-11-01 00:02:17.076236 [info]: sec-ch-ua-mobile: ?0\n2022-11-01 00:02:17.076510 [info]: sec-ch-ua-platform: \"Linux\"\n2022-11-01 00:02:17.076842 [info]: Upgrade-Insecure-Requests: 1\n2022-11-01 00:02:17.077076 [info]: Origin: http://localhost:9006\n2022-11-01 00:02:17.077304 [info]: Content-Type: application/x-www-form-urlencoded\n2022-11-01 00:02:17.077492 [info]: User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36 Edg/108.0.1438.1\n2022-11-01 00:02:17.077731 [info]: Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9\n2022-11-01 00:02:17.077977 [info]: Sec-Fetch-Site: same-origin\n2022-11-01 00:02:17.078187 [info]: Sec-Fetch-Mode: navigate\n2022-11-01 00:02:17.078396 [info]: Sec-Fetch-User: ?1\n2022-11-01 00:02:17.078630 [info]: Sec-Fetch-Dest: document\n2022-11-01 00:02:17.078890 [info]: Referer: http://localhost:9006/2CGISQL.cgi\n2022-11-01 00:02:17.079242 [info]: Accept-Encoding: gzip, deflate, br\n2022-11-01 00:02:17.079453 [info]: Accept-Language: zh-CN,zh;q=0.9,en;q=0.8,en-GB;q=0.7,en-US;q=0.6\n2022-11-01 00:02:17.079747 [info]: \n2022-11-01 00:02:17.081606 [info]: request:HTTP/1.1 200 OK\n\n2022-11-01 00:02:17.081919 [info]: request:HTTP/1.1 200 OK\nContent-Length:340\nConnection:keep-alive\n\n\n\n\nHost 字段：客户端发送请求时，用来指定服务器的域名。\n\nContent-Length 字段：服务器在返回数据时，会有 Content-Length 字段，表明本次回应的数据长度。\n\n\n\n\n\n\n\n\n\n\n\n大家应该都知道 HTTP 是基于 TCP 传输协议进行通信的，而使用了 TCP 传输协议，就会存在一个“粘包”的问题，HTTP 协议通过设置回车符、换行符作为 HTTP header 的边界，通过 Content-Length 字段作为 HTTP body 的边界，这两个方式都是为了解决“粘包”的问题。\n\nConnection 字段：最常用于客户端要求服务器使用「 HTTP 长连接」机制，以便其他请求复用。\n\nHTTP&#x2F;1.1 版本的默认连接都是长连接，但为了兼容老版本的 HTTP，需要指定 Connection 首部字段的值为 Keep-Alive。(和上面的例子一样)\n\nContent-Type 字段：用于服务器回应时，告诉客户端，本次数据是什么格式。\nContent-Encoding 字段：说明数据的压缩方法。表示服务器返回的数据使用了什么压缩格式\n\nGET 与 POST根据 RFC 规范，GET 的语义是从服务器获取指定的资源，这个资源可以是静态的文本、页面、图片视频等。GET 请求的参数位置一般是写在 URL 中，URL 规定只能支持 ASCII，所以 GET 请求的参数只允许 ASCII 字符 ，而且浏览器会对 URL 的长度有限制（HTTP协议本身对 URL长度并没有做任何规定）。\n比如，你打开我的文章，浏览器就会发送 GET 请求给服务器，服务器就会返回文章的所有文字及资源。\n根据 RFC 规范，POST 的语义是根据请求负荷（报文body）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 请求携带数据的位置一般是写在报文 body 中， body 中的数据可以是任意格式的数据，只要客户端与服务端协商好即可，而且浏览器不会对 body 大小做限制。\n比如，你在我文章底部，敲入了留言后点击「提交」（暗示你们留言），浏览器就会执行一次 POST 请求，把你的留言文字放进了报文 body 里，然后拼接好 POST 请求头，通过 TCP 协议发送给服务器。\n先说明下安全和幂等的概念：\n\n在 HTTP 协议里，所谓的「安全」是指请求方法不会「破坏」服务器上的资源。\n所谓的「幂等」，意思是多次执行相同的操作，结果都是「相同」的。\n\n如果从 RFC 规范定义的语义来看：\n\nGET 方法就是安全且幂等的，因为它是「只读」操作，无论操作多少次，服务器上的数据都是安全的，且每次的结果都是相同的。所以，可以对 GET 请求的数据做缓存，这个缓存可以做到浏览器本身上（彻底避免浏览器发请求），也可以做到代理上（如nginx），而且在浏览器中 GET 请求可以保存为书签。\nPOST 因为是「新增或提交数据」的操作，会修改服务器上的资源，所以是不安全的，且多次提交数据就会创建多个资源，所以不是幂等的。所以，浏览器一般不会缓存 POST 请求，也不能把 POST 请求保存为书签。\n\n做个简要的小结。\nGET 的语义是请求获取指定的资源。GET 方法是安全、幂等、可被缓存的。\nPOST 的语义是根据请求负荷（报文主体）对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，（大部分实现）不可缓存。\n","slug":"计算机网络笔记","date":"2022-10-19T13:57:03.000Z","categories_index":"计算机网络","tags_index":"计算机网络,基础知识","author_index":"依水何安"},{"id":"d198ad69ab98260fa3db17c94f83ffaa","title":"mysql常用语句","content":"\n\n\n\n\n\n\n\n\n这一章是纯粹的个人笔记，所以不会按照目录的方式分类各种语句，因为有点麻烦，如果有空的话可能会整理吧，主要还是注释形式来记录一些语句的用法（因为我的mysql使用的是DataGrip所以可以比较方便的记录语句，如果有兴趣我也可以出一期安装和配置mysql已经DG的教程）\n\n\n\n\n#使用Mysql\ncreate DATABASE course; #创建数据库\nuse course;#使用数据库\nshow tables ;#展示当前数据库的表名\nshow databases ;#展示所有数据库的名\nshow columns from customers; #展示一个表的内容\nshow grants;#显示授予用户的安全权限\n\n#检索数据\nSELECT prod_name from products; #从表中检索元素\n\n#排序检索数据\nSELECT prod_id,prod_name,prod_price from products order by prod_price desc,prod_name; #DESC为降序排列，默认为升序关键词为ASC\nselect  distinct vend_id from products; #distinct唯一化关键字，如果select多个将会全部相同才会删除\n\n#数据过滤\nselect prod_name,prod_price from products where prod_price between 2.50 and 10 order by prod_price; #where条件语句筛选，包括&gt; &lt; !&#x3D; between等\nselect prod_id,prod_price,prod_name from products where vend_id &#x3D;1003 and prod_price &lt;&#x3D;10;\nselect prod_name,prod_price from products where vend_id &#x3D;1003 or vend_id &#x3D;1002; #AND或OR操作符实现where语句组合\nselect prod_name,prod_price from products where vend_id &#x3D;1003 or vend_id &#x3D;1002 and prod_price&gt;&#x3D;10;\nselect prod_name,prod_price from products where (vend_id &#x3D;1003 or vend_id &#x3D;1002) and prod_price&gt;&#x3D;10;#如果使用and和or的组合操作必须使用圆括号来保证语义，否则会默认的优先处理and语句。\nselect prod_name,prod_price from products where  vend_id in(1002,1003) order by prod_name;#in操作符类似于or但是执行更快因为in只需要全部扫描一遍，但or每个语句都要扫描。\nselect prod_name,prod_price from products where  vend_id not in(1002,1003) order by prod_name;#not就是简单的取反操作\n\n#使用通配符过滤\nselect prod_id,prod_name from products where prod_name like &#39;jet%&#39;;#like操作符搜索通配符匹配，%则表示无视后续的字符串只需开头为jet，通过修改配置可以区分大小写，默认不区分\nselect prod_id,prod_name from products where prod_name like &#39;%anvil%&#39;;\nselect prod_id,prod_name from products where prod_name like &#39;1%l&#39;;\nselect prod_id,prod_name from products where prod_name like &#39;_ ton anvil&#39;;#_通配符只能替换一个字符，不能多也不能少而%可以是0个字符\n\n#使用正则表达式\nselect prod_id,prod_name from products where prod_name regexp &#39;1000|2000&#39;;\nselect prod_id,prod_name from products where prod_name regexp &#39;.000&#39;;#上面两个语句相等价，使用regexp作为操作符，需要注意的是和like不同，这里的内容可以匹配其中的一部分，而不需要使用通配符，但处理效率不高。\nselect prod_name from products where prod_name regexp &#39;[123] ton&#39;;#使用[]来定义一组字符，其中任意一个满足要求即可\nselect prod_name from products where prod_name regexp &#39;[1|2|3] ton&#39;;#与上一个语句等价\nselect prod_name from products where prod_name regexp &#39;1|2|3 ton&#39;;#如果是这样的语句将与预期出入，因为没有[]后，将会理解为匹配1或2或3 ton这样的话就会多出许多结果。\nselect prod_name from products where prod_name regexp &#39;[1-5] ton&#39;;#-表示一个范围的集合\nselect prod_name from products where prod_name regexp &#39;.&#39;;#.作为特殊字符将会输出全部结果，因此为了查找特殊字符.需要加上\\\\\nselect vend_name from vendors where vendors.vend_name regexp &#39;\\\\.&#39;;#同时还有一些预定义的字符集可以作为匹配\nselect prod_name from products where prod_name regexp &#39;\\\\([0-9] sticks?\\\\)&#39; order by prod_name;#?表示s可有可无，而（）作为特殊字符必须加上\\\\\nselect prod_name from products where prod_name regexp &#39;[[:digit:]]&#123;4&#125;&#39; order by prod_name;#&#123;&#125;表示前面的字符必须出现四次\nselect prod_name from products where prod_name regexp &#39;^[0-9\\\\.]&#39; order by prod_name;#定位元字符的使用\n\n#创建计算字段\nselect concat(vend_name , &#39; (&#39;, vend_country , &#39;)&#39;) from vendors order by vend_name;#concat()函数用于链接两个查询字段输出期望拼接成的格式\nselect concat(RTrim(vend_name) , &#39; (&#39;, vend_country , &#39;)&#39;) from vendors order by vend_name;#rtrim()去掉字符串右边的空格，同样的还有ltrim()去掉左边的空格以及trim()去掉两边的空格\nselect concat(RTrim(vend_name) , &#39; (&#39;, vend_country , &#39;)&#39;) as vend_title from vendors order by vend_name;#用as对关键词赋予别名\nselect prod_id, quantity, item_price, quantity*orderitems.item_price as expanded_price from orderitems where  order_num &#x3D; 20005;#可以通过as来实现一个计算并且输出\n#使用数据处理函数(需要注意的是，使用函数的可移植性远不如sql语句，所以一旦使用需要做好注释)\nselect vend_name, upper(vend_name) as vend_name_upcase from vendors order by vend_name;#upper()函数将字符串变成大写\nselect cust_name,cust_contact from customers where soundex(cust_contact) &#x3D; soundex(&#39;Y Lie&#39;); #soundex通过近似发音搜索匹配字符串\nselect cust_id, order_num,order_date from orders where date(order_date) &#x3D; &#39;2005-09-01&#39;;#这样的搜索并不可靠，可能会因为时间干扰检索，因此必须使用date()函数提取出日期部分\nselect cust_id, order_num,order_date from orders where date(order_date) between &#39;2005-09-01&#39; and &#39;2005-09-30&#39;;\nselect cust_id, order_num,order_date from orders where year(order_date) &#x3D; 2005 and month(order_date) &#x3D; 9;#这两个语句等价\n\n#汇总数据\nselect avg(prod_price) as avg_price from products where vend_id &#x3D; 1003;#avg()返回平均值,其只能用于单列并且忽略NULL行\nselect count(*) as num_cust from customers;#count()计数行，其中count(*)是无论空或非空，而具体列count()忽略null值\nselect count(cust_email) as num_cust from customers;#只统计非空值\nselect max(prod_price) as max_price from products;#选取最大值，对于非数据型最大值将会返回最后一行\nselect min(prod_price) as min_price from products;#选取最小值，对于非数据型最小值将会返回第一行\nselect sum(item_price*quantity) as total_price from orderitems where order_num &#x3D; 20005;#返回合计值，并且自动忽略NULL\nselect avg(distinct prod_price) as avg_price from products where vend_id &#x3D; 1003;#distinct唯一化\nselect count(*) as num_items,min(prod_price) as min,max(prod_price) as max,avg(prod_price) as avg from products;#组合查询\n\n#数据分组\nselect count(*) as num_prod from products group by vend_id;\n# GROUP BY子句可以包含任意数目的列。这使得能对分组进行嵌套，为数据分组提供更细致的控制。\n# 如果在GROUP BY子句中嵌套了分组，数据将在最后规定的分组上进行汇总。换句话说，在建立分组时，指定的所有列都一起计算（所以不能从个别的列取回数据)。\n# GROUP BY子句中列出的每个列都必须是检索列或有效的表达式（但不能是聚集函数）。如果在SELECT中使用表达式，则必须在GROUP BY子句中指定相同的表达式。不能使用别名。\n# 除聚集计算语句外，SELECT语句中的每个列都必须在GROUP BY子句中给出。\n# 如果分组列中具有NULL值，则NULL将作为一个分组返回。如果列中有多行NULL值，它们将分为一组。\n# #ROUP BY子句必须出现在WHERE子句之后，ORDER BY子句之前\nselect cust_id,count(*) as orders from orders group by cust_id having count(*)&gt;&#x3D;2;#having类似于where唯一区别在于where并没有分组的概念因此使用having代替\nselect vend_id,count(*) as num_prods from products where prod_price&gt;&#x3D;10 group by vend_id having count(*)&gt;&#x3D;2;#综合使用where和having\nselect order_num, sum(item_price*quantity) as ordertotal from orderitems group by order_num having sum(quantity*item_price) &gt;&#x3D;50;\nselect order_num, sum(item_price*quantity) as ordertotal from orderitems group by order_num having sum(quantity*item_price) &gt;&#x3D;50 order by ordertotal;#使用order by整合group by\n\n#使用子查询\nselect cust_name,cust_contact from customers where cust_id in (select cust_id from orders where order_num in (select order_num from orderitems where prod_id &#x3D; &#39;TNT2&#39;));#子查询通过嵌套由内而外的查询\nselect  cust_name,cust_state ,(select count(*) from orders where orders.cust_id &#x3D; customers.cust_id) as orders from customers order by cust_name;#注意限定列名\nselect  cust_name,cust_state ,(select count(*) from orders where cust_id &#x3D; cust_id) as orders from customers order by cust_name;#这样会自身比较\n#联结表\nselect vend_name, prod_name, prod_price from vendors,products where vendors.vend_id &#x3D; products.vend_id order by vend_name,prod_name;#两个表查询\nselect vend_name, prod_name, prod_price from vendors,products order by vend_name,prod_name;#两个表查询,如果没有where限制将是第一个表行数与第二表行数的乘积，名为笛卡尔积\nselect vend_name, prod_name, prod_price from vendors inner join products on vendors.vend_id &#x3D; products.vend_id;#inner join内部联结适用于等值联结\nselect prod_name, vend_name, prod_price, quantity from orderitems, products, vendors where vendors.vend_id &#x3D; products.vend_id and products.prod_id&#x3D;orderitems.prod_id and order_num&#x3D;20005;\n#创建高级联结\nselect cust_name, cust_contact from customers as c,orders as o, orderitems as oi where c.cust_id &#x3D; o.cust_id and oi.order_num &#x3D; o.order_num and prod_id &#x3D; &#39;TNT2&#39;;#使用别名简化语句\nselect p1.prod_id, p1.prod_name from products as p1 , products as p2 where p1.vend_id &#x3D; p2.vend_id and p2.prod_id &#x3D; &#39;DTNTR&#39;;#自联结，将自己的表作为别名\nselect customers.cust_id, order_num from customers left outer join orders on customers.cust_id &#x3D; orders.cust_id;#外联结需要left和right关键词决定驱动表\nselect customers.cust_name, customers.cust_id,count(o.cust_id) as num_ord from customers  left outer join orders o on customers.cust_id &#x3D; o.cust_id group by customers.cust_id;#聚集函数count使用group by就可以分组\n#组合查询\nselect vend_id, prod_id, prod_price from products where prod_price&lt;&#x3D;5\nunion\nselect vend_id, prod_id, prod_price from products where vend_id in (1001,1002);#union可以联结两个语句，将其拼接式的输入，在这个简单例子里等价于or\nselect vend_id, prod_id, prod_price from products where prod_price&lt;&#x3D;5\nunion all\nselect vend_id, prod_id, prod_price from products where vend_id in (1001,1002) order by vend_id,prod_price;#加上all后会输出重复的行,group by正常排序\n#插入数据\ninsert into customers values (null,&#39;Pep E. LaPew&#39;,&#39;100 Main Street&#39;,&#39;Los Angeles&#39;,&#39;CA&#39;,&#39;90046&#39;,&#39;USA&#39;,null,null);\n#更新和删除数据\nupdate customers set cust_email&#x3D;&#39;elmer@fudd.com&#39; where cust_id &#x3D; 10005;\nupdate customers set cust_email&#x3D;&#39;null&#39; where cust_id &#x3D; 10005;#删除某一行的列数据就是设置成null\ndelete from customers where cust_id &#x3D; 10006;#删除整行\n#创建表\ncreate table test(\n    cust_id int not null auto_increment,\n    cust_name char(50) not null DEFAULT 1,#指定默认值为1\n    cust_address char(50) not null ,#not null即不能为null\n    primary key (cust_id)#指定主键\n)engine &#x3D; innodb;#指定引擎\nalter table test add tmp char(20);#添加新列\nalter table test drop column tmp;#删除新加列\ndrop table test;#永久删除表，慎用，没有确认直接执行\nrename table test to test1;\n#使用视图\ncreate  view productcustomers as select cust_name, cust_contact, prod_id from customers ,orders , orderitems  where orders.cust_id &#x3D; customers.cust_id and orders.order_num &#x3D; orderitems.order_num ;\ndrop view productcustomers;#删除视图\nselect cust_name,cust_contact from productcustomers where prod_id &#x3D; &#39;TNT2&#39;;\nselect * from productcustomers;\n#视图很少更新因为使用分组，联结，子查询，并，聚集函数，distinc，导出都会导致试图无法更新。\n#存储过程\ncall productpricing(@pricelow,@pricehigh,@priceaverage);#使用存储过程，mysql所有变量都必须以@开始\ncreate procedure productpricing()\nbegin\n    select avg(prod_price) as priceaverage\n    from products;\nend;#创建一个存储过程，类似于函数\ncall productpricing();#使用存储过程\ndrop procedure productpricing;#删除例程\ncreate procedure productpricing(\n out pl decimal(8,2),\n out ph decimal(8,2),\n out pa decimal(8,2)\n)#out为输出，in为输入\nbegin\n    select min(prod_price) into pl from products;\n    select max(prod_price) into ph from products;\n    select avg(prod_price) into pa from products;\nend;#创建含参例程\nselect @pricehigh ,@priceaverage,@pricelow;\ncreate procedure processorders()\n#游标好像没什么用\nbegin\n    declare ordernumbers cursor for select order_num from orders;\n    open ordernumbers;\n    close ordernumbers;\nend;\ndrop procedure processorders;\n#触发器\ncreate trigger newproduct after insert on products\nfor each row select &#39;Producet added&#39; into @tmp;#创建触发器，需要存在变量中\ninsert into products values (&#39;ANV&#39;,1005,&#39;.123456&#39;,3.855,&#39;123123&#39;);\nselect @tmp;\n#事务处理\ninsert into test1 values(1231,&#39;123&#39;,&#39;123213123&#39;);\nstart transaction;#事务开始\ndelete from test1;\nselect * from test1;\nsavepoint del1;#事务保存点方便回滚\ninsert into test1 values(321,&#39;123&#39;,&#39;123213123&#39;);\nselect * from test1;\nrollback ;#事务回滚\nselect * from test1;\n\nstart transaction ;\ndelete from orderitems where order_num &#x3D; 20010;\ndelete from orders where order_num &#x3D;20010;\ncommit ;\nshow character set ;\nuse mysql;\nselect user from user;\nanalyze table orders;\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"mysql常用语句","date":"2022-10-17T09:13:29.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"},{"id":"5f1d861065ff3b07fbdc6d6fa1d8207a","title":"奇怪的小问题","content":"\n\n\n\n\n\n\n\n\n这个文章主要是记录一些平常突发奇想的一些小问题，所以没有什么顺序，如果你也有同样的疑惑希望可以帮到你。\nDFS先判断后递归还是先递归后判断\n\n\n\n\n\n\n\n\n今天像往常一样在写DFS突然冒出了一个奇怪的想法，究竟应该先递归还是应该先判断，然后就有了这个问题的探究。先说结论：都可以，几乎没有区别，虽然从最底层的角度看先判断优于先递归，毕竟省略了函数调用，但实际上影响非常有限。\n先上测试代码：asdasdasdsad\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\nusing namespace  std;\n\nvoid dfs1(vector&lt;vector&lt;int&gt;&gt;&amp; tmp, int i, int j,int target)&#123;\n    &#x2F;&#x2F;if(tmp[i][j] !&#x3D; target) return;\n    tmp[i][j] ++;\n    &#x2F;&#x2F;cout&lt;&lt;sum&lt;&lt;endl;\n    if(i &lt; 99 &amp;&amp; tmp[i+1][j] &#x3D;&#x3D; target) dfs1(tmp,i+1,j,target);\n    if(i &gt; 0 &amp;&amp; tmp[i-1][j]  &#x3D;&#x3D; target ) dfs1(tmp,i-1,j,target);\n    if(j &lt; 99 &amp;&amp; tmp[i][j+1]  &#x3D;&#x3D; target ) dfs1(tmp, i,j+1,target);\n    if(j &gt; 0 &amp;&amp; tmp[i][j-1]  &#x3D;&#x3D; target ) dfs1(tmp, i,j-1,target);\n&#125;\nvoid dfs2(vector&lt;vector&lt;int&gt;&gt;&amp; tmp, int i, int j,int target)&#123;\n    if(tmp[i][j] !&#x3D; target) return;\n    tmp[i][j] ++;\n    &#x2F;&#x2F;cout&lt;&lt;sum&lt;&lt;endl;\n    if(i &lt; 99 ) dfs1(tmp,i+1,j,target);\n    if(i &gt; 0 ) dfs1(tmp,i-1,j,target);\n    if(j &lt; 99) dfs1(tmp, i,j+1,target);\n    if(j &gt; 0) dfs1(tmp, i,j-1,target);\n&#125;\n\nint main() &#123;\n    int count &#x3D; 0;\n    for(int j &#x3D; 0;j&lt;100;j++)&#123;\n        double time1 &#x3D;0,time2 &#x3D;0;\n        clock_t startTime,endTime;\n        vector&lt;vector&lt;int&gt;&gt; tmp(100,vector&lt;int&gt;(100,0));\n        vector&lt;vector&lt;int&gt;&gt; tmp1(100,vector&lt;int&gt;(100,0));\n        startTime &#x3D; clock();\n        for(int i &#x3D;0; i &lt; 1000;i++)&#123;\n            dfs2(tmp,0,0,i);\n        &#125;\n        &#x2F;&#x2F;cout&lt;&lt;sum;\n        endTime &#x3D; clock();\n        time1 &#x3D; (double)(endTime - startTime) &#x2F; CLOCKS_PER_SEC;\n        cout&lt;&lt;&quot;先判断：&quot;&lt;&lt;(double)(endTime - startTime) &#x2F; CLOCKS_PER_SEC&lt;&lt;endl;\n        startTime &#x3D; clock();\n        for(int i &#x3D;0; i &lt; 1000;i++)&#123;\n            dfs2(tmp1,0,0,i);\n        &#125;\n        endTime &#x3D; clock();\n        time2 &#x3D; (double)(endTime - startTime) &#x2F; CLOCKS_PER_SEC;\n        cout&lt;&lt;&quot;先递归：&quot;&lt;&lt;(double)(endTime - startTime) &#x2F; CLOCKS_PER_SEC&lt;&lt;endl;\n        if(time1&gt;time2) count--;\n        if(time2&gt;time1) count++;\n    &#125;\n    cout&lt;&lt;&quot;总次数:&quot;&lt;&lt;&quot;100\\t&quot;&lt;&lt;&quot;先判断比先递归快的次数：&quot;&lt;&lt;count&lt;&lt;endl;\n&#125;\n\n这里顺便提一嘴，递归深度真的很有限哈哈哈。\n先说测试结论：两者快慢好像就是单纯的程序波动。\n我分别测试了好几组，发现每次结论的波动都非常大，而且即使是同一个程序使用两个一样的方法也会有很大的波动，所以看起来这里的影响已经是微乎其微的了。\n因此和我们常规感觉一致递归是调用自身的函数，而函数的每次调用都会在栈中产生调用帧（call frame, 用来保存内部变量、返回点等信息），可栈的空间是有限的，没法一次同时保存过多的调用帧。所以如果调用的次数多了就容易导致栈溢出，对空间消耗大。\n那么在条件允许的情况下先判断也不错，当然由于性能的影响微乎其微所以怎么做也完全可以根据代码简洁度和规范决定。\ni++和++i的效率问题C语言中的 i++ 和 ++i 是有区别的，这就有可能带来效率上的差异。如果有代码关心 i++ 执行时的 i 当前值，程序在对 i 进行自加操作时，将不得不先保存 i 的当前值，而 ++i 就无需保存当前值，这就会带来效率上的差异。如果没人关心 i++ 的当前值，那么现代大多数C语言编译器将会将这一差异优化掉，此时 i++ 和 ++i 不再有效率上的差异。\n数组越界的处理问题\n数组越界问题int a[10];\nfor (int i &#x3D; 0; i &lt;&#x3D; 12; i++)\n&#123;\n\ta[i] &#x3D; i;\n\tcout &lt;&lt;  a+i &lt;&lt; endl;\n&#125;\ncout &lt;&lt; a[12] &lt;&lt; endl;\n\n\n\n\n\n\n\n\n\n\n运行上述程序发现会无限循环输出0，因为数组大小为3，下标最大到2，而上述代码因为书写问题，导致for循环的最大索引访问到了3，数组a[3]访问越界，在C++中，只要不是访问受限的内存，所有的内存空间都可以自由访问，根据上面的数组寻址公式，a[3]会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量i的内存地址，也就是i的指针指向了&amp;a[3]，那么a[3]&#x3D;0相当与i&#x3D;0，所以会导致代码无限循环。\n但目前已经没有这个问题，在数组越界的情况下，数组仍然可以被正常调用，因为越界值不再被作为野指针，而是会继续在数组边界之后连续的被声明，非常有意思。\n并且会在程序的最后弹出数组越界的错误，也就是说当有数组越界时程序仍然可以正常执行，但是越界的定位却难以捉摸，因为指针的不确定性。所以在对数组进行管理时要格外小心。\nmain函数含参问题[[邓俊辉学习笔记#main函数含参]]\n类与结构体的定义概念：class和struct的语法基本相同，从声明到使用，都很相似，但是struct的约束要比class多，理论上，struct能做到的class都能做到，但class能做到的stuct却不一定做的到类型：struct是值类型，class是引用类型，因此它们具有所有值类型和引用类型之间的差异效率：由于堆栈的执行效率要比堆的执行效率高，但是堆栈资源却很有限，不适合处理逻辑复杂的大对象，因此struct常用来处理作为基类型对待的小对象，而class来处理某个商业逻辑关系：struct不仅能继承也能被继承 ，而且可以实现接口，不过Class可以完全扩展。内部结构有区别，struct只能添加带参的构造函数，不能使用abstract和protected等修饰符，不能初始化实例字段\n全局变量与局部变量的生命周期C&#x2F;C++变量的生命周期和static_山人自有锦囊妙计的博客-CSDN博客_c++成员变量生命周期\nstl中size的问题使用size减一个数的时候一定不能小于0，因为size是unsigned int，所以小于0还返回2^64次方-1。\n    while(nums[nums.size()-count]&gt;&#x3D;i)&#123;\n    \tcount++;\n    cout&lt;&lt;nums.size()&lt;&lt;count&lt;&lt;endl;\n    cout&lt;&lt;nums.size()-count&lt;&lt;endl;\n    &#125;\nscout:\n    22\n    0\n    23\n    18446744073709551615\n\n","slug":"奇怪的小问题","date":"2022-10-13T08:14:34.000Z","categories_index":"日常记录","tags_index":"日常记录","author_index":"依水何安"},{"id":"6e85e7b765209c5fafd1be815fdedbe2","title":"csapp笔记","content":"程序结构与执行浮点数在机器中表示一个浮点数时需要给出指数，这个指数用整数形式表示，这个整数叫做阶码，阶码指明了小数点在数据中的位置。\n\n\n\n\n\n\n\n\n\n阶码：对于任意一个二进制数N，可用N&#x3D;S×2^P表示，其中S为尾数，P为阶码，2为阶码的底，P、S都用二进制数表示，S表示N的全部有效数字，P指明小数点的位置。当阶码为固定值时，数的这种表示法称为定点表示，这样的数称为“定点数”；当阶码为可变时，数的这种表示法称为浮点表示，这样的数称为“浮点数”。\n对于一个浮点数来说\n来看下float, 他有1个符号位,8个指数位及24个有效数位(只保存23位). 当然刚才的binary32中的binary表明他是以二进制形式保存的.下图是一个float在内存中的表示. \n\n\n\n\n\n 其中有效数中还有一个隐藏位,永远是1. 所以有效数位的那部分永远是1.xxxxxxx…(23个x).另外一个要注意的地方是指数的表示,在IEEE754中规定是用偏移指数的方式表示的,意思是指数位中的数减去127后的数来表示最终的指数.比较上面的图中指数部分是01111100,转换成十进制数为124,然后减去127,结果是-3,也就是说指数部分是2-3&#x3D;1&#x2F;8&#x3D;0.125 .那么有效数部分呢? 加上隐藏的位之后表示为 1.01000000000000000000000&#x3D;1+(1*2-2)&#x3D;5&#x2F;4&#x3D;1.25 ,所以上面表示的数就是 1&#x2F;8 * 5&#x2F;4 &#x3D; 0.15625 .\n\n舍入\n\n\n\n\n\n\nC语言中的浮点数\n\n\n\n\n\n编译命令gcc -Og -S ./xxx.c  //指定.c文件生成汇编文件.s\n\n控制\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n## 数组分配\n\nC语言实现数组的方式非常简单所以很容易，很容易翻译成机器代码。\n\n\n\n\n\n\n\n\nGDB的常见指令\n\n\n","slug":"csapp笔记","date":"2022-10-09T13:30:13.000Z","categories_index":"操作系统","tags_index":"csapp,操作系统,计算机网络","author_index":"依水何安"},{"id":"298ae6749824eedc891feac490554768","title":"MySQL幻读","content":"\n\n\n\n\n\n\n\n\n幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n\n\n\n\n\n\n提示\n这里对“幻读”做一个说明：\n\n在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。\n上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。\n\n\n\n幻读存在的问题\n首先是语义上的。导致幻读的操作会破坏第一次当前读的语义。\n\n其次，是数据一致性的问题。锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。\n\n暴力加锁无法解决问题。即使把所有的记录都加上锁，还是阻止不了新插入的记录。\n\n\n幻读的解决方法\n\n\n\n\n\n\n\n\n行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。\n间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。\n间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。\n间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。\n逻辑一旦有并发，就会碰到死锁。\n间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。\n","slug":"MySQL幻读","date":"2022-09-25T15:36:04.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"},{"id":"dd59c704134a0428540392e3edcac680","title":"MySQL功能机制","content":"数据库表的空间回收机制\n\n\n\n\n\n\n\n\n一个 InnoDB 表包含两部分，即：表结构定义和数据。因为表结构定义占用的空间很小，所以我们今天主要讨论的是表数据。\n参数 innodb_file_per_table表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的：\n\n这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；\n这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。\n\n\n\n\n\n\n\n提示\n将 innodb_file_per_table 设置为 ON，是推荐做法\n\n\n数据删除流程\n\n\n\n假设，我们要删掉 R4 这个记录，InnoDB 引擎只会把 R4 这个记录标记为删除。如果之后要再插入一个 ID 在 300 和 600 之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。\nInnoDB 的数据是按页存储的,所以当删除整个页的时候，整个数据也都可以被复用，但是，数据页的复用跟记录的复用是不同的。\n\n记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了。\n而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。\n\ndelete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。\n不止是删除数据会造成空洞，插入数据也会。\n如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。\n也就是说，经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。\n因此我们就需要了解重建表。\n重建表\n表 A需要怎么做空间收缩\n你可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。\n由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。显然地，表 B 的主键索引更紧凑，数据页的利用率也更高。如果我们把表 B 作为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。\n\n\n\n\n\n\n\n\n\n注意\n在 MySQL 5.5 版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表 B 不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。\n\n\n而在MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。\n\n建立一个临时文件，扫描表 A 主键的所有数据页；\n用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；\n生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；\n临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；\n用临时文件替换表 A 的数据文件。\n\n由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。\nOnline 和 inplace说到 Online，我还要再和你澄清一下它和另一个跟 DDL 有关的、容易混淆的概念 inplace 的区别。\n你可能注意到了，在 MySQL 5.5 版本之前中，我们把表 A 中的数据导出来的存放位置叫作 tmp_table。这是一个临时表，是在 server 层创建的。\n在MySQL 5.6 版本开始，根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。\n所以，我现在问你，如果你有一个 1TB 的表，现在磁盘间是 1.2TB，能不能做一个 inplace 的 DDL 呢？\n答案是不能。因为，tmp_file 也是要占用临时空间的。\n如果说这两个逻辑之间的关系是什么的话，可以概括为：\n\nDDL 过程如果是 Online 的，就一定是 inplace 的；\n反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。\n\n\n\n\n\n\n\n提示\noptimize table、analyze table 和 alter table 这三种方式重建表的区别。\n\n从 MySQL 5.6 版本开始，alter table t engine &#x3D; InnoDB（也就是 recreate）默认的就是上面 Online DDL的流程了；\nanalyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；\noptimize table t 等于 recreate+analyze。\n\n\n\ncount(*) 的实现方式在不同的 MySQL 引擎中，count(*) 有不同的实现方式。\n\nMyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；\n而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。\n\n\n\n\n\n\n\n提示\n在这篇文章里讨论的是没有过滤条件的 count(*)，如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的。\n\n\n为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？\n这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。这里，我用一个算 count(*) 的例子来为你解释一下。\n假设表 t 中现在有 10000 条记录，我们设计了三个用户并行的会话。\n\n会话 A 先启动事务并查询一次表的总行数；\n会话 B 启动事务，插入一行后记录后，查询表的总行数；\n会话 C 先启动一个单独的语句，插入一行记录后，查询表的总行数。\n\n\n\n\n\n三个会话 A、B、C 会同时查询表 t 的总行数，但拿到的结果却不同。\n\n\n\n\n\n\ncount(*) 优化\nInnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。 在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。\n\n\n如果你用过 show table status 命令的话，就会发现这个命令的输出结果里面也有一个 TABLE_ROWS 用于显示这个表当前有多少行，这个命令执行挺快的，那这个 TABLE_ROWS 能代替 count(*) 吗？\n\n\n\n\n\n\n\n特别注意\n实际上，TABLE_ROWS 就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到 40% 到 50%。所以，show table status 命令显示的行数也不能直接使用。\n\n\n总的来说就是:\n\nMyISAM 表虽然 count(*) 很快，但是不支持事务；\nshow table status 命令虽然返回很快，但是不准确；\nInnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。\n\n数据行数的存储方式因此如果想要计数我们需要找个地方存储行数：\n1.用缓存系统保存计数你可以用一个 Redis 服务来保存这个表的总行数。这个表每被插入一行 Redis 计数就加 1，每被删除一行 Redis 计数就减 1。这种方式下，读和更新操作都很快，但你再想一下这种方式存在什么问题吗？\n没错，缓存系统可能会丢失更新。\nRedis 的数据不能永久地留在内存里，所以你会找一个地方把这个值定期地持久化存储起来。但即使这样，仍然可能丢失更新。试想如果刚刚在数据表中插入了一行，Redis 中保存的值也加了 1，然后 Redis 异常重启了，重启后你要从存储 redis 数据的地方把这个值读回来，而刚刚加 1 的这个计数操作却丢失了。\n当然了，这还是有解的。比如，Redis 异常重启以后，到数据库里面单独执行一次 count(*) 获取真实的行数，再把这个值写回到 Redis 里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。\n但实际上，将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的：\n\n一种是，查到的 100 行结果里面有最新插入记录，而 Redis 的计数里还没加 1；\n另一种是，查到的 100 行结果里没有最新插入的记录，而 Redis 的计数里已经加了 1。\n\n2.在数据库保存计数用缓存系统保存计数有丢失数据和计数不精确的问题。那么，如果我们把这个计数直接放到数据库里单独的一张计数表 C 中，又会怎么样呢？\n首先，这解决了崩溃丢失的问题，InnoDB 是支持崩溃恢复不丢数据的。\n由于 InnoDB 要支持事务，从而导致 InnoDB 表不能把 count(*) 直接存起来，然后查询的时候直接返回形成的。\n\n\n\n\n虽然会话 B 的读操作仍然是在 T3 执行的，但是因为这时候更新事务还没有提交，所以计数值加 1 这个操作对会话 B 还不可见。\n因此，会话 B 看到的结果里， 查计数值和“最近 100 条记录”看到的结果，逻辑上就是一致的。\n不同count的用法\n\n\n\n\n\n\n\n\ncount() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。\n所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。\n至于分析性能差别的时候，有几个原则：\n\nserver 层要什么就给什么；\nInnoDB 只给必要的值；\n现在的优化器只优化了 count(*) 的语义为“取行数”，其他“显而易见”的优化并没有做。\n\n对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。\n对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。\n单看这两个用法的差别的话，你能对比出来，count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。\n对于 count(字段) 来说：\n\n如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；\n如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。\n\n也就是前面的第一条原则，server 层要什么字段，InnoDB 就返回什么字段。\n但是 count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。\n\n强烈推荐这篇参考文章\nhttps://learnsql.com/blog/difference-between-count-distinct/ (这篇文章讲的非常好)\n\n\n排序机制全字段排序通常情况下，这个语句执行流程如下所示 ：\n\n初始化 sort_buffer，确定放入 name、city、age 这三个字段；\n从索引 city 找到第一个满足 city&#x3D;’杭州’条件的主键 id，也就是图中的 ID_X；\n到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；\n从索引 city 取下一个记录的主键 id；\n重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；\n对 sort_buffer 中的数据按照字段 name 做快速排序；\n按照排序结果取前 1000 行返回给客户端。\n\n\n\n\n\n\n\n\n注意\n“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。\n\n\nrowid 排序在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。\nmax_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。\ncity、name、age 这三个字段的定义总长度是 36，我把 max_length_for_sort_data 设置为 16，我们再来看看计算过程有什么改变。\n新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。\n整个执行流程就变成如下所示的样子：\n\n初始化 sort_buffer，确定放入两个字段，即 name 和 id；\n从索引 city 找到第一个满足 city&#x3D;’杭州’条件的主键 id，也就是图中的 ID_X；\n到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；\n从索引 city 取下一个记录的主键 id；\n重复步骤 3、4 直到不满足 city&#x3D;’杭州’条件为止，也就是图中的 ID_Y；\n对 sort_buffer 中的数据按照字段 name 进行排序；\n遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。\n\n全字段排序 VS rowid 排序如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。\n如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。\n这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。\n索引优化排序性能联合索引其实，并不是所有的 order by 语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。\n我们可以在这个市民表上创建一个 city 和 name 的联合索引，对应的 SQL 语句是：\nalter table t add index city_user(city, name);\n\n在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足 city&#x3D;’杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是杭州，name 的值就一定是有序的。\n这样整个查询过程的流程就变成了：\n\n从索引 (city,name) 找到第一个满足 city&#x3D;’杭州’条件的主键 id；\n到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；\n从索引 (city,name) 取下一个记录主键 id；\n重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city&#x3D;’杭州’条件时循环结束。\n\n覆盖索引覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。\n按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程。\n针对这个查询，我们可以创建一个 city、name 和 age 的联合索引，对应的 SQL 语句就是：\nalter table t add index city_user_age(city, name, age);\n\n这时，对于 city 字段的值相同的行来说，还是按照 name 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了：\n\n从索引 (city,name,age) 找到第一个满足 city&#x3D;’杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；\n从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；\n重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city&#x3D;’杭州’条件时循环结束。\n\n随机消息\n\n\n\n\n\n\n\n\n对于 InnoDB 表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。\n对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越小越好了，所以，MySQL 这时就会选择 rowid 排序。\n这条语句的执行流程是这样的：\n\n创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。\n从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。\n现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R 排序。\n初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。\n从内存临时表中一行一行地取出 R 值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。\n在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。\n排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。\n\n磁盘临时表\n\n\n\n\n\n\n\n\ntmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。\n磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。\n当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。\n采用是 MySQL 5.6 版本引入的一个新的排序算法，即：优先队列排序算法。接下来，我们就看看为什么没有使用临时文件的算法，也就是归并排序算法，而是采用了优先队列排序算法。\n其实，我们现在的 SQL 语句，只需要取 R 值最小的 3 个 rowid。但是，如果使用归并排序算法的话，虽然最终也能得到前 3 个值，但是这个算法结束后，已经将 10000 行数据都排好序了。\n也就是说，后面的 9997 行也是有序的了。但，我们的查询并不需要这些数据是有序的。所以，想一下就明白了，这浪费了非常多的计算量。\n而优先队列算法，就可以精确地只得到三个最小值，执行流程如下：\n\n对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；\n\n（对数据结构印象模糊的同学，可以先设想成这是一个由三个元素组成的数组）\n\n取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；\n重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。\n\n随机排序方法我们先把问题简化一下，如果只随机选择 1 个 word 值，可以怎么做呢？思路上是这样的：\n\n取得这个表的主键 id 的最大值 M 和最小值 N;\n用随机函数生成一个最大值到最小值之间的数 X &#x3D; (M-N)*rand() + N;\n取不小于 X 的第一个 ID 的行。\n\n这个方法效率很高，因为取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的 select 也可以用索引快速定位，可以认为就只扫描了 3 行。但实际上，这个算法本身并不严格满足题目的随机要求，因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。\n所以，为了得到严格随机的结果，你可以用下面这个流程:\n\n取得整个表的行数，并记为 C。\n取得 Y &#x3D; floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。\n再用 limit Y,1 取得一行。\n\n现在，我们再看看，如果我们按照随机算法 2 的思路，要随机取 3 个 word 值呢？你可以这么做：\n\n取得整个表的行数，记为 C；\n根据相同的随机方法得到 Y1、Y2、Y3；\n再执行三个 limit Y, 1 语句得到三行数据。\n\n全表扫描InnoDB 内存管理用的是最近最少使用 (Least Recently Used, LRU) 算法，这个算法的核心就是淘汰最久未使用的数据。\n下图是一个 LRU 算法的基本模型。\n\n\n\n\nInnoDB 管理 Buffer Pool 的 LRU 算法，是用链表来实现的。\n\n在图 6 的状态 1 里，链表头部是 P1，表示 P1 是最近刚刚被访问过的数据页；假设内存里只能放下这么多数据页；\n这时候有一个读请求访问 P3，因此变成状态 2，P3 被移到最前面；\n状态 3 表示，这次访问的数据页是不存在于链表中的，所以需要在 Buffer Pool 中新申请一个数据页 Px，加到链表头部。但是由于内存已经满了，不能申请新的内存。于是，会清空链表末尾 Pm 这个数据页的内存，存入 Px 的内容，然后放到链表头部。\n从效果上看，就是最久没有被访问的数据页 Pm，被淘汰了。\n\n假设按照这个算法，我们要扫描一个 200G 的表，而这个表是一个历史数据表，平时没有业务访问它。\n那么，按照这个算法扫描的话，就会把当前的 Buffer Pool 里的数据全部淘汰掉，存入扫描过程中访问到的数据页的内容。也就是说 Buffer Pool 里面主要放的是这个历史数据表的数据。\n对于一个正在做业务服务的库，这可不妙。你会看到，Buffer Pool 的内存命中率急剧下降，磁盘压力增加，SQL 语句响应变慢。\n所以，InnoDB 不能直接使用这个 LRU 算法。实际上，InnoDB 对 LRU 算法做了改进。\n\n\n\n\n在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域。图中 LRU_old 指向的就是 old 区域的第一个位置，是整个链表的 5&#x2F;8 处。也就是说，靠近链表头部的 5&#x2F;8 是 young 区域，靠近链表尾部的 3&#x2F;8 是 old 区域。\n改进后的 LRU 算法执行流程变成了下面这样。\n\n图 7 中状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态 2。\n之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 Px，是放在 LRU_old 处。\n处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：\n若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部；\n如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒。\n\n\n\n这个策略，就是为了处理类似全表扫描的操作量身定制的。还是以刚刚的扫描 200G 的历史数据表为例，我们看看改进后的 LRU 算法的操作逻辑：\n\n扫描过程中，需要新插入的数据页，都被放到 old 区域 ;\n一个数据页里面有多条记录，这个数据页会被多次访问到，但由于是顺序扫描，这个数据页第一次被访问和最后一次被访问的时间间隔不会超过 1 秒，因此还是会被保留在 old 区域；\n再继续扫描后续的数据，之前的这个数据页之后也不会再被访问到，于是始终没有机会移到链表头部（也就是 young 区域），很快就会被淘汰出去。\n\n可以看到，这个策略最大的收益，就是在扫描这个大表的过程中，虽然也用到了 Buffer Pool，但是对 young 区域完全没有影响，从而保证了 Buffer Pool 响应正常业务的查询命中率。\njoin算法\n\n\n\n\n\n\n\n\nMysql-表连接join中的NLJ、BNL算法\nIndex Nested-Loop Join（NJL）我们来看一下这个语句：\nselect * from t1 straight_join t2 on (t1.a&#x3D;t2.a);\n\n如果直接使用 join 语句，MySQL 优化器可能会选择表 t1 或 t2 作为驱动表，这样会影响我们分析 SQL 语句的执行过程。所以，为了便于分析执行过程中的性能问题，我改用 straight_join 让 MySQL 使用固定的连接方式执行查询，这样优化器只会按照我们指定的方式去 join。在这个语句里，t1 是驱动表，t2 是被驱动表。\n可以看到，在这条语句里，被驱动表 t2 的字段 a 上有索引，join 过程用上了这个索引，因此这个语句的执行流程是这样的：\n\n从表 t1 中读入一行数据 R；\n从数据行 R 中，取出 a 字段到表 t2 里去查找；\n取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；\n重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。\n\n这个过程是先遍历表 t1，然后根据从表 t1 中取出的每行数据中的 a 值，去表 t2 中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称 NLJ。\n可以看到，在这条语句里，被驱动表 t2 的字段 a 上有索引，join 过程用上了这个索引，因此这个语句的执行流程是这样的：\n\n从表 t1 中读入一行数据 R；\n从数据行 R 中，取出 a 字段到表 t2 里去查找；\n取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；\n重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。\n\n这个过程是先遍历表 t1，然后根据从表 t1 中取出的每行数据中的 a 值，去表 t2 中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称 NLJ。\n它对应的流程图如下所示：\n\n\n\n\n在这个流程里：\n\n对驱动表 t1 做了全表扫描，这个过程需要扫描 100 行；\n而对于每一行 R，根据 a 字段去表 t2 查找，走的是树搜索过程。由于我们构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描 100 行；\n所以，整个执行流程，总扫描行数是 200。\n\n到这里小结一下，通过上面的分析我们得到了两个结论：\n\n使用 join 语句，性能比强行拆成多个单表执行 SQL 语句的性能要好；\n如果使用 join 语句的话，需要让小表做驱动表。\n\n但是，你需要注意，这个结论的前提是“可以使用被驱动表的索引”。\nBlock Nested-Loop Join（BNL）这时候，被驱动表上没有可用的索引，算法的流程是这样的：\n\n把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；\n扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。\n\n\n\n\n\n可以看到，在这个过程中，对表 t1 和 t2 都做了一次全表扫描，因此总的扫描行数是 1100。由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做 100 次判断，总共需要在内存中做的判断次数是：100*1000&#x3D;10 万次。\n前面我们说过，如果使用 Simple Nested-Loop Join 算法进行查询，扫描行数也是 10 万行。因此，从时间复杂度上来说，这两个算法是一样的。但是，Block Nested-Loop Join 算法的这 10 万次判断是内存操作，速度上会快很多，性能也更好。\n接下来，我们来看一下，在这种情况下，应该选择哪个表做驱动表。\n假设小表的行数是 N，大表的行数是 M，那么在这个算法里：\n\n两个表都做一次全表扫描，所以总的扫描行数是 M+N；\n内存中的判断次数是 M*N。\n\n可以看到，调换这两个算式中的 M 和 N 没差别，因此这时候选择大表还是小表做驱动表，执行耗时是一样的。\n然后，你可能马上就会问了，这个例子里表 t1 才 100 行，要是表 t1 是一个大表，join_buffer 放不下怎么办呢？\njoin_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t1 的所有数据话，策略很简单，就是分段放。\n执行过程就变成了：\n\n扫描表 t1，顺序读取数据行放入 join_buffer 中，放完第 88 行 join_buffer 满了，继续第 2 步；\n扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回；\n清空 join_buffer；\n继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步。\n\n执行流程图也就变成这样：\n\n\n\n\n图中的步骤 4 和 5，表示清空 join_buffer 再复用。\n这个流程才体现出了这个算法名字中“Block”的由来，表示“分块去 join”。\n可以看到，这时候由于表 t1 被分成了两次放入 join_buffer 中，导致表 t2 会被扫描两次。虽然分成两次放入 join_buffer，但是判断等值条件的次数还是不变的，依然是 (88+12)*1000&#x3D;10 万次。\n我们再来看下，在这种情况下驱动表的选择问题。\n假设，驱动表的数据行数是 N，需要分 K 段才能完成算法流程，被驱动表的数据行数是 M。\n注意，这里的 K 不是常数，N 越大 K 就会越大，因此把 K 表示为λ*N，显然λ的取值范围是 (0,1)。\n所以，在这个算法的执行过程中：\n\n扫描行数是 N+λNM；\n内存判断 N*M 次。\n\nMulti-Range Read 优化（MRR）\n\n\n\n\n\n\n\n\nMulti-Range Read 优化 (MRR)。这个优化的主要目的是尽量使用顺序读盘。\n如果随着 a 的值递增顺序查询的话，id 的值就变成随机的，那么就会出现随机访问，性能相对较差。虽然“按行查”这个机制不能改，但是调整查询的顺序，还是能够加速的。\n因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。\n这，就是 MRR 优化的设计思路。此时，语句的执行流程变成了这样：\n\n根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;\n将 read_rnd_buffer 中的 id 进行递增排序；\n排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。\n\n这里，read_rnd_buffer 的大小是由 read_rnd_buffer_size 参数控制的。如果步骤 1 中，read_rnd_buffer 放满了，就会先执行完步骤 2 和 3，然后清空 read_rnd_buffer。之后继续找索引 a 的下个记录，并继续循环。\nBatched Key Access在 join_buffer 中放入的数据是 P1P100，表示的是只会取查询需要的字段。当然，如果 join buffer 放不下 P1P100 的所有数据，就会把这 100 行数据分成多段执行上图的流程。\n\n\n\n\n扩展 -hash join看到这里你可能发现了，其实上面计算 10 亿次那个操作，看上去有点儿傻。如果 join_buffer 里面维护的不是一个无序数组，而是一个哈希表的话，那么就不是 10 亿次判断，而是 100 万次 hash 查找。这样的话，整条语句的执行速度就快多了吧？\n确实如此。\n这，也正是 MySQL 的优化器和执行器一直被诟病的一个原因：不支持哈希 join。并且，MySQL 官方的 roadmap，也是迟迟没有把这个优化排上议程。\n实际上，这个优化思路，我们可以自己实现在业务端。实现流程大致如下：\n\nselect * from t1;取得表 t1 的全部 1000 行数据，在业务端存入一个 hash 结构，比如 C++ 里的 set、PHP 的数组这样的数据结构。\nselect * from t2 where b&gt;=1 and b&lt;=2000; 获取表 t2 中满足条件的 2000 行数据。\n把这 2000 行数据，一行一行地取到业务端，到 hash 结构的数据表中寻找匹配的数据。满足匹配的条件的这行数据，就作为结果集的一行。\n\n小结\n\n\n\n\n\n提示\n\nBKA 优化是 MySQL 已经内置支持的，建议你默认使用；\nBNL 算法效率低，建议你都尽量转成 BKA 算法。优化的方向就是给被驱动表的关联字段加上索引；\n基于临时表的改进方案，对于能够提前过滤出小数据的 join 语句来说，效果还是很好的；\nMySQL 目前的版本还不支持 hash join，但你可以配合应用端自己模拟出来，理论上效果要好于临时表的方案。\n\n\n\n临时表\n\n\n\n\n\n\n\n\n有的人可能会认为，临时表就是内存表。但是，这两个概念可是完全不同的。\n\n内存表，指的是使用 Memory 引擎的表，建表语法是 create table … engine&#x3D;memory。这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。除了这两个特性看上去比较“奇怪”外，从其他的特征上看，它就是一个正常的表。\n而临时表，可以使用各种引擎类型 。如果是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，写数据的时候是写到磁盘上的。当然，临时表也可以使用 Memory 引擎。\n\n\n\n\n\n\n\n提示\n可以看到，临时表在使用上有以下几个特点：\n\n建表语法是 create temporary table …。\n一个临时表只能被创建它的 session 访问，对其他线程不可见。所以，图中 session A 创建的临时表 t，对于 session B 就是不可见的。\n临时表可以与普通表同名。\nsession A 内有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表。\nshow tables 命令不显示临时表。\n\n\n\n也正是由于这个特性，临时表就特别适合我们文章开头的 join 优化这种场景。为什么呢？\n原因主要包括以下两个方面：\n\n不同 session 的临时表是可以重名的，如果有多个 session 同时执行 join 优化，不需要担心表名重复导致建表失败的问题。\n不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表由于会自动回收，所以不需要这个额外的操作。\n\n","slug":"MySQL功能机制","date":"2022-09-22T15:12:15.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"},{"id":"88440a5b541fa0a94c29d4531936445a","title":"MySQL锁设计","content":"\n\n\n\n\n\n\n\n\n根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。\n全局锁顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。\n当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：\n\n数据更新语句（数据的增删改）\n数据定义语句（包括建表、修改表结构等）\n更新类事务的提交语句。\n\n全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。\n\n\n\n\n\n\n\n特别注意\n但是让整库都只读，听上去就很危险：\n\n如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；\n如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。\n\n\n\n在可重复读隔离级别下开启一个事务。也可以解决这个问题。\n官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。\n为什么还需要 FTWRL 呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。\n所以，single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。\n既然要全库只读，为什么不使用 set global readonly&#x3D;true 的方式呢？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因：\n\n一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。\n二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。\n\n表级锁\n\n\n\n\n\n\n\n\nMySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。\n表锁的语法是 lock tables … read&#x2F;write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。\n举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。\n而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。\n另一类表级的锁是 MDL（metadata lock)。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。\n因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。\n\n读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。\n读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。\n\n行锁\n\n\n\n\n\n\n\n\nMySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。\n在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。\n知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。\n死锁和死锁检测当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。\n\n\n\n\n这时候，事务 A 在等待事务 B 释放 id&#x3D;2 的行锁，而事务 B 在等待事务 A 释放 id&#x3D;1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：\n\n一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。\n另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。\n\n\n\n\n\n\n\n提示\n在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。\n但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。\n\n\n所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。\n每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。\n怎么解决由这种热点行更新导致的性能问题呢？\n\n一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。\n\n另一个思路是控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。\n\n\n\n如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？\n你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1&#x2F;10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。\n这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。\n\n\n“快照”在 MVCC 里是怎么工作的？\n\n\n\n\n\n\n\n\n在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。\nInnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。\n而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。\n也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。\n\n\n\n\n\n\n提示\n更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。\n\n\n而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：\n\n在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；\n在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。\n\nMySQL实战45讲_8_从一个问题来加深对 mysql\n加锁规则这个规则中，包含了两个“原则”、两个“优化”和一个“bug”：\n\n原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。\n原则 2：查找过程中访问到的对象才会加锁。\n优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。\n优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。\n一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n\n","slug":"全局锁","date":"2022-09-17T12:22:15.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"},{"id":"464acd4e6150cb107fc5e6d33892ffb1","title":"友链留言","content":"友情链接金鱼井啊 - 在读研二研究生，记录嗯转码过程，不定时更新读研生活碎片。\n仰止 - 高山仰止，景行行止\nLuiYang - 与其临渊羡鱼，不如退而结网\nHades&amp;笔记 - 我本微末凡尘,却也心向天空\n月下叶子 - 日月东升西落，未曾负你我\n添加友链格式如果你想要和我交换友链只需要在下方的gitalk留下评论就行了，格式为:\n\n博客名称: \n博客简介：\n博客地址：\n\n当然我想你也会需要我的博客信息，那么只需要复制下面的信息就可以啦:\n\n博客名称：依水何安的博客\n博客简介：一个抽象的码农\n博客地址：https://yishuihean.cn/\n头像链接：https://cdn.staticaly.com/gh/jankin12138/IMG@main/img/b8d3b3c382fa44e5c92a361d33e0c616_hd.4sew3rxcedq0.jpg\n\n\n\n\n\n\n\n\n注意\n希望你的博客可以保证访问，并且保持维护状态（最近更新在三个月以内），不然有可能被清理哟。\n\n\n","slug":"友链留言","date":"2022-09-06T12:22:15.000Z","categories_index":"留言板","tags_index":"友链,留言板","author_index":"依水何安"},{"id":"76d4212e70fc90d13d8dd3025d415413","title":"事务隔离&数据库索引","content":"\n\n\n\n\n\n\n\n\n之前在字节青训营因为大作业的相关内容也接触过一些数据库方向的知识，但一直苦于没有系统性的学习和整理，所以这系列文章来总结和记录一些，个人觉得比较重要的内容，以便以后复习使用。主要参考文章是极客时间的MySQL45讲：MySQL 实战 45 讲 这次主要是事务和索引方面的内容，感觉写在一起太长了也不方便记录所以分成几个部分来写，如果后续觉得不方便查阅可能会合并。\n事务隔离\n\n\n\n\n\n\n\n\n简单来说，事务是由一条SQL语句，或者一组SQL语句组成的程序执行单元，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。\n\n支付举例\n最经典的例子就是转账，你要给朋友小王转 100 块钱，而此时你的银行卡只有 100 块钱。转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这 100 块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账。因此事务的作用就是保证一组数据库操作保持一致。\n\n\n隔离性\n\n\n\n\n\n\n\n\nACDI事务四大特性\n1.原子性（Atomicity）：指事务内所有操作要么一起执行成功，要么都一起失败(或者说是回滚)；如事务经典转账案例：A给B转账，A把钱扣了，但B没有收到；可见这种错误是不能接受的，最终会回滚，这也是原子性的重要性。\n2.一致性（Consistency）：指事务执行前后的状态一致，如事务经典转账案例：A给B互相转账，不管怎么转，最终两者钱的总和还是不变。\n3.持久性（Durability）：事务一旦提交，数据就已经永久保存了，不能再回滚。\n4.隔离性（Isolation）：指多个并发事务之间的操作互不干扰，但是事务的并发可能会导致数据脏读、不可重复读、幻读问题，根据业务情况，采用事务隔离级别进行对应数据读问题处理。\n隔离级别\n\n\n\n\n\n\n\n\nSQL 标准定义了四种隔离级别，MySQL 全都支持。这4种隔离级别，并行性能依次降低，安全性依次提高：\n\n读未提交（READ UNCOMMITTED）一个事务还没提交时，它做的变更就能被别的事务看到.\n读已提交 （READ COMMITTED）一个事务提交之后，它做的变更才会被其他事务看到。\n可重复读 （REPEATABLE READ）一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n串行化 （SERIALIZABLE）顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n\n视图实现\n在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n\n在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。\n\n在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。\n\n“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；\n\n“串行化”隔离级别下直接用加锁的方式来避免并行访问。\n\n\n\n\n\n可重复读场景\n假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。\n这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。\n\n\n事务隔离实现\n\n\n\n\n\n\n\n\n在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。当系统里没有比这个回滚日志更早的 read-view 的时候，系统会判断没有事务再需要用到这些回滚日志，此时回滚日志会被删除。\n\n\n\n\n\n\n提示\n尽量不要使用长业务\n\n\n长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。\n在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。\n事物的启动方式MySQL 的事务启动方式有以下几种：\n\n显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。\nset autocommit&#x3D;0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。\n\n\n\n\n\n\n\n\n注意\n有些客户端连接框架会默认连接成功后先执行一个 set autocommit&#x3D;0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。\n因此，建议总是使用 set autocommit&#x3D;1, 通过显式语句的方式来启动事务。\n\n\n\n\n\n\n\n\nQuestion\n现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？\n\n\n\nAnswer\n首先，从应用开发端来看：\n\n确认是否使用了 set autocommit&#x3D;0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。\n确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin&#x2F;commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。\n业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）\n\n其次，从数据库端来看：\n\n监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 &#x2F; 或者 kill；\nPercona 的 pt-kill 这个工具不错，推荐使用；\n在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；\n如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。\n\n\n\n数据库索引\n\n\n\n\n\n\n\n\n一句话简单来说，索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。\n\n\n\n\n\n\n\n特别注意\n对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\n\n\n常见模型1.哈希表（K-V）存储哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的值即 key，就可以找到其对应的值即 Value。结构如下图所示：\n\n需要注意的是，图中哈希表的的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。所以，哈希表这种结构适用于只有等值查询的场景。\n2.有序数组有序数组在等值查询和范围查询场景中的性能就都非常优秀。因为每个数组都可以保证递增，所以可以使用二分法就可以快速得到，这个时间复杂度是 O(log(N))。\n如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。所以，有序数组索引只适用于静态存储引擎\n3.二叉搜索树\n\n\n\n\n\n\n\n\n二叉搜索树，它或者是一棵空树，或者是具有下列性质的二叉树： 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 它的左、右子树也分别为二叉搜索树。\n\n这个树的查询时间复杂度当然是O(log(N))，当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。\n\n\n\n\n\n\n提示\n树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。\n\n\n以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。\nN 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。\nInnoDB 的索引模型在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。\n每一个索引在 InnoDB 里面对应一棵 B+ 树。\n假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。\n这个表的建表语句是：\nmysql&gt; create table T(\nid int primary key, \nk int not null, \nname varchar(16),\nindex (k))engine&#x3D;InnoDB;\n\n表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下。\n\n\n\n\n从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。\n\n主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。\n\n非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。\n\n\n基于主键索引和普通索引的查询有什么区别？\n\n如果语句是 select * from T where ID&#x3D;500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；\n如果语句是 select * from T where k&#x3D;5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。\n\n也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。\n索引维护插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。\n也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。\n而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。\n最左前缀原则B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。\n如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是”where name like ‘张 %’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。\n可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。\n那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。\n\n\n\n\n\n\n提示\n这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。\n\n\n索引下推我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：\nmysql&gt; select * from tuser where name like &#39;张 %&#39; and age&#x3D;10 and ismale&#x3D;1;\n\n你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。\n\n在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。\n\n而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。\n\n\n普通索引与唯一索引\n\n\n\n\n\n\n\n\n1、普通索引\n　　普通索引（由关键字KEY或INDEX定义的索引）的唯一任务是加快对数据的访问速度。因此，应该只为那些最经常出现在查询条件（WHEREcolumn&#x3D;）或排序条件（ORDERBYcolumn）中的数据列创建索引。只要有可能，就应该选择一个数据最整齐、最紧凑的数据列（如一个整数类型的数据列）来创建索引。\n2、唯一索引\n　　普通索引允许被索引的数据列包含重复的值。比如说，因为人有可能同名，所以同一个姓名在同一个“员工个人资料”数据表里可能出现两次或更多次。\nchange buffer当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。\n需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。\n将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。\n显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。\n:::deatils 什么条件下可以使用 change buffer \n对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k&#x3D;4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。\n因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。\nchange buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。\n:::\n优化器逻辑\n\n\n\n\n\n\n\n\n优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。\n扫描行数是怎么判断的？\nMySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。\n这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。\nMySQL 是怎样得到索引的基数的呢？\nMySQL 采样统计的方法。\n因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。\n采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。\n在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：\n\n设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。\n设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。\n\n索引选择异常和处理\n采用 force index 强行选择一个索引。\n\n修改语句，引导 MySQL 使用我们期望的索引。\n\n在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。\n\n\n前缀索引与覆盖索引\n\n\n\n\n\n\n\n\n使用前缀索引就用不上覆盖索引对查询性能的优化了\n但是使用前缀索引通常效果不错，如何提高前缀索引的区分度：\n\n第一种方式是使用倒序存储。由于身份证号的最后 6 位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了足够的区分度。\n\n第二种方式是使用 hash 字段。然后每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。\n\n\n这两种方法的异同点：\n\n\n\n\n\n\n相同点\n\n它们的相同点是，都不支持范围查询。\n\n倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在 [ID_X, ID_Y] 的所有市民了。同样地，hash 字段的方式也只能支持等值查询。\n\n\n\n\n\n\n\n\n不同点\n\n从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。\n\n在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。\n\n从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。\n\n\n\n\n字符串索引小结\n直接创建完整索引，这样可能比较占用空间；\n创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\n倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；\n创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。\n\n为什么二级索引的非叶子节点也存主键值假设建了二级索引，那么非叶子节点上的每一行记录，会存所有索引列的值+主键以及页号，但是为什么要存主键值呢？\n假设现在对“姓名”列建了索引，有相当多的人都叫张三，第一个叶子节点所有姓名都是张三，第二个叶子节点的最小姓名，也是张三，也就是说，第一个、第二个叶子节点的最小索引列值，都是张三。\n假设有一个非叶子节点，其中有两行记录，分别指向第一、第二个叶子节点，现在又插入一行姓名为张三的记录，更新索引的时候，这一行记录是要插到第一个、还是第二个叶子节点呢？无法判断。\n因此，需要保证B+树的同一层非叶子节点，除了页号以外，其他信息唯一，因此二级索引的非叶子节点，都会存索引列值+主键+页号，联合索引同理。\n因此，假如建了c1列的二级索引，实际上跟建(c1, id)的联合索引是一样的，假如建了(c1, c2)的联合索引，跟建(c1, c2, id)的联合索引是一样的。\n即使对某个UNIQUE列建了索引，非叶子节点的记录还是会存主键值，一是UNIQUE属性的列可能有多个NULL值，二是因为MVCC。\n","slug":"事务隔离","date":"2022-08-31T12:22:15.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"},{"id":"77b268d8a20b2f9b34be681cdfe52894","title":"MySQL框架&日志系统","content":"\n\n\n\n\n\n\n\n\n之前在字节青训营因为大作业的相关内容也接触过一些数据库方向的知识，但一直苦于没有系统性的学习和整理，所以这系列文章来总结和记录一些，个人觉得比较重要的内容，以便以后复习使用。主要参考文章是极客时间的MySQL45讲：MySQL 实战 45 讲 \nMySQL框架\n\n\n\n连接器\n\n\n\n\n\n\n\n\n连接器负责跟客户端建立链接、获取权限、维持和管理链接。常见的连接命令为：\n&gt;mysql -h$ip -P$port -u$user -p\n连接器在完成连接操作之后会进入Sleep状态表示空闲连接，而wait_timeout参数可以控制连接器自动断开的时间，一般默认为8小时。\n\n解决占用内存过多\n\n定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。\n如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n\n\n\n查询缓存\n\n\n\n\n\n\n\n\nMySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。\n查询缓存往往弊大于利，因为查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。\n分析器\n\n\n\n\n\n\n\n\n分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。\nMySQL 从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。\n做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。\n优化器\n\n\n\n\n\n\n\n\n优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。\n执行器\n\n\n\n\n\n\n\n\nMySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。\n执行器的业务逻辑一般为：\n\n验证权限\n调用引擎接口执行逻辑\n重复逻辑知道表的最后一行\n返回满足条件的的行记录作为结果返回给客户端\n\n\n查询日志\n你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。\n在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。\n\n\n日志系统mysql&gt; create table T(ID int primary key, c int);\n\n这是一条最常见的更新语句，例如我们现在要将ID&#x3D;2 这一行的值加 1，SQL 语句就会这么写：\nmysql&gt; update T set c&#x3D;c+1 where ID&#x3D;2;\n\n在上文中我们已经介绍了查询语句的流程,那么我们来整理一下更新语句的流程：\n\n连接连接器，验证权限\n分析器分析更新语句\n清空缓存结果\n优化器决定ID索引\n执行器执行更新\nredo log（重做日志）&amp; binlog（归档日志）\n\nredo log 重做日志\n\n\n\n\n\n\n\n\n在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了redo log来提升更新效率。\nMySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。下图为 redo log的示意图。\n\n\n\n\nnnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB。从头开始写，写到末尾就又回到开头循环写。\n\nredo log示意图详解\nwrite pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。\nwrite pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。\n\n\nflush机制由于这个机制的存在，当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n一下这些情况就会发生数据库的flush（刷脏页，也就是将脏页恢复为一直内容）:\n\nInnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。\n系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。\nMySQL 认为系统“空闲”的时候。\nMySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。\n\n分析一下分析一下上面四种场景对性能的影响。\n其中，第三种情况是属于 MySQL 空闲时的操作，这时系统没什么压力，而第四种场景是数据库本来就要关闭了。这两种情况下，你不会太关注“性能”问题。\n第一种是“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0。\n第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：\n\n第一种是，还没有使用的；\n第二种是，使用了并且是干净页；\n第三种是，使用了并且是脏页。\n\n\n\n\n\n\n\n提示\nInnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。\n而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。\n\n\n刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：\n\n一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；\n日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。\n\n所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。\nInnoDB 刷脏页的控制策略首先，你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。\n这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：\nfio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest \n\n其实，因为没能正确地设置 innodb_io_capacity 参数，而导致的性能问题也比比皆是。\nInnoDB 的刷盘速度就是要参考这两个因素：\n\n一个是脏页比例。参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字。InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。如图所示：\n\n\n\n\n\n\n\n一个是 redo log 写盘速度。\n\n\n\n\n\n\n\n\n注意\n一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。\n在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。\n找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机 IO。机械硬盘的随机 IOPS 一般只有几百，相同的逻辑操作减少随机 IO 就意味着系统性能的大幅度提升。\n而如果使用的是 SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。\n在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了。\n\n\ncrash-safe\n\n\n\n\n\n\n\n\n有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。\nbinlog（归档日志）\n\n\n\n\n\n\n\n\n实际上，在框架中我们不难发现MySQL有一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。如果说redo log是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。\n仅仅依靠binlog只能完成归档服务而不能实现crash-safe 能力，因此 MySQL为了实现存储引擎的crash-safe 能力带来了另一套日志系统也就是redo log。这两种日志主要有以下三点不同：\n\nredo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。\nredo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。\nredo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n此时我们就可以总结执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程：\n\n执行器先找引擎取 ID&#x3D;2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID&#x3D;2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。\n执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。\n引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。\n执行器生成这个操作的 binlog，并把 binlog 写入磁盘。\n执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。\n\n两阶段提交\n\n\n\n\n\n\n\n\n仍然用前面的 update 语句来做例子。假设当前 ID&#x3D;2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？\n\n先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。\n先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。\n\n虽然表面上看起来，发生宕机的概率不高，但是在需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。\nredo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。\nsync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。只有持久化的存储才能保证数据一场重启之后不会丢失。\n\n\n\n\n\n\nQuestion\n定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？\n\n\n\nAnswer\n该问题主要取决于binlog的规模，一天一备的binlog规模较小，那么恢复到误删时刻的时间和成本自然也就越短，而一周一备虽然恢复时间较长，但是如果发现问题时距离误操作已经过去了好几天，那么也仍然可以恢复，也就是后悔的容错时间更长。因此可以一天一备或者短周期备份后，再额外全库备份一次，以防止意外的发生也比较兼顾。\n\n\n异常重启\n\n\n\n如果在图中时刻 A 的地方，也就是写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。到这里，大家都可以理解。\n大家出现问题的地方，主要集中在时刻 B，也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？\nMySQL崩溃恢复时的判断规则。\n\n如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；\n如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：a. 如果是，则提交事务；b. 否则，回滚事务。\n\n这里，时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交。\n\n\n\n\n\n\nQuestion\nMySQL 怎么知道 binlog 是完整的?\n\n\n一个事务的 binlog 是有完整格式的：\n\nstatement 格式的 binlog，最后会有 COMMIT；\nrow 格式的 binlog，最后会有一个 XID event。\n\n另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的。\n\n\n\n\n\n\nQuestion\nredo log 和 binlog 是怎么关联起来的?\n\n\n它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：\n\n如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；\n如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。\n\n\n\n\n\n\n\nQuestion\n处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?\n\n\n在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。\n所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。\n\n\n\n\n\n\nQuestion\n不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？\n\n\nmysql 为什么不能用binlog来做数据恢复？_JackMa_的博客-CSDN博客_binlog为什么不支持崩溃恢复\n\n\n\n\n\n\nQuestion\n能不能反过来，只用 redo log，不要 binlog\n\n\n如果只从崩溃恢复的角度来讲是可以的。你可以把 binlog 关掉，这样就没有两阶段提交了，但系统依然是 crash-safe 的。\n但是，如果你了解一下业界各个公司的使用场景的话，就会发现在正式的生产库上，binlog 都是开着的。因为 binlog 有着 redo log 无法替代的功能。\n一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。\n一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。\n还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的 binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。\n总之，由于现在包括 MySQL 高可用在内的很多系统机制都依赖于 binlog，所以“鸠占鹊巢”redo log 还做不到。你看，发展生态是多么重要。\n\n\n\n\n\n\nQuestion\nredo log buffer 是什么？是先修改内存，还是先写 redo log 文件？\n\n\n在一个事务的更新过程中，日志是要写多次的。比如下面这个事务：\nbegin;\ninsert into t1 ...\ninsert into t2 ...\ncommit;\n\n这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。\n所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。\n但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。\n","slug":"MySQL框架","date":"2022-08-29T10:22:15.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"}]