[{"id":"e3447cde20e84ead44a473b80d153b14","title":"hexo+aurora+github+gitalk搭建属于自己的个人博客","content":"\n\n\n\n\n\n\n注意\n本文前八章来自于: 叁鄕浪子原作者写于2022年7月15日本人在基础上有所增加，并适当修改了章节顺序，配套的教学视频可在B站查看。\n\n\n1 node js的安装及环境配置\n\n\n\n\n\n\n\n\n直接访问Node.js的官方网站下载即可\n安装可以无脑下一步，注意安装路径就行，不会有问题，如果不放心的话可以参考原文章的安装过程截图，有详细步骤，由于本文篇幅较长，这里就不再转载了。\n测试成功方法如下：\n\n\n打开windows终端（按下win+R输入cmd）\n\nnode -v\n\nnpm -v\n\n如果安装成功会出现版本号码，如下图所示:\n1.2 配置环境变量以管理员身份-打开cmd，配置路径\nnpm config set prefix \"E:\\develop\\nodejs\\node_global\"\n\nnpm config set cache \"E:\\develop\\nodejs\\node_cache\"\n\n修改全局路径 node_global\n修改缓存路径 node_cache内路径需要根据自己实际情况来进行修改\n\n\n\n\n\n\n\n注意\n修改全局安装路径后，需要在系统环境变量Path中添加该路径，否则之后使用npm install –global xxx，xxx都报错找不到命令。\n\n\n找到电脑环境配置\n\nwin10 &amp; win11：右键此电脑-属性-高级系统设置-高级-环境变量\nwin11 还可以：点设置-系统-关于-高级系统设置-高级-环境变量\n\n2 安装git2.1 下载git访问Git 找到首页下方的Downloads\n下载对应系统（MAC、Windows、Linux&#x2F;Unix）安装包\n\n\n\n\n\n\n\n特别注意\n想省事可以直接无脑 Next(下一步)，带 New(新)的新功能不要选就是了,如果想了解详细的安装过程可以参考文章顶部的原文。\n\n\n3 hexo 下载npm install hexo-cli -g #安装hexo\n\n\n\n\n\n\n\n\n\n\n中间如果出现各种报错，可以先不用管，重新运行上述代码，直至成功因为网络原因导致的报错占大部分（因为墙的问题，也可以适当的使用科技）\n4 检查安装\nnode:\n\nnode -v\n\n\n\nnpm:\n\nnpm -v\n\n\ngit:\n\ngit --version\n\n\nhexo:\n\nhexo -v\n\n\n安装成功后截图：\n\n\n5 创建仓库及配置SSH连接5.1 创建github仓库5.1参考视频教程\n利用github仓库，存放静态网站资源，达到挂载网站的目的。\n需要注意的是作为网站访问的这个仓库，仓库名称一定是，拥有者名+github.io\n5.2 生成ssh keys5.2参考视频教程\n在博客文件夹根目录下，右键，调用git bash here功能\n先输入ssh查看是否已经安装ssh，git默认有安装，如下图所示就是安装过了。\n\n本地生成ssh keys,注意这里的邮箱地址是你github的注册邮箱地址\nssh-keygen -t rsa -C \"邮箱地址\"\n\n\n\n在本地电脑中找到.ssh\n\n\n一般默认都是，C:\\Users\\用户名.ssh\\id_rsa.pub\n找到秘钥的位置，并用记事本打开，复制其内容 (ctrl+a全选，ctrl+c复制，ctrl+v粘贴)\n打开github，头像箭头，下拉选项setting（设置）-SSH与GPG keys -new ssh keys（新建ssh秘钥）,把在本地生成的秘钥内容粘贴至此秘钥处，标题可以随便取。\n\n为了后面流程，在github里顺便设置person access tokens（个人访问令牌）\n(与ssh选项同一列，下面选择Developer setting log -Generate new token)\n\n下面勾选权限，建议全部勾选\n点击生成，生成的序列号\n\n\n\n\n\n\n\n特别注意\n注意保存\n要保存（复制&#x2F;截图）下来在存在本地，他只显示一次，如果忘记了，还需要重新生成一次。\n\n\n测试ssh是否绑定成功（在git里操作）\nssh -T git@github.com\n\n\n6 搭建本地博客创建一个放置博客文件夹的文件，在里面启用git Bash here，这里也可以用vscode打开终端管理。\n\n\n初始化hexo\n\nhexo init\n\n\n\n生成hexo本地页面\n\nhexo s\n\n\n\n复制粘贴该地址到浏览器中，即可访问本地搭建的博客 http://localhost=4000\n\nhexo cl #clean #清理编译文件\nhexo g #generate #编译项目\nhexo s #server #本地预览运行项目\n\n7 上传至本地博客至GitHub7.1 修改配置文件在创建博客文件夹的根目录下修改-config.yml文件\n\ndeploy:\n  type: git\n  repository: 你的github地址（就是你github.io那个仓库的地址）\n  branch: main\n\n7.2 安装hexo-deployer-git 自动部署发布工具npm install hexo-deployer-git --save\n\n7.3 编译文件生成页面hexo g\n\n7.4 本地文件上传到Githubhexo d\n\n\n\n\n\n\n\n提示\n在上传时，浏览器会跳出关于github的验证,要耐心等候\n\n\n\n输入用户名\n\n输入令牌\n\n\n(就是在github生成的那个，切记要保存)\n\n成功后可以直接访问http:&#x2F;&#x2F;你的用户名+.github.io访问\n\n8 安装Aurora主题\n\n\n\n\n\n\n\n\nAurora官方文档参考：https://aurora.tridiamond.tech/zh/guide\n8.1 配置npm install hexo-theme-aurora --save #进入hexo初始化目录用git执行\n\n\n因为主题是使用 NPM 或者 Yarn 安装的，而不是 clone 到 themes 文件夹的。\n所以我们需要自己创建一个配置文件。你只需要在 Hexo 博客的根目录下创建一个_config.aurora.yml 配置文件来配置主题\n此时打开配置文件发现是空的我们可以到node_modules下找到hexo-theme-aurora（.\\node_modules\\hexo-theme-aurora_config.yml），将改文件内容复制到根目录下的_config.aurora.yml。\n\n8.2 修改配置打开_comfig.yml\n由默认主题改为Aurora\n\n\n由于Aurora是vue3项目\n打开根目录下的_config.yml\n修改路由方式\n\n运行\nhexo clean &amp; hexo g &amp; hexo server\n\n\n8.3 上传并覆盖GitHub仓库hexo d\n\n打开仓库地址 主题配置成功\n\n9 参考教程\n\n\n\n\n\n\n\n\n【2021最新版】保姆级Hexo+github搭建个人博客\nHexo博客+Aurora主题安装与配置_神秘布偶猫\nhexo+aurora+github搭建 | 致彩之镜 (sxlz.me)\nAurora主题安装\nhexo+github搭建个人博客\n博客搭建日志\nAurora主题官方文档\n","slug":"hexo-aurora-github搭建属于自己的个人博客","date":"2022-09-27T09:48:24.000Z","categories_index":"技术教程","tags_index":"hexo,博客搭建","author_index":"依水何安"},{"id":"e7ec4f0245ca61bcdc5ddc21332c4d05","title":"MySQL高可用","content":"MySQL 主备的基本原理\n\n\n\n在状态 1 中，客户端的读写都直接访问节点 A，而节点 B 是 A 的备库，只是将 A 的更新都同步过来，到本地执行。这样可以保持节点 B 和 A 的数据是相同的。\n当需要切换的时候，就切成状态 2。这时候客户端读写访问的都是节点 B，而节点 A 是 B 的备库。\n在状态 1 中，虽然节点 B 没有被直接访问，但是我依然建议你把节点 B（也就是备库）设置成只读（readonly）模式。这样做，有以下几个考虑：\n\n有时候一些运营类的查询语句会被放到备库上去查，设置为只读可以防止误操作；\n防止切换逻辑有 bug，比如切换过程中出现双写，造成主备不一致；\n可以用 readonly 状态，来判断节点的角色。\n\n备库 B 跟主库 A 之间维持了一个长连接。主库 A 内部有一个线程，专门用于服务备库 B 的这个长连接。一个事务日志同步的完整过程是这样的：\n\n在备库 B 上通过 change master 命令，设置主库 A 的 IP、端口、用户名、密码，以及要从哪个位置开始请求 binlog，这个位置包含文件名和日志偏移量。\n在备库 B 上执行 start slave 命令，这时候备库会启动两个线程，就是图中的 io_thread 和 sql_thread。其中 io_thread 负责与主库建立连接。\n主库 A 校验完用户名、密码后，开始按照备库 B 传过来的位置，从本地读取 binlog，发给 B。\n备库 B 拿到 binlog 后，写到本地文件，称为中转日志（relay log）。\nsql_thread 读取中转日志，解析出日志里的命令，并执行。\n\nbinlog 的三种格式对比statement 格式\n\n\n\n\n第一行 SET @@SESSION.GTID_NEXT&#x3D;’ANONYMOUS’\n第二行是一个 BEGIN，跟第四行的 commit 对应，表示中间是一个事务；\n第三行就是真实执行的语句了。可以看到，在真实执行的 delete 命令之前，还有一个“use ‘test’”命令。这条命令不是我们主动执行的，而是 MySQL 根据当前要操作的表所在的数据库，自行添加的。这样做可以保证日志传到备库去执行的时候，不论当前的工作线程在哪个库里，都能够正确地更新到 test 库的表 t。use ‘test’命令之后的 delete 语句，就是我们输入的 SQL 原文了。可以看到，binlog“忠实”地记录了 SQL 命令，甚至连注释也一并记录了。\n最后一行是一个 COMMIT。你可以看到里面写着 xid&#x3D;61。是用来决定binlog是否完整的。\n\n\n\n\n\n\n\n\n注意\n可以看到，运行这条 delete 命令产生了一个 warning，原因是当前 binlog 设置的是 statement 格式，并且语句中有 limit，所以这个命令可能是 unsafe 的。\n为什么这么说呢？这是因为 delete 带 limit，很可能会出现主备数据不一致的情况。比如上面这个例子：\n\n如果 delete 语句使用的是索引 a，那么会根据索引 a 找到第一个满足条件的行，也就是说删除的是 a&#x3D;4 这一行；\n但如果使用的是索引 t_modified，那么删除的就是 t_modified&#x3D;’2018-11-09’也就是 a&#x3D;5 这一行。\n\n由于 statement 格式下，记录到 binlog 里的是语句原文，因此可能会出现这样一种情况：在主库执行这条 SQL 语句的时候，用的是索引 a；而在备库执行这条 SQL 语句的时候，却使用了索引 t_modified。因此，MySQL 认为这样写是有风险的。\n\n\nrow格式\n\n\n\n可以看到，与 statement 格式的 binlog 相比，前后的 BEGIN 和 COMMIT 是一样的。但是，row 格式的 binlog 里没有了 SQL 语句的原文，而是替换成了两个 event：Table_map 和 Delete_rows。\n\nTable_map event，用于说明接下来要操作的表是 test 库的表 t;\nDelete_rows event，用于定义删除的行为。\n\n\n\n\n\n从这个图中，我们可以看到以下几个信息：\n\nserver id 1，表示这个事务是在 server_id&#x3D;1 的这个库上执行的。\n每个 event 都有 CRC32 的值，这是因为我把参数 binlog_checksum 设置成了 CRC32。\nTable_map event 跟在图 5 中看到的相同，显示了接下来要打开的表，map 到数字 226。现在我们这条 SQL 语句只操作了一张表，如果要操作多张表呢？每个表都有一个对应的 Table_map event、都会 map 到一个单独的数字，用于区分对不同表的操作。\n我们在 mysqlbinlog 的命令中，使用了 -vv 参数是为了把内容都解析出来，所以从结果里面可以看到各个字段的值（比如，@1&#x3D;4、 @2&#x3D;4 这些值）。\nbinlog_row_image 的默认配置是 FULL，因此 Delete_event 里面，包含了删掉的行的所有字段的值。如果把 binlog_row_image 设置为 MINIMAL，则只会记录必要的信息，在这个例子里，就是只会记录 id&#x3D;4 这个信息。\n最后的 Xid event，用于表示事务被正确地提交了。\n\n你可以看到，当 binlog_format 使用 row 格式的时候，binlog 里面记录了真实删除行的主键 id，这样 binlog 传到备库去的时候，就肯定会删除 id&#x3D;4 的行，不会有主备删除不同行的问题。\nmixed格式为什么会有 mixed 这种 binlog 格式的存在场景？推论过程是这样的：\n\n因为有些 statement 格式的 binlog 可能会导致主备不一致，所以要使用 row 格式。\n但 row 格式的缺点是，很占空间。比如你用一个 delete 语句删掉 10 万行数据，用 statement 的话就是一个 SQL 语句被记录到 binlog 中，占用几十个字节的空间。但如果用 row 格式的 binlog，就要把这 10 万条记录都写到 binlog 中。这样做，不仅会占用更大的空间，同时写 binlog 也要耗费 IO 资源，影响执行速度。\n所以，MySQL 就取了个折中方案，也就是有了 mixed 格式的 binlog。mixed 格式的意思是，MySQL 自己会判断这条 SQL 语句是否可能引起主备不一致，如果有可能，就用 row 格式，否则就用 statement 格式。\n\n\n\n\n\n\n\n\n\n\n也就是说，mixed 格式可以利用 statment 格式的优点，同时又避免了数据不一致的风险。\n循环复制问题双 M 结构还有一个问题需要解决。\n业务逻辑在节点 A 上更新了一条语句，然后再把生成的 binlog 发给节点 B，节点 B 执行完这条更新语句后也会生成 binlog。（我建议你把参数 log_slave_updates 设置为 on，表示备库执行 relay log 后生成 binlog）。\n那么，如果节点 A 同时是节点 B 的备库，相当于又把节点 B 新生成的 binlog 拿过来执行了一次，然后节点 A 和 B 间，会不断地循环执行这个更新语句，也就是循环复制了。这个要怎么解决呢？\n从上面的图 6 中可以看到，MySQL 在 binlog 中记录了这个命令第一次执行时所在实例的 server id。因此，我们可以用下面的逻辑，来解决两个节点间的循环复制的问题：\n\n规定两个库的 server id 必须不同，如果相同，则它们之间不能设定为主备关系；\n一个备库接到 binlog 并在重放的过程中，生成与原 binlog 的 server id 相同的新的 binlog；\n每个库在收到从自己的主库发过来的日志后，先判断 server id，如果跟自己的相同，表示这个日志是自己生成的，就直接丢弃这个日志。\n\n按照这个逻辑，如果我们设置了双 M 结构，日志的执行流就会变成这样：\n\n从节点 A 更新的事务，binlog 里面记的都是 A 的 server id；\n传到节点 B 执行一次以后，节点 B 生成的 binlog 的 server id 也是 A 的 server id；\n再传回给节点 A，A 判断到这个 server id 与自己的相同，就不会再处理这个日志。所以，死循环在这里就断掉了。\n\nMySQL高可用主备延迟主备切换可能是一个主动运维动作，比如软件升级、主库所在机器按计划下线等，也可能是被动操作，比如主库所在机器掉电。\n接下来，我们先一起看看主动切换的场景。\n在介绍主动切换流程的详细步骤之前，我要先跟你说明一个概念，即“同步延迟”。与数据同步有关的时间点主要包括以下三个：\n\n主库 A 执行完成一个事务，写入 binlog，我们把这个时刻记为 T1;\n之后传给备库 B，我们把备库 B 接收完这个 binlog 的时刻记为 T2;\n备库 B 执行完成这个事务，我们把这个时刻记为 T3。\n\n所谓主备延迟，就是同一个事务，在备库执行完成的时间和主库执行完成的时间之间的差值，也就是 T3-T1。\n你可以在备库上执行 show slave status 命令，它的返回结果里面会显示 seconds_behind_master，用于表示当前备库延迟了多少秒。\nseconds_behind_master 的计算方法是这样的：\n\n每个事务的 binlog 里面都有一个时间字段，用于记录主库上写入的时间；\n备库取出当前正在执行的事务的时间字段的值，计算它与当前系统时间的差值，得到 seconds_behind_master。\n\n可以看到，其实 seconds_behind_master 这个参数计算的就是 T3-T1。所以，我们可以用 seconds_behind_master 来作为主备延迟的值，这个值的时间精度是秒。\n\n\n\n\n\n\n\n\n\n主备延迟的来源\n首先，有些部署条件下，备库所在机器的性能要比主库所在的机器性能差。\n一般情况下，有人这么部署时的想法是，反正备库没有请求，所以可以用差一点儿的机器。或者，他们会把 20 个主库放在 4 台机器上，而把备库集中在一台机器上。\n第二种常见的可能了，即备库的压力大。\n般的想法是，主库既然提供了写能力，那么备库可以提供一些读能力。或者一些运营后台需要的分析语句，不能影响正常业务，所以只能在备库上跑。\n这种情况，我们一般可以这么处理：\n\n一主多从。除了备库外，可以多接几个从库，让这些从库来分担读的压力。\n通过 binlog 输出到外部系统，比如 Hadoop 这类系统，让外部系统提供统计类查询的能力。\n\n这就是第三种可能了，即大事务。\n可靠性优先策略在双 M 结构下，从状态 1 到状态 2 切换的详细过程是这样的：\n\n判断备库 B 现在的 seconds_behind_master，如果小于某个值（比如 5 秒）继续下一步，否则持续重试这一步；\n把主库 A 改成只读状态，即把 readonly 设置为 true；\n判断备库 B 的 seconds_behind_master 的值，直到这个值变成 0 为止；\n把备库 B 改成可读写状态，也就是把 readonly 设置为 false；\n把业务请求切到备库 B。\n\n可以看到，这个切换流程中是有不可用时间的。因为在步骤 2 之后，主库 A 和备库 B 都处于 readonly 状态，也就是说这时系统处于不可写状态，直到步骤 5 完成后才能恢复。\n在这个不可用状态中，比较耗费时间的是步骤 3，可能需要耗费好几秒的时间。这也是为什么需要在步骤 1 先做判断，确保 seconds_behind_master 的值足够小。\n试想如果一开始主备延迟就长达 30 分钟，而不先做判断直接切换的话，系统的不可用时间就会长达 30 分钟，这种情况一般业务都是不可接受的。\n按照可靠性优先的思路，异常切换会是什么效果？\n假设，主库 A 和备库 B 间的主备延迟是 30 分钟，这时候主库 A 掉电了，HA 系统要切换 B 作为主库。我们在主动切换的时候，可以等到主备延迟小于 5 秒的时候再启动切换，但这时候已经别无选择了。\n采用可靠性优先策略的话，你就必须得等到备库 B 的 seconds_behind_master&#x3D;0 之后，才能切换。但现在的情况比刚刚更严重，并不是系统只读、不可写的问题了，而是系统处于完全不可用的状态。因为，主库 A 掉电后，我们的连接还没有切到备库 B。\n当然，系统的不可用时间，是由这个数据可靠性优先的策略决定的。你也可以选择可用性优先的策略，来把这个不可用时间几乎降为 0。\n可用性优先策略如果我强行把步骤 4、5 调整到最开始执行，也就是说不等主备数据同步，直接把连接切到备库 B，并且让备库 B 可以读写，那么系统几乎就没有不可用时间了。\n我们把这个切换流程，暂时称作可用性优先流程。这个切换流程的代价，就是可能出现数据不一致的情况。\n\n\n\n\n\n\n\n\n\nMySQL 高可用系统的可用性，是依赖于主备延迟的。延迟的时间越小，在主库故障的时候，服务恢复需要的时间就越短，可用性就越高。\n备库并行复制\n\n\n\n\n\n\n\n\n如果备库执行日志的速度持续低于主库生成日志的速度，那这个延迟就有可能成了小时级别。而且对于一个压力持续比较高的主库来说，备库很可能永远都追不上主库的节奏。\n\n\n\n\n\n\n\n注意\n在主库上，影响并发度的原因就是各种锁了。由于 InnoDB 引擎支持行锁，除了所有并发事务都在更新同一行（热点行）这种极端场景外，它对业务并发度的支持还是很友好的。所以，你在性能测试的时候会发现，并发压测线程 32 就比单线程时，总体吞吐量高。\n而日志在备库上的执行，就是图中备库上 sql_thread 更新数据 (DATA) 的逻辑。如果是用单线程的话，就会导致备库应用日志不够快，造成主备延迟。\n\n\n\n\n\n\n在官方的 5.6 版本之前，MySQL 只支持单线程复制，由此在主库并发高、TPS 高时就会出现严重的主备延迟问题。\n从单线程复制到最新版本的多线程复制，中间的演化经历了好几个版本。其实说到底，所有的多线程复制机制，都是要把上图中只有一个线程的 sql_thread，拆成多个线程，也就是都符合下面的这个模型：\n\n\n\n\ncoordinator 就是原来的 sql_thread, 不过现在它不再直接更新数据了，只负责读取中转日志和分发事务。真正更新日志的，变成了 worker 线程。而 work 线程的个数，就是由参数 slave_parallel_workers 决定的。\n\n\n\n\n\n\n提示\n\n事务能不能按照轮询的方式分发给各个 worker，也就是第一个事务分给 worker_1，第二个事务发给 worker_2 呢？\n\n其实是不行的。因为，事务被分发给 worker 以后，不同的 worker 就独立执行了。但是，由于 CPU 的调度策略，很可能第二个事务最终比第一个事务先执行。而如果这时候刚好这两个事务更新的是同一行，也就意味着，同一行上的两个事务，在主库和备库上的执行顺序相反，会导致主备不一致的问题。\n\n同一个事务的多个更新语句，能不能分给不同的 worker 来执行呢？\n\n答案是，也不行。举个例子，一个事务更新了表 t1 和表 t2 中的各一行，如果这两条更新语句被分到不同 worker 的话，虽然最终的结果是主备一致的，但如果表 t1 执行完成的瞬间，备库上有一个查询，就会看到这个事务“更新了一半的结果”，破坏了事务逻辑的隔离性。\n\n\n所以，coordinator 在分发的时候，需要满足以下这两个基本要求：\n\n不能造成更新覆盖。这就要求更新同一行的两个事务，必须被分发到同一个 worker 中。\n同一个事务不能被拆开，必须放到同一个 worker 中。\n\n并行复制策略按表分发策略\n\n\n\n\n\n\n\n\n按表分发事务的基本思路是，如果两个事务更新不同的表，它们就可以并行。因为数据是存储在表里的，所以按表分发，可以保证两个 worker 不会更新同一行。\n\n\n\n\n可以看到，每个 worker 线程对应一个 hash 表，用于保存当前正在这个 worker 的“执行队列”里的事务所涉及的表。hash 表的 key 是“库名. 表名”，value 是一个数字，表示队列中有多少个事务修改这个表。\n在有事务分配给 worker 时，事务里面涉及的表会被加到对应的 hash 表中。worker 执行完成后，这个表会被从 hash 表中去掉。hash_table_1 表示，现在 worker_1 的“待执行事务队列”里，有 4 个事务涉及到 db1.t1 表，有 1 个事务涉及到 db2.t2 表；hash_table_2 表示，现在 worker_2 中有一个事务会更新到表 t3 的数据。\n\n\n\n\n\n\n提示\n假设在图中的情况下，coordinator 从中转日志中读入一个新事务 T，这个事务修改的行涉及到表 t1 和 t3。\n现在我们用事务 T 的分配流程，来看一下分配规则。\n\n由于事务 T 中涉及修改表 t1，而 worker_1 队列中有事务在修改表 t1，事务 T 和队列中的某个事务要修改同一个表的数据，这种情况我们说事务 T 和 worker_1 是冲突的。\n按照这个逻辑，顺序判断事务 T 和每个 worker 队列的冲突关系，会发现事务 T 跟 worker_2 也冲突。\n事务 T 跟多于一个 worker 冲突，coordinator 线程就进入等待。\n每个 worker 继续执行，同时修改 hash_table。假设 hash_table_2 里面涉及到修改表 t3 的事务先执行完成，就会从 hash_table_2 中把 db1.t3 这一项去掉。\n这样 coordinator 会发现跟事务 T 冲突的 worker 只有 worker_1 了，因此就把它分配给 worker_1。\ncoordinator 继续读下一个中转日志，继续分配事务。\n\n\n\n\n\n\n\n\n\n提示\n也就是说，每个事务在分发的时候，跟所有 worker 的冲突关系包括以下三种情况：\n\n如果跟所有 worker 都不冲突，coordinator 线程就会把这个事务分配给最空闲的 woker;\n如果跟多于一个 worker 冲突，coordinator 线程就进入等待状态，直到和这个事务存在冲突关系的 worker 只剩下 1 个；\n如果只跟一个 worker 冲突，coordinator 线程就会把这个事务分配给这个存在冲突关系的 worker。\n\n\n\n按行分发策略\n\n\n\n\n\n\n\n\n要解决热点表的并行复制问题，就需要一个按行并行复制的方案。按行复制的核心思路是：如果两个事务没有更新相同的行，它们在备库上可以并行执行。显然，这个模式要求 binlog 格式必须是 row。\n这时候，我们判断一个事务 T 和 worker 是否冲突，用的就规则就不是“修改同一个表”，而是“修改同一行”。按行复制和按表复制的数据结构差不多，也是为每个 worker，分配一个 hash 表。只是要实现按行分发，这时候的 key，就必须是“库名 + 表名 + 唯一键的值”。\n\n\n\n\n\n\n\n注意\n基于行的策略，事务 hash 表中还需要考虑唯一键，即 key 应该是“库名 + 表名 + 索引 a 的名字 +a 的值”。\n因此，coordinator 在解析这个语句的 binlog 的时候，这个事务的 hash 表就有三个项:\n\nkey&#x3D;hash_func(db1+t1+“PRIMARY”+2), value&#x3D;2; 这里 value&#x3D;2 是因为修改前后的行 id 值不变，出现了两次。\nkey&#x3D;hash_func(db1+t1+“a”+2), value&#x3D;1，表示会影响到这个表 a&#x3D;2 的行。\nkey&#x3D;hash_func(db1+t1+“a”+1), value&#x3D;1，表示会影响到这个表 a&#x3D;1 的行。\n\n\n\n可见，相比于按表并行分发策略，按行并行策略在决定线程分发的时候，需要消耗更多的计算资源。你可能也发现了，这两个方案其实都有一些约束条件：\n\n要能够从 binlog 里面解析出表名、主键值和唯一索引的值。也就是说，主库的 binlog 格式必须是 row；\n表必须有主键；\n不能有外键。表上如果有外键，级联更新的行不会记录在 binlog 中，这样冲突检测就不准确。\n\n对比按表分发和按行分发这两个方案的话，按行分发策略的并行度更高。不过，如果是要操作很多行的大事务的话，按行分发的策略有两个问题：\n\n耗费内存。比如一个语句要删除 100 万行数据，这时候 hash 表就要记录 100 万个项。\n耗费 CPU。解析 binlog，然后计算 hash 值，对于大事务，这个成本还是很高的。\n\n所以，在实现这个策略的时候会设置一个阈值，单个事务如果超过设置的行数阈值（比如，如果单个事务更新的行数超过 10 万行），就暂时退化为单线程模式，退化过程的逻辑大概是这样的：\n\ncoordinator 暂时先 hold 住这个事务；\n等待所有 worker 都执行完成，变成空队列；\ncoordinator 直接执行这个事务；\n恢复并行模式。\n\nMySQL 5.6 版本的并行复制策略官方 MySQL5.6 版本，支持了并行复制，只是支持的粒度是按库并行。理解了上面介绍的按表分发策略和按行分发策略，你就理解了，用于决定分发策略的 hash 表里，key 就是数据库名。\n这个策略的并行效果，取决于压力模型。如果在主库上有多个 DB，并且各个 DB 的压力均衡，使用这个策略的效果会很好。\n相比于按表和按行分发，这个策略有两个优势：\n\n构造 hash 值的时候很快，只需要库名；而且一个实例上 DB 数也不会很多，不会出现需要构造 100 万个项这种情况。\n不要求 binlog 的格式。因为 statement 格式的 binlog 也可以很容易拿到库名。\n\n但是，如果你的主库上的表都放在同一个 DB 里面，这个策略就没有效果了；或者如果不同 DB 的热点不同，比如一个是业务逻辑库，一个是系统配置库，那也起不到并行的效果。\n理论上你可以创建不同的 DB，把相同热度的表均匀分到这些不同的 DB 中，强行使用这个策略。不过据我所知，由于需要特地移动数据，这个策略用得并不多。\nMariaDB 的并行复制策略redo log 组提交 (group commit) 优化， 而 MariaDB 的并行复制策略利用的就是这个特性：\n\n能够在同一组里提交的事务，一定不会修改同一行；\n主库上可以并行执行的事务，备库上也一定是可以并行执行的。\n\n在实现上，MariaDB 是这么做的：\n\n在一组里面一起提交的事务，有一个相同的 commit_id，下一组就是 commit_id+1；\ncommit_id 直接写到 binlog 里面；\n传到备库应用的时候，相同 commit_id 的事务分发到多个 worker 执行；\n这一组全部执行完成后，coordinator 再去取下一批。\n\n当时，这个策略出来的时候是相当惊艳的。因为，之前业界的思路都是在“分析 binlog，并拆分到 worker”上。而 MariaDB 的这个策略，目标是“模拟主库的并行模式”。\n但是，这个策略有一个问题，它并没有实现“真正的模拟主库并发度”这个目标。在主库上，一组事务在 commit 的时候，下一组事务是同时处于“执行中”状态的。\n可以看到，在备库上执行的时候，要等第一组事务完全执行完成后，第二组事务才能开始执行，这样系统的吞吐量就不够。\n另外，这个方案很容易被大事务拖后腿。假设 trx2 是一个超大事务，那么在备库应用的时候，trx1 和 trx3 执行完成后，就只能等 trx2 完全执行完成，下一组才能开始执行。这段时间，只有一个 worker 线程在工作，是对资源的浪费。\n不过即使如此，这个策略仍然是一个很漂亮的创新。因为，它对原系统的改造非常少，实现也很优雅。\nMySQL 5.7 的并行复制策略\n\n\n\n\n\n\n\n\n在 MariaDB 并行复制实现之后，官方的 MySQL5.7 版本也提供了类似的功能，由参数 slave-parallel-type 来控制并行复制策略：\n\n配置为 DATABASE，表示使用 MySQL 5.6 版本的按库并行策略；\n配置为 LOGICAL_CLOCK，表示的就是类似 MariaDB 的策略。不过，MySQL 5.7 这个策略，针对并行度做了优化。\n\n其实，不用等到 commit 阶段，只要能够到达 redo log prepare 阶段，就表示事务已经通过锁冲突的检验了。\n因此，MySQL 5.7 并行复制策略的思想是：\n\n同时处于 prepare 状态的事务，在备库执行时是可以并行的；\n处于 prepare 状态的事务，与处于 commit 状态的事务之间，在备库执行时也是可以并行的。\n\nbinlog 的组提交的时候，介绍过两个参数：\n\nbinlog_group_commit_sync_delay 参数，表示延迟多少微秒后才调用 fsync;\nbinlog_group_commit_sync_no_delay_count 参数，表示累积多少次以后才调用 fsync。\n\n这两个参数是用于故意拉长 binlog 从 write 到 fsync 的时间，以此减少 binlog 的写盘次数。在 MySQL 5.7 的并行复制策略里，它们可以用来制造更多的“同时处于 prepare 阶段的事务”。这样就增加了备库复制的并行度。\n也就是说，这两个参数，既可以“故意”让主库提交得慢些，又可以让备库执行得快些。在 MySQL 5.7 处理备库延迟的时候，可以考虑调整这两个参数值，来达到提升备库复制并发度的目的。\nMySQL 5.7.22 的并行复制策略在 2018 年 4 月份发布的 MySQL 5.7.22 版本里，MySQL 增加了一个新的并行复制策略，基于 WRITESET 的并行复制。\n相应地，新增了一个参数 binlog-transaction-dependency-tracking，用来控制是否启用这个新策略。这个参数的可选值有以下三种。\n\nCOMMIT_ORDER，表示的就是前面介绍的，根据同时进入 prepare 和 commit 来判断是否可以并行的策略。\nWRITESET，表示的是对于事务涉及更新的每一行，计算出这一行的 hash 值，组成集合 writeset。如果两个事务没有操作相同的行，也就是说它们的 writeset 没有交集，就可以并行。\nWRITESET_SESSION，是在 WRITESET 的基础上多了一个约束，即在主库上同一个线程先后执行的两个事务，在备库执行的时候，要保证相同的先后顺序。\n\n当然为了唯一标识，这个 hash 值是通过“库名 + 表名 + 索引名 + 值”计算出来的。如果一个表上除了有主键索引外，还有其他唯一索引，那么对于每个唯一索引，insert 语句对应的 writeset 就要多增加一个 hash 值。\n一主多从切换\n\n\n\n\n\n\n\n图中，虚线箭头表示的是主备关系，也就是 A 和 A’互为主备， 从库 B、C、D 指向的是主库 A。一主多从的设置，一般用于读写分离，主库负责所有的写入和一部分读，其他的读请求则由从库分担。\n相比于一主一备的切换流程，一主多从结构在切换完成后，A’会成为新的主库，从库 B、C、D 也要改接到 A’。正是由于多了从库 B、C、D 重新指向的这个过程，所以主备切换的复杂性也相应增加了。\n基于位点的主备切换这里，我们需要先来回顾一个知识点。\n当我们把节点 B 设置成节点 A’的从库的时候，需要执行一条 change master 命令：\nCHANGE MASTER TO \nMASTER_HOST&#x3D;$host_name \nMASTER_PORT&#x3D;$port \nMASTER_USER&#x3D;$user_name \nMASTER_PASSWORD&#x3D;$password \nMASTER_LOG_FILE&#x3D;$master_log_name \nMASTER_LOG_POS&#x3D;$master_log_pos  \n\n这条命令有这么 6 个参数：\n\nMASTER_HOST、MASTER_PORT、MASTER_USER 和 MASTER_PASSWORD 四个参数，分别代表了主库 A’的 IP、端口、用户名和密码。\n最后两个参数 MASTER_LOG_FILE 和 MASTER_LOG_POS 表示，要从主库的 master_log_name 文件的 master_log_pos 这个位置的日志继续同步。而这个位置就是我们所说的同步位点，也就是主库对应的文件名和日志偏移量。\n\n那么，这里就有一个问题了，节点 B 要设置成 A’的从库，就要执行 change master 命令，就不可避免地要设置位点的这两个参数，但是这两个参数到底应该怎么设置呢？\n原来节点 B 是 A 的从库，本地记录的也是 A 的位点。但是相同的日志，A 的位点和 A’的位点是不同的。因此，从库 B 要切换的时候，就需要先经过“找同步位点”这个逻辑。\n考虑到切换过程中不能丢数据，所以我们找位点的时候，总是要找一个“稍微往前”的，然后再通过判断跳过那些在从库 B 上已经执行过的事务。\n一种取同步位点的方法是这样的：\n\n等待新主库 A’把中转日志（relay log）全部同步完成；\n在 A’上执行 show master status 命令，得到当前 A’上最新的 File 和 Position；\n取原主库 A 故障的时刻 T；\n用 mysqlbinlog 工具解析 A’的 File，得到 T 时刻的位点。\n\n\n\n\n\n\n\n提示\n通常情况下，我们在切换任务的时候，要先主动跳过这些错误，有两种常用的方法。\n\n一种做法是，主动跳过一个事务。跳过命令的写法是：\n\nset global sql_slave_skip_counter&#x3D;1;\nstart slave;\n\n因为切换过程中，可能会不止重复执行一个事务，所以我们需要在从库 B 刚开始接到新主库 A’时，持续观察，每次碰到这些错误就停下来，执行一次跳过命令，直到不再出现停下来的情况，以此来跳过可能涉及的所有事务。\n\n另外一种方式是，通过设置 slave_skip_errors 参数，直接设置跳过指定的错误。\n\n在执行主备切换时，有这么两类错误，是经常会遇到的：\n\n1062 错误是插入数据时唯一键冲突；\n1032 错误是删除数据时找不到行。\n\n因此，我们可以把 slave_skip_errors 设置为 “1032,1062”，这样中间碰到这两个错误时就直接跳过。\n这里需要注意的是，这种直接跳过指定错误的方法，针对的是主备切换时，由于找不到精确的同步位点，所以只能采用这种方法来创建从库和新主库的主备关系。\n这个背景是，我们很清楚在主备切换过程中，直接跳过 1032 和 1062 这两类错误是无损的，所以才可以这么设置 slave_skip_errors 参数。等到主备间的同步关系建立完成，并稳定执行一段时间之后，我们还需要把这个参数设置为空，以免之后真的出现了主从数据不一致，也跳过了。\n\n\nGTID\n\n\n\n\n\n\n\n\n通过 sql_slave_skip_counter 跳过事务和通过 slave_skip_errors 忽略错误的方法，虽然都最终可以建立从库 B 和新主库 A’的主备关系，但这两种操作都很复杂，而且容易出错。所以，MySQL 5.6 版本引入了 GTID，彻底解决了这个困难。\nGTID 的全称是 Global Transaction Identifier，也就是全局事务 ID，是一个事务在提交的时候生成的，是这个事务的唯一标识。它由两部分组成，格式是：\nGTID&#x3D;server_uuid:gno\n\n其中：\n\nserver_uuid 是一个实例第一次启动时自动生成的，是一个全局唯一的值；\ngno 是一个整数，初始值是 1，每次提交事务的时候分配给这个事务，并加 1。\n\n在 GTID 模式下，每个事务都会跟一个 GTID 一一对应。这个 GTID 有两种生成方式，而使用哪种方式取决于 session 变量 gtid_next 的值。\n\n如果 gtid_next&#x3D;automatic，代表使用默认值。这时，MySQL 就会把 server_uuid:gno 分配给这个事务。a. 记录 binlog 的时候，先记录一行 SET @@SESSION.GTID_NEXT&#x3D;‘server_uuid:gno’;b. 把这个 GTID 加入本实例的 GTID 集合。\n如果 gtid_next 是一个指定的 GTID 的值，比如通过 set gtid_next&#x3D;’current_gtid’指定为 current_gtid，那么就有两种可能：a. 如果 current_gtid 已经存在于实例的 GTID 集合中，接下来执行的这个事务会直接被系统忽略；b. 如果 current_gtid 没有存在于实例的 GTID 集合中，就将这个 current_gtid 分配给接下来要执行的事务，也就是说系统不需要给这个事务生成新的 GTID，因此 gno 也不用加 1。\n\n\n\n\n\n\n\n\n注意\n注意，一个 current_gtid 只能给一个事务使用。这个事务提交后，如果要执行下一个事务，就要执行 set 命令，把 gtid_next 设置成另外一个 gtid 或者 automatic。\n\n\n基于 GTID 的主备切换我们在实例 B 上执行 start slave 命令，取 binlog 的逻辑是这样的：\n\n实例 B 指定主库 A’，基于主备协议建立连接。\n实例 B 把 set_b 发给主库 A’。\n实例 A’算出 set_a 与 set_b 的差集，也就是所有存在于 set_a，但是不存在于 set_b 的 GTID 的集合，判断 A’本地是否包含了这个差集需要的所有 binlog 事务。a. 如果不包含，表示 A’已经把实例 B 需要的 binlog 给删掉了，直接返回错误；b. 如果确认全部包含，A’从自己的 binlog 文件里面，找出第一个不在 set_b 的事务，发给 B；\n之后就从这个事务开始，往后读文件，按顺序取 binlog 发给 B 去执行。\n\n其实，这个逻辑里面包含了一个设计思想：在基于 GTID 的主备关系里，系统认为只要建立主备关系，就必须保证主库发给备库的日志是完整的。因此，如果实例 B 需要的日志已经不存在，A’就拒绝把日志发给 B。\nGTID 和在线 DDL\n\n\n\n\n\n\n\n\n如果是由于索引缺失引起的性能问题，我们可以通过在线加索引来解决。但是，考虑到要避免新增索引对主库性能造成的影响，我们可以先在备库加索引，然后再切换。\n假设，这两个互为主备关系的库还是实例 X 和实例 Y，且当前主库是 X，并且都打开了 GTID 模式。这时的主备切换流程可以变成下面这样：\n\n在实例 X 上执行 stop slave。\n在实例 Y 上执行 DDL 语句。注意，这里并不需要关闭 binlog。\n执行完成后，查出这个 DDL 语句对应的 GTID，并记为 server_uuid_of_Y:gno。\n\n读写分离架构接下来，就看一下客户端直连和带 proxy 的读写分离架构，各有哪些特点。\n\n客户端直连方案，因为少了一层 proxy 转发，所以查询性能稍微好一点儿，并且整体架构简单，排查问题更方便。但是这种方案，由于要了解后端部署细节，所以在出现主备切换、库迁移等操作的时候，客户端都会感知到，并且需要调整数据库连接信息。你可能会觉得这样客户端也太麻烦了，信息大量冗余，架构很丑。其实也未必，一般采用这样的架构，一定会伴随一个负责管理后端的组件，比如 Zookeeper，尽量让业务端只专注于业务逻辑开发。\n带 proxy 的架构，对客户端比较友好。客户端不需要关注后端细节，连接维护、后端信息维护等工作，都是由 proxy 完成的。但这样的话，对后端维护团队的要求会更高。而且，proxy 也需要有高可用架构。因此，带 proxy 架构的整体就相对比较复杂。\n\n由于主从可能存在延迟，客户端执行完一个更新事务后马上发起查询，如果查询选择的是从库的话，就有可能读到刚刚的事务更新之前的状态。\n这种“在从库上会读到系统的一个过期状态”的现象，在这篇文章里，我们暂且称之为“过期读”。\n前面我们说过了几种可能导致主备延迟的原因，以及对应的优化策略，但是主从延迟还是不能 100% 避免的。\n不论哪种结构，客户端都希望查询从库的数据结果，跟查主库的数据结果是一样的。\n这些方案包括：\n\n强制走主库方案；\nsleep 方案；\n判断主备无延迟方案；\n配合 semi-sync 方案；\n等主库位点方案；\n等 GTID 方案。\n\n强制走主库方案强制走主库方案其实就是，将查询请求做分类。通常情况下，我们可以将查询请求分为这么两类：\n\n对于必须要拿到最新结果的请求，强制将其发到主库上。比如，在一个交易平台上，卖家发布商品以后，马上要返回主页面，看商品是否发布成功。那么，这个请求需要拿到最新的结果，就必须走主库。\n对于可以读到旧数据的请求，才将其发到从库上。在这个交易平台上，买家来逛商铺页面，就算晚几秒看到最新发布的商品，也是可以接受的。那么，这类请求就可以走从库。\n\n你可能会说，这个方案是不是有点畏难和取巧的意思，但其实这个方案是用得最多的。\n当然，这个方案最大的问题在于，有时候你会碰到“所有查询都不能是过期读”的需求，比如一些金融类的业务。这样的话，你就要放弃读写分离，所有读写压力都在主库，等同于放弃了扩展性。\nSleep 方案主库更新后，读从库之前先 sleep 一下。具体的方案就是，类似于执行一条 select sleep(1) 命令。\n这个方案的假设是，大多数情况下主备延迟在 1 秒之内，做一个 sleep 可以有很大概率拿到最新的数据。\n这个方案给你的第一感觉，很可能是不靠谱儿，应该不会有人用吧？并且，你还可能会说，直接在发起查询时先执行一条 sleep 语句，用户体验很不友好啊。\n但，这个思路确实可以在一定程度上解决问题。为了看起来更靠谱儿，我们可以换一种方式。\n以卖家发布商品为例，商品发布后，用 Ajax（Asynchronous JavaScript + XML，异步 JavaScript 和 XML）直接把客户端输入的内容作为“新的商品”显示在页面上，而不是真正地去数据库做查询。\n这样，卖家就可以通过这个显示，来确认产品已经发布成功了。等到卖家再刷新页面，去查看商品的时候，其实已经过了一段时间，也就达到了 sleep 的目的，进而也就解决了过期读的问题。\n\n\n\n\n\n\n\n注意\n也就是说，这个 sleep 方案确实解决了类似场景下的过期读问题。但，从严格意义上来说，这个方案存在的问题就是不精确。这个不精确包含了两层意思：\n\n如果这个查询请求本来 0.5 秒就可以在从库上拿到正确结果，也会等 1 秒；\n如果延迟超过 1 秒，还是会出现过期读。\n\n\n\n判断主备无延迟方案要确保备库无延迟，通常有三种做法。\n\n第一种确保主备无延迟的方法是，每次从库执行查询请求前，先判断 seconds_behind_master 是否已经等于 0。如果还不等于 0 ，那就必须等到这个参数变为 0 才能执行查询请求。\n\nseconds_behind_master 的单位是秒，如果你觉得精度不够的话，还可以采用对比位点和 GTID 的方法来确保主备无延迟，也就是我们接下来要说的第二和第三种方法。\n第二种方法，对比位点确保主备无延迟：\n\nMaster_Log_File 和 Read_Master_Log_Pos，表示的是读到的主库的最新位点；\nRelay_Master_Log_File 和 Exec_Master_Log_Pos，表示的是备库执行的最新位点。\n\n如果 Master_Log_File 和 Relay_Master_Log_File、Read_Master_Log_Pos 和 Exec_Master_Log_Pos 这两组值完全相同，就表示接收到的日志已经同步完成。\n第三种方法，对比 GTID 集合确保主备无延迟：\n\nAuto_Position&#x3D;1 ，表示这对主备关系使用了 GTID 协议。\nRetrieved_Gtid_Set，是备库收到的所有日志的 GTID 集合；\nExecuted_Gtid_Set，是备库所有已经执行完成的 GTID 集合。\n\n如果这两个集合相同，也表示备库接收到的日志都已经同步完成。\n可见，对比位点和对比 GTID 这两种方法，都要比判断 seconds_behind_master 是否为 0 更准确。\n\n\n\n\n\n\n\n特别注意\n我们上面判断主备无延迟的逻辑，是“备库收到的日志都执行完成了”。但是，从 binlog 在主备之间状态的分析中，不难看出还有一部分日志，处于客户端已经收到提交确认，而备库还没收到日志的状态。\n\n\n配合 semi-sync\n要解决这个问题，就要引入半同步复制，也就是 semi-sync replication。\nsemi-sync 做了这样的设计：\n\n事务提交的时候，主库把 binlog 发给从库；\n从库收到 binlog 以后，发回给主库一个 ack，表示收到了；\n主库收到这个 ack 以后，才能给客户端返回“事务完成”的确认。\n\n也就是说，如果启用了 semi-sync，就表示所有给客户端发送过确认的事务，都确保了备库已经收到了这个日志。\n其实，判断同步位点的方案还有另外一个潜在的问题，即：如果在业务更新的高峰期，主库的位点或者 GTID 集合更新很快，那么上面的两个位点等值判断就会一直不成立，很可能出现从库上迟迟无法响应查询请求的情况。\n实际上，回到我们最初的业务逻辑里，当发起一个查询请求以后，我们要得到准确的结果，其实并不需要等到“主备完全同步”。\n\n\n\n\n备库 B 一直到状态 4 都和主库 A 存在延迟，如果用上面必须等到无延迟才能查询的方案，select 语句直到状态 4 都不能被执行。\n但是，其实客户端是在发完 trx1 更新后发起的 select 语句，我们只需要确保 trx1 已经执行完成就可以执行 select 语句了。也就是说，如果在状态 3 执行查询请求，得到的就是预期结果了。\n到这里，我们小结一下，semi-sync 配合判断主备无延迟的方案，存在两个问题：\n\n一主多从的时候，在某些从库执行查询请求会存在过期读的现象；\n在持续延迟的情况下，可能出现过度等待的问题。\n\n等主库位点方案要理解等主库位点方案，需要知道这样一条命令：\nselect master_pos_wait(file, pos[, timeout]);\n\n这条命令的逻辑如下：\n\n它是在从库执行的；\n参数 file 和 pos 指的是主库上的文件名和位置；\ntimeout 可选，设置为正整数 N 表示这个函数最多等待 N 秒。\n\n这个命令正常返回的结果是一个正整数 M，表示从命令开始执行，到应用完 file 和 pos 表示的 binlog 位置，执行了多少事务。\n当然，除了正常返回一个正整数 M 外，这条命令还会返回一些其他结果，包括：\n\n如果执行期间，备库同步线程发生异常，则返回 NULL；\n如果等待超过 N 秒，就返回 -1；\n如果刚开始执行的时候，就发现已经执行过这个位置了，则返回 0。\n\n对于上图中先执行 trx1，再执行一个查询请求的逻辑，要保证能够查到正确的数据，我们可以使用这个逻辑：\n\ntrx1 事务更新完成后，马上执行 show master status 得到当前主库执行到的 File 和 Position；\n选定一个从库执行查询语句；\n在从库上执行 select master_pos_wait(File, Position, 1)；\n如果返回值是 &gt;&#x3D;0 的正整数，则在这个从库执行查询语句；\n否则，到主库执行查询语句。\n\n如果你的数据库开启了 GTID 模式，对应的也有等待 GTID 的方案。\nMySQL 中同样提供了一个类似的命令：\nselect wait_for_executed_gtid_set(gtid_set, 1);\n\n这条命令的逻辑是：\n\n等待，直到这个库执行的事务中包含传入的 gtid_set，返回 0；\n超时返回 1。\n\n这时，等 GTID 的执行流程就变成了：\n\ntrx1 事务更新完成后，从返回包直接获取这个事务的 GTID，记为 gtid1；\n选定一个从库执行查询语句；\n在从库上执行 select wait_for_executed_gtid_set(gtid1, 1)；\n如果返回值是 0，则在这个从库执行查询语句；\n否则，到主库执行查询语句。\n\n数据库功能性判断select 1 判断实际上，select 1 成功返回，只能说明这个库的进程还在，并不能说明主库没问题。\n我们设置 innodb_thread_concurrency 参数的目的是，控制 InnoDB 的并发线程上限。也就是说，一旦并发线程数达到这个值，InnoDB 在接收到新请求的时候，就会进入等待状态，直到有线程退出。\n这里，我把 innodb_thread_concurrency 设置成 3，表示 InnoDB 只允许 3 个线程并行执行。而在我们的例子中，前三个 session 中的 sleep(100)，使得这三个语句都处于“执行”状态，以此来模拟大查询。\n你看到了， session D 里面，select 1 是能执行成功的，但是查询表 t 的语句会被堵住。也就是说，如果这时候我们用 select 1 来检测实例是否正常的话，是检测不出问题的。\n查表判断为了能够检测 InnoDB 并发线程数过多导致的系统不可用情况，我们需要找一个访问 InnoDB 的场景。一般的做法是，在系统库（mysql 库）里创建一个表，比如命名为 health_check，里面只放一行数据，然后定期执行：\nmysql&gt; select * from mysql.health_check; \n\n使用这个方法，我们可以检测出由于并发线程过多导致的数据库不可用的情况。\n但是，我们马上还会碰到下一个问题，即：空间满了以后，这种方法又会变得不好使。\n我们知道，更新事务要写 binlog，而一旦 binlog 所在磁盘的空间占用率达到 100%，那么所有的更新语句和事务提交的 commit 语句就都会被堵住。但是，系统这时候还是可以正常读数据的。\n更新判断既然要更新，就要放个有意义的字段，常见做法是放一个 timestamp 字段，用来表示最后一次执行检测的时间。这条更新语句类似于：\nmysql&gt; update mysql.health_check set t_modified&#x3D;now();\n\n节点可用性的检测都应该包含主库和备库。如果用更新来检测主库的话，那么备库也要进行更新检测。\n但，备库的检测也是要写 binlog 的。由于我们一般会把数据库 A 和 B 的主备关系设计为双 M 结构，所以在备库 B 上执行的检测命令，也要发回给主库 A。\n但是，如果主库 A 和备库 B 都用相同的更新命令，就可能出现行冲突，也就是可能会导致主备同步停止。所以，现在看来 mysql.health_check 这个表就不能只有一行数据了。\n更新语句，如果失败或者超时，就可以发起主备切换了，为什么还会有判定慢的问题呢？\n其实，这里涉及到的是服务器 IO 资源分配的问题。\n首先，所有的检测逻辑都需要一个超时时间 N。执行一条 update 语句，超过 N 秒后还不返回，就认为系统不可用。\n你可以设想一个日志盘的 IO 利用率已经是 100% 的场景。这时候，整个系统响应非常慢，已经需要做主备切换了。\n但是你要知道，IO 利用率 100% 表示系统的 IO 是在工作的，每个请求都有机会获得 IO 资源，执行自己的任务。而我们的检测使用的 update 命令，需要的资源很少，所以可能在拿到 IO 资源的时候就可以提交成功，并且在超时时间 N 秒未到达之前就返回给了检测系统。\n检测系统一看，update 命令没有超时，于是就得到了“系统正常”的结论。\n内部统计\n\n\n\n\n\n\n\n\nMySQL 5.6 版本以后提供的 performance_schema 库，就在 file_summary_by_event_name 表里统计了每次 IO 请求的时间。\n\n\n\n\n图中这一行表示统计的是 redo log 的写入时间，第一列 EVENT_NAME 表示统计的类型。\n接下来的三组数据，显示的是 redo log 操作的时间统计。\n第一组五列，是所有 IO 类型的统计。其中，COUNT_STAR 是所有 IO 的总次数，接下来四列是具体的统计项， 单位是皮秒；前缀 SUM、MIN、AVG、MAX，顾名思义指的就是总和、最小值、平均值和最大值。\n第二组六列，是读操作的统计。最后一列 SUM_NUMBER_OF_BYTES_READ 统计的是，总共从 redo log 里读了多少个字节。\n第三组六列，统计的是写操作。\n最后的第四组数据，是对其他类型数据的统计。在 redo log 里，你可以认为它们就是对 fsync 的统计。\n\n\n\n\n\n\n\n注意\n如果打开所有的 performance_schema 项，性能大概会下降 10% 左右。\n\n\n数据误删\n\n\n\n\n\n\n\n\n为了找到解决误删数据的更高效的方法，需要先对和 MySQL 相关的误删数据，做下分类：\n\n使用 delete 语句误删数据行；\n使用 drop table 或者 truncate table 语句误删数据表；\n使用 drop database 语句误删数据库；\n使用 rm 命令误删整个 MySQL 实例。\n\n误删行如果是使用 delete 语句误删了数据行，可以用 Flashback 工具通过闪回把数据恢复回来。\nFlashback 恢复数据的原理，是修改 binlog 的内容，拿回原库重放。而能够使用这个方案的前提是，需要确保 binlog_format&#x3D;row 和 binlog_row_image&#x3D;FULL。\n具体恢复数据时，对单个事务做如下处理：\n\n对于 insert 语句，对应的 binlog event 类型是 Write_rows event，把它改成 Delete_rows event 即可；\n同理，对于 delete 语句，也是将 Delete_rows event 改为 Write_rows event；\n而如果是 Update_rows 的话，binlog 里面记录了数据行修改前和修改后的值，对调这两行的位置即可。\n\n\n\n\n\n\n\n\n特别注意\n以上操作不建议直接在主库上执行\n\n\n恢复数据比较安全的做法，是恢复出一个备份，或者找一个从库作为临时库，在这个临时库上执行这些操作，然后再将确认过的临时库的数据，恢复回主库。\n为什么要这么做呢？\n这是因为，一个在执行线上逻辑的主库，数据状态的变更往往是有关联的。可能由于发现数据问题的时间晚了一点儿，就导致已经在之前误操作的基础上，业务代码逻辑又继续修改了其他数据。所以，如果这时候单独恢复这几行数据，而又未经确认的话，就可能会出现对数据的二次破坏。\n我们不止要说误删数据的事后处理办法，更重要是要做到事前预防。我有以下两个建议：\n\n把 sql_safe_updates 参数设置为 on。这样一来，如果我们忘记在 delete 或者 update 语句中写 where 条件，或者 where 条件里面没有包含索引字段的话，这条语句的执行就会报错。\n代码上线前，必须经过 SQL 审计。\n\n如果你确定这个删除操作没问题的话，可以在 delete 语句中加上 where 条件，比如 where id&gt;&#x3D;0。\n但是，delete 全表是很慢的，需要生成回滚日志、写 redo、写 binlog。所以，从性能角度考虑，你应该优先考虑使用 truncate table 或者 drop table 命令。\n使用 delete 命令删除的数据，你还可以用 Flashback 来恢复。而使用 truncate &#x2F;drop table 和 drop database 命令删除的数据，就没办法通过 Flashback 来恢复了。为什么呢？\n这是因为，即使我们配置了 binlog_format&#x3D;row，执行这三个命令时，记录的 binlog 还是 statement 格式。binlog 里面就只有一个 truncate&#x2F;drop 语句，这些信息是恢复不出数据的。\n误删库 &#x2F; 表这种情况下，要想恢复数据，就需要使用全量备份，加增量日志的方式了。这个方案要求线上有定期的全量备份，并且实时备份 binlog。\n在这两个条件都具备的情况下，假如有人中午 12 点误删了一个库，恢复数据的流程如下：\n\n取最近一次全量备份，假设这个库是一天一备，上次备份是当天 0 点；\n用备份恢复出一个临时库；\n从日志备份里面，取出凌晨 0 点之后的日志；\n把这些日志，除了误删除数据的语句外，全部应用到临时库。\n\n这个流程的示意图如下所示：\n\n\n\n\n关于这个过程，有以下几点说明：\n\n为了加速数据恢复，如果这个临时库上有多个数据库，你可以在使用 mysqlbinlog 命令时，加上一个–database 参数，用来指定误删表所在的库。这样，就避免了在恢复数据时还要应用其他库日志的情况。\n在应用日志的时候，需要跳过 12 点误操作的那个语句的 binlog（不然不是直接爆炸了，又删了，hhh）：\n如果原实例没有使用 GTID 模式，只能在应用到包含 12 点的 binlog 文件的时候，先用–stop-position 参数执行到误操作之前的日志，然后再用–start-position 从误操作之后的日志继续执行；\n如果实例使用了 GTID 模式，就方便多了。假设误操作命令的 GTID 是 gtid1，那么只需要执行 set gtid_next&#x3D;gtid1;begin;commit; 先把这个 GTID 加到临时实例的 GTID 集合，之后按顺序执行 binlog 的时候，就会自动跳过误操作的语句。\n\n\n\n恢复加速不过，即使这样，使用 mysqlbinlog 方法恢复数据还是不够快，主要原因有两个：\n\n如果是误删表，最好就是只恢复出这张表，也就是只重放这张表的操作，但是 mysqlbinlog 工具并不能指定只解析一个表的日志；\n用 mysqlbinlog 解析出日志应用，应用日志的过程就只能是单线程。\n\n一种加速的方法是，在用备份恢复出临时实例之后，将这个临时实例设置成线上备库的从库，这样：\n\n在 start slave 之前，先通过执行﻿﻿change replication filter replicate_do_table &#x3D; (tbl_name) 命令，就可以让临时库只同步误操作的表；\n这样做也可以用上并行复制技术，来加速整个数据恢复过程。\n\n\n\n\n\n可以看到，图中 binlog 备份系统到线上备库有一条虚线，是指如果由于时间太久，备库上已经删除了临时实例需要的 binlog 的话，我们可以从 binlog 备份系统中找到需要的 binlog，再放回备库中。\n预防误删库 &#x2F; 表的方法第一条建议是，账号分离。这样做的目的是，避免写错命令。比如：\n\n我们只给业务开发同学 DML 权限，而不给 truncate&#x2F;drop 权限。而如果业务开发人员有 DDL 需求的话，也可以通过开发管理系统得到支持。\n即使是 DBA 团队成员，日常也都规定只使用只读账号，必要的时候才使用有更新权限的账号。\n\n第二条建议是，制定操作规范。这样做的目的，是避免写错要删除的表名。比如：\n\n在删除数据表之前，必须先对表做改名操作。然后，观察一段时间，确保对业务无影响以后再删除这张表。\n改表名的时候，要求给表名加固定的后缀（比如加 _to_be_deleted)，然后删除表的动作必须通过管理系统执行。并且，管理系删除表的时候，只能删除固定后缀的表。\n\nrm 删除数据其实，对于一个有高可用机制的 MySQL 集群来说，最不怕的就是 rm 删除数据了。只要不是恶意地把整个集群删除，而只是删掉了其中某一个节点的数据的话，HA 系统就会开始工作，选出一个新的主库，从而保证整个集群的正常工作。\n这时，你要做的就是在这个节点上把数据恢复回来，再接入整个集群。\n当然了，现在不止是 DBA 有自动化系统，SA（系统管理员）也有自动化系统，所以也许一个批量下线机器的操作，会让你整个 MySQL 集群的所有节点都全军覆没。\n应对这种情况，我的建议只能是说尽量把你的备份跨机房，或者最好是跨城市保存。\n","slug":"MySQL高可用","date":"2022-09-26T13:48:46.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"},{"id":"1305302b447db5e66b7e5e506037fc4a","title":"hard记录","content":"\n\n\n\n\n\n\n\n\n最近做周赛基本都是三题，哪怕半小时以内做完三题，T4也没什么思路，因此专门记录一下周赛和平常遇到的一些有代表性思路的hard题也算是继续提升一下，希望以后可以成为AK选手。\n动态规划2430. 对字母串可执行的最大删除数（313场周赛T4）\n\n\n\n\n\n\n\n\n本题一开始的思路是准备使用hash来记录下，字符串最长前缀，但是错误的贪心了其实这里必须是On^2的，可以根据数据来判断复杂度，然后dfs来不及写了，但感觉dfs会超时，不过一般可以用dfs就可以用dp，所以这题的标准思路就是先记忆化最长字符串前缀，当最长前缀大于删除长度表示可以删除，然后在基础上再讲规划+1。\nclass Solution &#123;\npublic:\n    int deleteString(string s) &#123;\n        int n &#x3D; s.length();\n        if (equal(s.begin()+1, s.end(), s.begin())) &#x2F;&#x2F; 特判全部相同的情况\n            return n;\n        int lcp[n + 1][n + 1]; &#x2F;&#x2F; lcp[i][j] 表示 s[i:] 和 s[j:] 的最长公共前缀\n        memset(lcp, 0, sizeof(lcp));\n        for (int i &#x3D; n - 1; i &gt;&#x3D; 0; --i)\n            for (int j &#x3D; n - 1; j &gt; i; --j)\n                if (s[i] &#x3D;&#x3D; s[j])\n                    lcp[i][j] &#x3D; lcp[i + 1][j + 1] + 1;\n        int f[n];\n        memset(f, 0, sizeof(f));\n        for (int i &#x3D; 0; i &lt;n; ++i) &#123;\n            for (int j &#x3D; 1; i + j * 2 &lt;&#x3D; n; ++j)\n                if (lcp[i][i + j] &gt;&#x3D; j) &#x2F;&#x2F; 说明 s[i:i+j] &#x3D;&#x3D; s[i+j:i+j*2]\n                    f[i] &#x3D; max(f[i], f[i + j]);\n            ++f[i];\n        &#125;\n        return f[0];\n    &#125;\n&#125;;\n\n801. 使序列递增的最小交换次数（10.10每日一题）\n\n\n\n\n\n\n\n\n这题想到了动态规划，但是因为没有把情况搞清楚所以想简单了，这个题居然是以前周赛的第二题实在是不管相信，状态机DP的精髓就是一个限定死的操作，例如本题只有交换和不交换，那么只要保证前面数组的递增性就无后效性，将状态方程把握清楚就可以了。\nclass Solution &#123;\npublic:\n    int minSwap(vector&lt;int>&amp; nums1, vector&lt;int>&amp; nums2) &#123;\n        int n = nums1.size();\n        int a = 0, b = 1;\n        for (int i = 1; i &lt; n; i++) &#123;\n            int at = a, bt = b;\n            a = b = n;\n            if (nums1[i] > nums1[i - 1] &amp;&amp; nums2[i] > nums2[i - 1])  &#123;\n                a = min(a, at);\n                b = min(b, bt + 1);\n            &#125;\n            if (nums1[i] > nums2[i - 1] &amp;&amp; nums2[i] > nums1[i - 1]) &#123;\n                a = min(a, bt);\n                b = min(b, at + 1);\n            &#125;\n        &#125;\n        return min(a, b);\n    &#125;\n&#125;;\n\n\n相关问题\n198. 打家劫舍(和这种偷与不偷我感觉比较类似)\n213. 打家劫舍 II\n\n\n2435. 矩阵中和能被 K 整除的路径（314场周赛T4）\n\n\n\n\n\n\n\n\n标准的记忆化搜索题，奈何T3太难了浪费了很多时间，最接近AK的一次，这题的难点在于三维记忆化要想到取余作为sum不然的话会TEL，然后需要注意的是溢出的处理，说实话int溢出真的很烦尤其有减法，烦的一批！！！吃了好多发WA。（难得有自己写的代码贴上来的很香！）\nclass Solution &#123;\npublic:\n    int numberOfPaths(vector&lt;vector&lt;int&gt;&gt;&amp; grid, int k) &#123;\n        long long res &#x3D;0;\n        vector&lt;vector&lt;vector&lt;long long&gt;&gt;&gt; dp(grid.size(),vector&lt;vector&lt;long long&gt;&gt;(grid[0].size(),vector&lt;long long&gt;(50,-1)));\n        dfs(0,0,grid,k,0,res,dp);\n        res &#x3D; res % 1000000007;\n        return (int)res;\n    &#125;\n    void dfs(int i,int j,vector&lt;vector&lt;int&gt;&gt;&amp; grid, int&amp; k,int sum,long long&amp; res,vector&lt;vector&lt;vector&lt;long long&gt;&gt;&gt;&amp; dp)&#123;\n        sum +&#x3D; grid[i][j];\n        if(dp[i][j][sum%k] !&#x3D; -1)&#123;\n            &#x2F;&#x2F;res &#x3D; res % 1000000007;\n            res +&#x3D; dp[i][j][sum%k];\n            return;\n        &#125;\n        long long tmp &#x3D; res % 1000000007;\n        if(i &#x3D;&#x3D; grid.size()-1 &amp;&amp; j&#x3D;&#x3D;grid[0].size()-1)&#123;\n            if(sum % k &#x3D;&#x3D; 0) res++;\n            return;\n        &#125;\n        if(i &lt; grid.size()-1) dfs(i+1,j,grid,k,sum,res,dp);\n        if(j &lt; grid[0].size()-1) dfs(i,j+1,grid,k,sum,res,dp);\n        dp[i][j][sum%k] &#x3D; (res - tmp)%1000000007;\n    &#125;\n&#125;;\n\n树状数组&#x2F;线段树2426. 满足不等式的数对数目（88场双周赛T4）\n\n\n\n\n\n\n\n\n这题的不等式变形我是想到了，然后求出来数组之后没有办法快速的选取满足条件的区间，感觉逻辑出了点问题，知道要用树状数组求和，奈何没有系统的训练，因此最后也没做出来，区间求和问题还是需要熟练掌握这两种结构，因为周赛出现频率极高。这里可以推荐这个视频：五分钟丝滑动画讲解 | 树状数组来学习树状数组的原理，我觉得讲的特别清楚。\nclass BIT &#123;&#x2F;&#x2F;树状数组的标准写法\nprivate:\n    vector&lt;int&gt; tree;\n\npublic:\n    BIT(int n) : tree(n) &#123;&#125;\n\n    void add(int x) &#123;\n        while (x &lt; tree.size()) &#123;\n            ++tree[x];\n            x +&#x3D; x &amp; -x;\n        &#125;\n    &#125;\n\n    int query(int x) &#123;\n        int res &#x3D; 0;\n        while (x &gt; 0) &#123;\n            res +&#x3D; tree[x];\n            x &amp;&#x3D; x - 1;\n        &#125;\n        return res;\n    &#125;\n&#125;;\n\nclass Solution &#123;\npublic:\n    long long numberOfPairs(vector&lt;int&gt; &amp;a, vector&lt;int&gt; &amp;nums2, int diff) &#123;\n        int n &#x3D; a.size();\n        for (int i &#x3D; 0; i &lt; n; ++i)\n            a[i] -&#x3D; nums2[i];\n        auto b &#x3D; a;\n        sort(b.begin(), b.end()); &#x2F;&#x2F; 配合下面的二分，离散化\n\n        long ans &#x3D; 0L;\n        auto t &#x3D; new BIT(n + 1);\n        for (int x : a) &#123;\n            ans +&#x3D; t-&gt;query(upper_bound(b.begin(), b.end(), x + diff) - b.begin());&#x2F;&#x2F;查询第一个大于x+diff\n            t-&gt;add(lower_bound(b.begin(), b.end(), x) - b.begin() + 1);&#x2F;&#x2F;查询第一个大于等于x\n        &#125;\n        return ans;\n    &#125;\n&#125;;\n\n\n相关问题\n327. 区间和的个数\n剑指 Offer 51. 数组中的逆序对\n\n\n","slug":"hard记录","date":"2022-09-26T10:08:53.000Z","categories_index":"数据结构","tags_index":"算法刷题,思路记录","author_index":"依水何安"},{"id":"5f1d861065ff3b07fbdc6d6fa1d8207a","title":"奇怪的小问题","content":"\n\n\n\n\n\n\n\n\n这个文章主要是记录一些平常突发奇想的一些小问题，所以没有什么顺序，如果你也有同样的疑惑希望可以帮到你。\nDFS先判断后递归还是先递归后判断\n\n\n\n\n\n\n\n\n今天像往常一样在写DFS突然冒出了一个奇怪的想法，究竟应该先递归还是应该先判断，然后就有了这个问题的探究。先说结论：都可以，几乎没有区别，虽然从最底层的角度看先判断优于先递归，毕竟省略了函数调用，但实际上影响非常有限。\n先上测试代码：\n#include &lt;iostream&gt;\n#include &lt;vector&gt;\nusing namespace  std;\n\nvoid dfs1(vector&lt;vector&lt;int&gt;&gt;&amp; tmp, int i, int j,int target)&#123;\n    &#x2F;&#x2F;if(tmp[i][j] !&#x3D; target) return;\n    tmp[i][j] ++;\n    &#x2F;&#x2F;cout&lt;&lt;sum&lt;&lt;endl;\n    if(i &lt; 99 &amp;&amp; tmp[i+1][j] &#x3D;&#x3D; target) dfs1(tmp,i+1,j,target);\n    if(i &gt; 0 &amp;&amp; tmp[i-1][j]  &#x3D;&#x3D; target ) dfs1(tmp,i-1,j,target);\n    if(j &lt; 99 &amp;&amp; tmp[i][j+1]  &#x3D;&#x3D; target ) dfs1(tmp, i,j+1,target);\n    if(j &gt; 0 &amp;&amp; tmp[i][j-1]  &#x3D;&#x3D; target ) dfs1(tmp, i,j-1,target);\n&#125;\nvoid dfs2(vector&lt;vector&lt;int&gt;&gt;&amp; tmp, int i, int j,int target)&#123;\n    if(tmp[i][j] !&#x3D; target) return;\n    tmp[i][j] ++;\n    &#x2F;&#x2F;cout&lt;&lt;sum&lt;&lt;endl;\n    if(i &lt; 99 ) dfs1(tmp,i+1,j,target);\n    if(i &gt; 0 ) dfs1(tmp,i-1,j,target);\n    if(j &lt; 99) dfs1(tmp, i,j+1,target);\n    if(j &gt; 0) dfs1(tmp, i,j-1,target);\n&#125;\n\nint main() &#123;\n    int count &#x3D; 0;\n    for(int j &#x3D; 0;j&lt;100;j++)&#123;\n        double time1 &#x3D;0,time2 &#x3D;0;\n        clock_t startTime,endTime;\n        vector&lt;vector&lt;int&gt;&gt; tmp(100,vector&lt;int&gt;(100,0));\n        vector&lt;vector&lt;int&gt;&gt; tmp1(100,vector&lt;int&gt;(100,0));\n        startTime &#x3D; clock();\n        for(int i &#x3D;0; i &lt; 1000;i++)&#123;\n            dfs2(tmp,0,0,i);\n        &#125;\n        &#x2F;&#x2F;cout&lt;&lt;sum;\n        endTime &#x3D; clock();\n        time1 &#x3D; (double)(endTime - startTime) &#x2F; CLOCKS_PER_SEC;\n        cout&lt;&lt;&quot;先判断：&quot;&lt;&lt;(double)(endTime - startTime) &#x2F; CLOCKS_PER_SEC&lt;&lt;endl;\n        startTime &#x3D; clock();\n        for(int i &#x3D;0; i &lt; 1000;i++)&#123;\n            dfs2(tmp1,0,0,i);\n        &#125;\n        endTime &#x3D; clock();\n        time2 &#x3D; (double)(endTime - startTime) &#x2F; CLOCKS_PER_SEC;\n        cout&lt;&lt;&quot;先递归：&quot;&lt;&lt;(double)(endTime - startTime) &#x2F; CLOCKS_PER_SEC&lt;&lt;endl;\n        if(time1&gt;time2) count--;\n        if(time2&gt;time1) count++;\n    &#125;\n    cout&lt;&lt;&quot;总次数:&quot;&lt;&lt;&quot;100\\t&quot;&lt;&lt;&quot;先判断比先递归快的次数：&quot;&lt;&lt;count&lt;&lt;endl;\n&#125;\n\n这里顺便提一嘴，递归深度真的很有限哈哈哈。\n先说测试结论：两者快慢好像就是单纯的程序波动。\n我分别测试了好几组，发现每次结论的波动都非常大，而且即使是同一个程序使用两个一样的方法也会有很大的波动，所以看起来这里的影响已经是微乎其微的了。\n因此和我们常规感觉一致递归是调用自身的函数，而函数的每次调用都会在栈中产生调用帧（call frame, 用来保存内部变量、返回点等信息），可栈的空间是有限的，没法一次同时保存过多的调用帧。所以如果调用的次数多了就容易导致栈溢出，对空间消耗大。\n那么在条件允许的情况下先判断也不错，当然由于性能的影响微乎其微所以怎么做也完全可以根据代码简洁度和规范决定。\ni++和++i的效率问题C语言中的 i++ 和 ++i 是有区别的，这就有可能带来效率上的差异。如果有代码关心 i++ 执行时的 i 当前值，程序在对 i 进行自加操作时，将不得不先保存 i 的当前值，而 ++i 就无需保存当前值，这就会带来效率上的差异。如果没人关心 i++ 的当前值，那么现代大多数C语言编译器将会将这一差异优化掉，此时 i++ 和 ++i 不再有效率上的差异。\n数组越界的处理问题\n数组越界问题int a[10];\nfor (int i &#x3D; 0; i &lt;&#x3D; 12; i++)\n&#123;\n\ta[i] &#x3D; i;\n\tcout &lt;&lt;  a+i &lt;&lt; endl;\n&#125;\ncout &lt;&lt; a[12] &lt;&lt; endl;\n\n\n\n\n\n\n\n\n\n\n运行上述程序发现会无限循环输出0，因为数组大小为3，下标最大到2，而上述代码因为书写问题，导致for循环的最大索引访问到了3，数组a[3]访问越界，在C++中，只要不是访问受限的内存，所有的内存空间都可以自由访问，根据上面的数组寻址公式，a[3]会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量i的内存地址，也就是i的指针指向了&amp;a[3]，那么a[3]&#x3D;0相当与i&#x3D;0，所以会导致代码无限循环。\n但目前已经没有这个问题，在数组越界的情况下，数组仍然可以被正常调用，因为越界值不再被作为野指针，而是会继续在数组边界之后连续的被声明，非常有意思。\n并且会在程序的最后弹出数组越界的错误，也就是说当有数组越界时程序仍然可以正常执行，但是越界的定位却难以捉摸，因为指针的不确定性。所以在对数组进行管理时要格外小心。\nmain函数含参问题[[邓俊辉学习笔记#main函数含参]]\n类与结构体的定义概念：class和struct的语法基本相同，从声明到使用，都很相似，但是struct的约束要比class多，理论上，struct能做到的class都能做到，但class能做到的stuct却不一定做的到类型：struct是值类型，class是引用类型，因此它们具有所有值类型和引用类型之间的差异效率：由于堆栈的执行效率要比堆的执行效率高，但是堆栈资源却很有限，不适合处理逻辑复杂的大对象，因此struct常用来处理作为基类型对待的小对象，而class来处理某个商业逻辑关系：struct不仅能继承也能被继承 ，而且可以实现接口，不过Class可以完全扩展。内部结构有区别，struct只能添加带参的构造函数，不能使用abstract和protected等修饰符，不能初始化实例字段\n全局变量与局部变量的生命周期C&#x2F;C++变量的生命周期和static_山人自有锦囊妙计的博客-CSDN博客_c++成员变量生命周期\nstl中size的问题使用size减一个数的时候一定不能小于0，因为size是unsigned int，所以小于0还返回2^64次方-1。\n    while(nums[nums.size()-count]&gt;&#x3D;i)&#123;\n    \tcount++;\n    cout&lt;&lt;nums.size()&lt;&lt;count&lt;&lt;endl;\n    cout&lt;&lt;nums.size()-count&lt;&lt;endl;\n    &#125;\nscout:\n    22\n    0\n    23\n    18446744073709551615\n\n","slug":"奇怪的小问题","date":"2022-10-13T08:14:34.000Z","categories_index":"日常记录","tags_index":"日常记录","author_index":"依水何安"},{"id":"6e85e7b765209c5fafd1be815fdedbe2","title":"csapp笔记","content":"程序结构与执行浮点数在机器中表示一个浮点数时需要给出指数，这个指数用整数形式表示，这个整数叫做阶码，阶码指明了小数点在数据中的位置。\n\n\n\n\n\n\n\n\n\n阶码：对于任意一个二进制数N，可用N&#x3D;S×2^P表示，其中S为尾数，P为阶码，2为阶码的底，P、S都用二进制数表示，S表示N的全部有效数字，P指明小数点的位置。当阶码为固定值时，数的这种表示法称为定点表示，这样的数称为“定点数”；当阶码为可变时，数的这种表示法称为浮点表示，这样的数称为“浮点数”。\n对于一个浮点数来说\n来看下float, 他有1个符号位,8个指数位及24个有效数位(只保存23位). 当然刚才的binary32中的binary表明他是以二进制形式保存的.下图是一个float在内存中的表示. \n\n\n\n\n\n 其中有效数中还有一个隐藏位,永远是1. 所以有效数位的那部分永远是1.xxxxxxx…(23个x).另外一个要注意的地方是指数的表示,在IEEE754中规定是用偏移指数的方式表示的,意思是指数位中的数减去127后的数来表示最终的指数.比较上面的图中指数部分是01111100,转换成十进制数为124,然后减去127,结果是-3,也就是说指数部分是2-3&#x3D;1&#x2F;8&#x3D;0.125 .那么有效数部分呢? 加上隐藏的位之后表示为 1.01000000000000000000000&#x3D;1+(1*2-2)&#x3D;5&#x2F;4&#x3D;1.25 ,所以上面表示的数就是 1&#x2F;8 * 5&#x2F;4 &#x3D; 0.15625 .\n\n舍入\n\n\n\n\n\n\nC语言中的浮点数\n\n\n\n\n\n编译命令gcc -Og -S ./xxx.c  //指定.c文件生成汇编文件.s\n\n控制\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","slug":"csapp笔记","date":"2022-10-09T13:30:13.000Z","categories_index":"操作系统","tags_index":"csapp,操作系统,计算机网络","author_index":"依水何安"},{"id":"298ae6749824eedc891feac490554768","title":"MySQL幻读","content":"\n\n\n\n\n\n\n\n\n幻读指的是一个事务在前后两次查询同一个范围的时候，后一次查询看到了前一次查询没有看到的行。\n\n\n\n\n\n\n提示\n这里对“幻读”做一个说明：\n\n在可重复读隔离级别下，普通的查询是快照读，是不会看到别的事务插入的数据的。因此，幻读在“当前读”下才会出现。\n上面 session B 的修改结果，被 session A 之后的 select 语句用“当前读”看到，不能称为幻读。幻读仅专指“新插入的行”。\n\n\n\n幻读存在的问题\n首先是语义上的。导致幻读的操作会破坏第一次当前读的语义。\n\n其次，是数据一致性的问题。锁的设计是为了保证数据的一致性。而这个一致性，不止是数据库内部数据状态在此刻的一致性，还包含了数据和日志在逻辑上的一致性。\n\n暴力加锁无法解决问题。即使把所有的记录都加上锁，还是阻止不了新插入的记录。\n\n\n幻读的解决方法\n\n\n\n\n\n\n\n\n行锁只能锁住行，但是新插入记录这个动作，要更新的是记录之间的“间隙”。因此，为了解决幻读问题，InnoDB 只好引入新的锁，也就是间隙锁 (Gap Lock)。\n间隙锁，锁的就是两个值之间的空隙。比如文章开头的表 t，初始化插入了 6 个记录，这就产生了 7 个间隙。\n间隙锁和行锁合称 next-key lock，每个 next-key lock 是前开后闭区间。也就是说，我们的表 t 初始化以后，如果用 select * from t for update 要把整个表所有记录锁起来，就形成了 7 个 next-key lock，分别是 (-∞,0]、(0,5]、(5,10]、(10,15]、(15,20]、(20, 25]、(25, +supremum]。\n间隙锁和 next-key lock 的引入，帮我们解决了幻读的问题，但同时也带来了一些“困扰”。\n逻辑一旦有并发，就会碰到死锁。\n间隙锁的引入，可能会导致同样的语句锁住更大的范围，这其实是影响了并发度的。\n","slug":"MySQL幻读","date":"2022-09-25T15:36:04.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"},{"id":"dd59c704134a0428540392e3edcac680","title":"MySQL功能机制","content":"数据库表的空间回收机制\n\n\n\n\n\n\n\n\n一个 InnoDB 表包含两部分，即：表结构定义和数据。因为表结构定义占用的空间很小，所以我们今天主要讨论的是表数据。\n参数 innodb_file_per_table表数据既可以存在共享表空间里，也可以是单独的文件。这个行为是由参数 innodb_file_per_table 控制的：\n\n这个参数设置为 OFF 表示的是，表的数据放在系统共享表空间，也就是跟数据字典放在一起；\n这个参数设置为 ON 表示的是，每个 InnoDB 表数据存储在一个以 .ibd 为后缀的文件中。\n\n\n\n\n\n\n\n提示\n将 innodb_file_per_table 设置为 ON，是推荐做法\n\n\n数据删除流程\n\n\n\n假设，我们要删掉 R4 这个记录，InnoDB 引擎只会把 R4 这个记录标记为删除。如果之后要再插入一个 ID 在 300 和 600 之间的记录时，可能会复用这个位置。但是，磁盘文件的大小并不会缩小。\nInnoDB 的数据是按页存储的,所以当删除整个页的时候，整个数据也都可以被复用，但是，数据页的复用跟记录的复用是不同的。\n\n记录的复用，只限于符合范围条件的数据。比如上面的这个例子，R4 这条记录被删除后，如果插入一个 ID 是 400 的行，可以直接复用这个空间。但如果插入的是一个 ID 是 800 的行，就不能复用这个位置了。\n而当整个页从 B+ 树里面摘掉以后，可以复用到任何位置。如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个页上，另外一个数据页就被标记为可复用。\n\ndelete 命令其实只是把记录的位置，或者数据页标记为了“可复用”，但磁盘文件的大小是不会变的。也就是说，通过 delete 命令是不能回收表空间的。这些可以复用，而没有被使用的空间，看起来就像是“空洞”。\n不止是删除数据会造成空洞，插入数据也会。\n如果数据是按照索引递增顺序插入的，那么索引是紧凑的。但如果数据是随机插入的，就可能造成索引的数据页分裂。\n也就是说，经过大量增删改的表，都是可能是存在空洞的。所以，如果能够把这些空洞去掉，就能达到收缩表空间的目的。\n因此我们就需要了解重建表。\n重建表\n表 A需要怎么做空间收缩\n你可以新建一个与表 A 结构相同的表 B，然后按照主键 ID 递增的顺序，把数据一行一行地从表 A 里读出来再插入到表 B 中。\n由于表 B 是新建的表，所以表 A 主键索引上的空洞，在表 B 中就都不存在了。显然地，表 B 的主键索引更紧凑，数据页的利用率也更高。如果我们把表 B 作为临时表，数据从表 A 导入表 B 的操作完成后，用表 B 替换 A，从效果上看，就起到了收缩表 A 空间的作用。\n\n\n\n\n\n\n\n\n\n注意\n在 MySQL 5.5 版本之前，这个命令的执行流程跟我们前面描述的差不多，区别只是这个临时表 B 不需要你自己创建，MySQL 会自动完成转存数据、交换表名、删除旧表的操作。\n\n\n而在MySQL 5.6 版本开始引入的 Online DDL，对这个操作流程做了优化。\n\n建立一个临时文件，扫描表 A 主键的所有数据页；\n用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；\n生成临时文件的过程中，将所有对 A 的操作记录在一个日志文件（row log）中，对应的是图中 state2 的状态；\n临时文件生成后，将日志文件中的操作应用到临时文件，得到一个逻辑数据上与表 A 相同的数据文件，对应的就是图中 state3 的状态；\n用临时文件替换表 A 的数据文件。\n\n由于日志文件记录和重放操作这个功能的存在，这个方案在重建表的过程中，允许对表 A 做增删改操作。这也就是 Online DDL 名字的来源。\nOnline 和 inplace说到 Online，我还要再和你澄清一下它和另一个跟 DDL 有关的、容易混淆的概念 inplace 的区别。\n你可能注意到了，在 MySQL 5.5 版本之前中，我们把表 A 中的数据导出来的存放位置叫作 tmp_table。这是一个临时表，是在 server 层创建的。\n在MySQL 5.6 版本开始，根据表 A 重建出来的数据是放在“tmp_file”里的，这个临时文件是 InnoDB 在内部创建出来的。整个 DDL 过程都在 InnoDB 内部完成。对于 server 层来说，没有把数据挪动到临时表，是一个“原地”操作，这就是“inplace”名称的来源。\n所以，我现在问你，如果你有一个 1TB 的表，现在磁盘间是 1.2TB，能不能做一个 inplace 的 DDL 呢？\n答案是不能。因为，tmp_file 也是要占用临时空间的。\n如果说这两个逻辑之间的关系是什么的话，可以概括为：\n\nDDL 过程如果是 Online 的，就一定是 inplace 的；\n反过来未必，也就是说 inplace 的 DDL，有可能不是 Online 的。截止到 MySQL 8.0，添加全文索引（FULLTEXT index）和空间索引 (SPATIAL index) 就属于这种情况。\n\n\n\n\n\n\n\n提示\noptimize table、analyze table 和 alter table 这三种方式重建表的区别。\n\n从 MySQL 5.6 版本开始，alter table t engine &#x3D; InnoDB（也就是 recreate）默认的就是上面 Online DDL的流程了；\nanalyze table t 其实不是重建表，只是对表的索引信息做重新统计，没有修改数据，这个过程中加了 MDL 读锁；\noptimize table t 等于 recreate+analyze。\n\n\n\ncount(*) 的实现方式在不同的 MySQL 引擎中，count(*) 有不同的实现方式。\n\nMyISAM 引擎把一个表的总行数存在了磁盘上，因此执行 count(*) 的时候会直接返回这个数，效率很高；\n而 InnoDB 引擎就麻烦了，它执行 count(*) 的时候，需要把数据一行一行地从引擎里面读出来，然后累积计数。\n\n\n\n\n\n\n\n提示\n在这篇文章里讨论的是没有过滤条件的 count(*)，如果加了 where 条件的话，MyISAM 表也是不能返回得这么快的。\n\n\n为什么 InnoDB 不跟 MyISAM 一样，也把数字存起来呢？\n这是因为即使是在同一个时刻的多个查询，由于多版本并发控制（MVCC）的原因，InnoDB 表“应该返回多少行”也是不确定的。这里，我用一个算 count(*) 的例子来为你解释一下。\n假设表 t 中现在有 10000 条记录，我们设计了三个用户并行的会话。\n\n会话 A 先启动事务并查询一次表的总行数；\n会话 B 启动事务，插入一行后记录后，查询表的总行数；\n会话 C 先启动一个单独的语句，插入一行记录后，查询表的总行数。\n\n\n\n\n\n三个会话 A、B、C 会同时查询表 t 的总行数，但拿到的结果却不同。\n\n\n\n\n\n\ncount(*) 优化\nInnoDB 是索引组织表，主键索引树的叶子节点是数据，而普通索引树的叶子节点是主键值。所以，普通索引树比主键索引树小很多。对于 count(*) 这样的操作，遍历哪个索引树得到的结果逻辑上都是一样的。因此，MySQL 优化器会找到最小的那棵树来遍历。 在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一。\n\n\n如果你用过 show table status 命令的话，就会发现这个命令的输出结果里面也有一个 TABLE_ROWS 用于显示这个表当前有多少行，这个命令执行挺快的，那这个 TABLE_ROWS 能代替 count(*) 吗？\n\n\n\n\n\n\n\n特别注意\n实际上，TABLE_ROWS 就是从这个采样估算得来的，因此它也很不准。有多不准呢，官方文档说误差可能达到 40% 到 50%。所以，show table status 命令显示的行数也不能直接使用。\n\n\n总的来说就是:\n\nMyISAM 表虽然 count(*) 很快，但是不支持事务；\nshow table status 命令虽然返回很快，但是不准确；\nInnoDB 表直接 count(*) 会遍历全表，虽然结果准确，但会导致性能问题。\n\n数据行数的存储方式因此如果想要计数我们需要找个地方存储行数：\n1.用缓存系统保存计数你可以用一个 Redis 服务来保存这个表的总行数。这个表每被插入一行 Redis 计数就加 1，每被删除一行 Redis 计数就减 1。这种方式下，读和更新操作都很快，但你再想一下这种方式存在什么问题吗？\n没错，缓存系统可能会丢失更新。\nRedis 的数据不能永久地留在内存里，所以你会找一个地方把这个值定期地持久化存储起来。但即使这样，仍然可能丢失更新。试想如果刚刚在数据表中插入了一行，Redis 中保存的值也加了 1，然后 Redis 异常重启了，重启后你要从存储 redis 数据的地方把这个值读回来，而刚刚加 1 的这个计数操作却丢失了。\n当然了，这还是有解的。比如，Redis 异常重启以后，到数据库里面单独执行一次 count(*) 获取真实的行数，再把这个值写回到 Redis 里就可以了。异常重启毕竟不是经常出现的情况，这一次全表扫描的成本，还是可以接受的。\n但实际上，将计数保存在缓存系统中的方式，还不只是丢失更新的问题。即使 Redis 正常工作，这个值还是逻辑上不精确的：\n\n一种是，查到的 100 行结果里面有最新插入记录，而 Redis 的计数里还没加 1；\n另一种是，查到的 100 行结果里没有最新插入的记录，而 Redis 的计数里已经加了 1。\n\n2.在数据库保存计数用缓存系统保存计数有丢失数据和计数不精确的问题。那么，如果我们把这个计数直接放到数据库里单独的一张计数表 C 中，又会怎么样呢？\n首先，这解决了崩溃丢失的问题，InnoDB 是支持崩溃恢复不丢数据的。\n由于 InnoDB 要支持事务，从而导致 InnoDB 表不能把 count(*) 直接存起来，然后查询的时候直接返回形成的。\n\n\n\n\n虽然会话 B 的读操作仍然是在 T3 执行的，但是因为这时候更新事务还没有提交，所以计数值加 1 这个操作对会话 B 还不可见。\n因此，会话 B 看到的结果里， 查计数值和“最近 100 条记录”看到的结果，逻辑上就是一致的。\n不同count的用法\n\n\n\n\n\n\n\n\ncount() 是一个聚合函数，对于返回的结果集，一行行地判断，如果 count 函数的参数不是 NULL，累计值就加 1，否则不加。最后返回累计值。\n所以，count(*)、count(主键 id) 和 count(1) 都表示返回满足条件的结果集的总行数；而 count(字段），则表示返回满足条件的数据行里面，参数“字段”不为 NULL 的总个数。\n至于分析性能差别的时候，有几个原则：\n\nserver 层要什么就给什么；\nInnoDB 只给必要的值；\n现在的优化器只优化了 count(*) 的语义为“取行数”，其他“显而易见”的优化并没有做。\n\n对于 count(主键 id) 来说，InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。\n对于 count(1) 来说，InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。\n单看这两个用法的差别的话，你能对比出来，count(1) 执行得要比 count(主键 id) 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。\n对于 count(字段) 来说：\n\n如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；\n如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。\n\n也就是前面的第一条原则，server 层要什么字段，InnoDB 就返回什么字段。\n但是 count(*) 是例外，并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。\n\n强烈推荐这篇参考文章\nhttps://learnsql.com/blog/difference-between-count-distinct/ (这篇文章讲的非常好)\n\n\n排序机制全字段排序通常情况下，这个语句执行流程如下所示 ：\n\n初始化 sort_buffer，确定放入 name、city、age 这三个字段；\n从索引 city 找到第一个满足 city&#x3D;’杭州’条件的主键 id，也就是图中的 ID_X；\n到主键 id 索引取出整行，取 name、city、age 三个字段的值，存入 sort_buffer 中；\n从索引 city 取下一个记录的主键 id；\n重复步骤 3、4 直到 city 的值不满足查询条件为止，对应的主键 id 也就是图中的 ID_Y；\n对 sort_buffer 中的数据按照字段 name 做快速排序；\n按照排序结果取前 1000 行返回给客户端。\n\n\n\n\n\n\n\n\n注意\n“按 name 排序”这个动作，可能在内存中完成，也可能需要使用外部排序，这取决于排序所需的内存和参数 sort_buffer_size。\n\n\nrowid 排序在上面这个算法过程里面，只对原表的数据读了一遍，剩下的操作都是在 sort_buffer 和临时文件中执行的。但这个算法有一个问题，就是如果查询要返回的字段很多的话，那么 sort_buffer 里面要放的字段数太多，这样内存里能够同时放下的行数很少，要分成很多个临时文件，排序的性能会很差。\nmax_length_for_sort_data，是 MySQL 中专门控制用于排序的行数据的长度的一个参数。它的意思是，如果单行的长度超过这个值，MySQL 就认为单行太大，要换一个算法。\ncity、name、age 这三个字段的定义总长度是 36，我把 max_length_for_sort_data 设置为 16，我们再来看看计算过程有什么改变。\n新的算法放入 sort_buffer 的字段，只有要排序的列（即 name 字段）和主键 id。\n整个执行流程就变成如下所示的样子：\n\n初始化 sort_buffer，确定放入两个字段，即 name 和 id；\n从索引 city 找到第一个满足 city&#x3D;’杭州’条件的主键 id，也就是图中的 ID_X；\n到主键 id 索引取出整行，取 name、id 这两个字段，存入 sort_buffer 中；\n从索引 city 取下一个记录的主键 id；\n重复步骤 3、4 直到不满足 city&#x3D;’杭州’条件为止，也就是图中的 ID_Y；\n对 sort_buffer 中的数据按照字段 name 进行排序；\n遍历排序结果，取前 1000 行，并按照 id 的值回到原表中取出 city、name 和 age 三个字段返回给客户端。\n\n全字段排序 VS rowid 排序如果 MySQL 实在是担心排序内存太小，会影响排序效率，才会采用 rowid 排序算法，这样排序过程中一次可以排序更多行，但是需要再回到原表去取数据。\n如果 MySQL 认为内存足够大，会优先选择全字段排序，把需要的字段都放到 sort_buffer 中，这样排序后就会直接从内存里面返回查询结果了，不用再回到原表去取数据。\n这也就体现了 MySQL 的一个设计思想：如果内存够，就要多利用内存，尽量减少磁盘访问。\n索引优化排序性能联合索引其实，并不是所有的 order by 语句，都需要排序操作的。从上面分析的执行过程，我们可以看到，MySQL 之所以需要生成临时表，并且在临时表上做排序操作，其原因是原来的数据都是无序的。\n我们可以在这个市民表上创建一个 city 和 name 的联合索引，对应的 SQL 语句是：\nalter table t add index city_user(city, name);\n\n在这个索引里面，我们依然可以用树搜索的方式定位到第一个满足 city&#x3D;’杭州’的记录，并且额外确保了，接下来按顺序取“下一条记录”的遍历过程中，只要 city 的值是杭州，name 的值就一定是有序的。\n这样整个查询过程的流程就变成了：\n\n从索引 (city,name) 找到第一个满足 city&#x3D;’杭州’条件的主键 id；\n到主键 id 索引取出整行，取 name、city、age 三个字段的值，作为结果集的一部分直接返回；\n从索引 (city,name) 取下一个记录主键 id；\n重复步骤 2、3，直到查到第 1000 条记录，或者是不满足 city&#x3D;’杭州’条件时循环结束。\n\n覆盖索引覆盖索引是指，索引上的信息足够满足查询请求，不需要再回到主键索引上去取数据。\n按照覆盖索引的概念，我们可以再优化一下这个查询语句的执行流程。\n针对这个查询，我们可以创建一个 city、name 和 age 的联合索引，对应的 SQL 语句就是：\nalter table t add index city_user_age(city, name, age);\n\n这时，对于 city 字段的值相同的行来说，还是按照 name 字段的值递增排序的，此时的查询语句也就不再需要排序了。这样整个查询语句的执行流程就变成了：\n\n从索引 (city,name,age) 找到第一个满足 city&#x3D;’杭州’条件的记录，取出其中的 city、name 和 age 这三个字段的值，作为结果集的一部分直接返回；\n从索引 (city,name,age) 取下一个记录，同样取出这三个字段的值，作为结果集的一部分直接返回；\n重复执行步骤 2，直到查到第 1000 条记录，或者是不满足 city&#x3D;’杭州’条件时循环结束。\n\n随机消息\n\n\n\n\n\n\n\n\n对于 InnoDB 表来说，执行全字段排序会减少磁盘访问，因此会被优先选择。\n对于内存表，回表过程只是简单地根据数据行的位置，直接访问内存得到数据，根本不会导致多访问磁盘。优化器没有了这一层顾虑，那么它会优先考虑的，就是用于排序的行越小越好了，所以，MySQL 这时就会选择 rowid 排序。\n这条语句的执行流程是这样的：\n\n创建一个临时表。这个临时表使用的是 memory 引擎，表里有两个字段，第一个字段是 double 类型，为了后面描述方便，记为字段 R，第二个字段是 varchar(64) 类型，记为字段 W。并且，这个表没有建索引。\n从 words 表中，按主键顺序取出所有的 word 值。对于每一个 word 值，调用 rand() 函数生成一个大于 0 小于 1 的随机小数，并把这个随机小数和 word 分别存入临时表的 R 和 W 字段中，到此，扫描行数是 10000。\n现在临时表有 10000 行数据了，接下来你要在这个没有索引的内存临时表上，按照字段 R 排序。\n初始化 sort_buffer。sort_buffer 中有两个字段，一个是 double 类型，另一个是整型。\n从内存临时表中一行一行地取出 R 值和位置信息（我后面会和你解释这里为什么是“位置信息”），分别存入 sort_buffer 中的两个字段里。这个过程要对内存临时表做全表扫描，此时扫描行数增加 10000，变成了 20000。\n在 sort_buffer 中根据 R 的值进行排序。注意，这个过程没有涉及到表操作，所以不会增加扫描行数。\n排序完成后，取出前三个结果的位置信息，依次到内存临时表中取出 word 值，返回给客户端。这个过程中，访问了表的三行数据，总扫描行数变成了 20003。\n\n磁盘临时表\n\n\n\n\n\n\n\n\ntmp_table_size 这个配置限制了内存临时表的大小，默认值是 16M。如果临时表大小超过了 tmp_table_size，那么内存临时表就会转成磁盘临时表。\n磁盘临时表使用的引擎默认是 InnoDB，是由参数 internal_tmp_disk_storage_engine 控制的。\n当使用磁盘临时表的时候，对应的就是一个没有显式索引的 InnoDB 表的排序过程。\n采用是 MySQL 5.6 版本引入的一个新的排序算法，即：优先队列排序算法。接下来，我们就看看为什么没有使用临时文件的算法，也就是归并排序算法，而是采用了优先队列排序算法。\n其实，我们现在的 SQL 语句，只需要取 R 值最小的 3 个 rowid。但是，如果使用归并排序算法的话，虽然最终也能得到前 3 个值，但是这个算法结束后，已经将 10000 行数据都排好序了。\n也就是说，后面的 9997 行也是有序的了。但，我们的查询并不需要这些数据是有序的。所以，想一下就明白了，这浪费了非常多的计算量。\n而优先队列算法，就可以精确地只得到三个最小值，执行流程如下：\n\n对于这 10000 个准备排序的 (R,rowid)，先取前三行，构造成一个堆；\n\n（对数据结构印象模糊的同学，可以先设想成这是一个由三个元素组成的数组）\n\n取下一个行 (R’,rowid’)，跟当前堆里面最大的 R 比较，如果 R’小于 R，把这个 (R,rowid) 从堆中去掉，换成 (R’,rowid’)；\n重复第 2 步，直到第 10000 个 (R’,rowid’) 完成比较。\n\n随机排序方法我们先把问题简化一下，如果只随机选择 1 个 word 值，可以怎么做呢？思路上是这样的：\n\n取得这个表的主键 id 的最大值 M 和最小值 N;\n用随机函数生成一个最大值到最小值之间的数 X &#x3D; (M-N)*rand() + N;\n取不小于 X 的第一个 ID 的行。\n\n这个方法效率很高，因为取 max(id) 和 min(id) 都是不需要扫描索引的，而第三步的 select 也可以用索引快速定位，可以认为就只扫描了 3 行。但实际上，这个算法本身并不严格满足题目的随机要求，因为 ID 中间可能有空洞，因此选择不同行的概率不一样，不是真正的随机。\n所以，为了得到严格随机的结果，你可以用下面这个流程:\n\n取得整个表的行数，并记为 C。\n取得 Y &#x3D; floor(C * rand())。 floor 函数在这里的作用，就是取整数部分。\n再用 limit Y,1 取得一行。\n\n现在，我们再看看，如果我们按照随机算法 2 的思路，要随机取 3 个 word 值呢？你可以这么做：\n\n取得整个表的行数，记为 C；\n根据相同的随机方法得到 Y1、Y2、Y3；\n再执行三个 limit Y, 1 语句得到三行数据。\n\n全表扫描InnoDB 内存管理用的是最近最少使用 (Least Recently Used, LRU) 算法，这个算法的核心就是淘汰最久未使用的数据。\n下图是一个 LRU 算法的基本模型。\n\n\n\n\nInnoDB 管理 Buffer Pool 的 LRU 算法，是用链表来实现的。\n\n在图 6 的状态 1 里，链表头部是 P1，表示 P1 是最近刚刚被访问过的数据页；假设内存里只能放下这么多数据页；\n这时候有一个读请求访问 P3，因此变成状态 2，P3 被移到最前面；\n状态 3 表示，这次访问的数据页是不存在于链表中的，所以需要在 Buffer Pool 中新申请一个数据页 Px，加到链表头部。但是由于内存已经满了，不能申请新的内存。于是，会清空链表末尾 Pm 这个数据页的内存，存入 Px 的内容，然后放到链表头部。\n从效果上看，就是最久没有被访问的数据页 Pm，被淘汰了。\n\n假设按照这个算法，我们要扫描一个 200G 的表，而这个表是一个历史数据表，平时没有业务访问它。\n那么，按照这个算法扫描的话，就会把当前的 Buffer Pool 里的数据全部淘汰掉，存入扫描过程中访问到的数据页的内容。也就是说 Buffer Pool 里面主要放的是这个历史数据表的数据。\n对于一个正在做业务服务的库，这可不妙。你会看到，Buffer Pool 的内存命中率急剧下降，磁盘压力增加，SQL 语句响应变慢。\n所以，InnoDB 不能直接使用这个 LRU 算法。实际上，InnoDB 对 LRU 算法做了改进。\n\n\n\n\n在 InnoDB 实现上，按照 5:3 的比例把整个 LRU 链表分成了 young 区域和 old 区域。图中 LRU_old 指向的就是 old 区域的第一个位置，是整个链表的 5&#x2F;8 处。也就是说，靠近链表头部的 5&#x2F;8 是 young 区域，靠近链表尾部的 3&#x2F;8 是 old 区域。\n改进后的 LRU 算法执行流程变成了下面这样。\n\n图 7 中状态 1，要访问数据页 P3，由于 P3 在 young 区域，因此和优化前的 LRU 算法一样，将其移到链表头部，变成状态 2。\n之后要访问一个新的不存在于当前链表的数据页，这时候依然是淘汰掉数据页 Pm，但是新插入的数据页 Px，是放在 LRU_old 处。\n处于 old 区域的数据页，每次被访问的时候都要做下面这个判断：\n若这个数据页在 LRU 链表中存在的时间超过了 1 秒，就把它移动到链表头部；\n如果这个数据页在 LRU 链表中存在的时间短于 1 秒，位置保持不变。1 秒这个时间，是由参数 innodb_old_blocks_time 控制的。其默认值是 1000，单位毫秒。\n\n\n\n这个策略，就是为了处理类似全表扫描的操作量身定制的。还是以刚刚的扫描 200G 的历史数据表为例，我们看看改进后的 LRU 算法的操作逻辑：\n\n扫描过程中，需要新插入的数据页，都被放到 old 区域 ;\n一个数据页里面有多条记录，这个数据页会被多次访问到，但由于是顺序扫描，这个数据页第一次被访问和最后一次被访问的时间间隔不会超过 1 秒，因此还是会被保留在 old 区域；\n再继续扫描后续的数据，之前的这个数据页之后也不会再被访问到，于是始终没有机会移到链表头部（也就是 young 区域），很快就会被淘汰出去。\n\n可以看到，这个策略最大的收益，就是在扫描这个大表的过程中，虽然也用到了 Buffer Pool，但是对 young 区域完全没有影响，从而保证了 Buffer Pool 响应正常业务的查询命中率。\njoin算法\n\n\n\n\n\n\n\n\nMysql-表连接join中的NLJ、BNL算法\nIndex Nested-Loop Join（NJL）我们来看一下这个语句：\nselect * from t1 straight_join t2 on (t1.a&#x3D;t2.a);\n\n如果直接使用 join 语句，MySQL 优化器可能会选择表 t1 或 t2 作为驱动表，这样会影响我们分析 SQL 语句的执行过程。所以，为了便于分析执行过程中的性能问题，我改用 straight_join 让 MySQL 使用固定的连接方式执行查询，这样优化器只会按照我们指定的方式去 join。在这个语句里，t1 是驱动表，t2 是被驱动表。\n可以看到，在这条语句里，被驱动表 t2 的字段 a 上有索引，join 过程用上了这个索引，因此这个语句的执行流程是这样的：\n\n从表 t1 中读入一行数据 R；\n从数据行 R 中，取出 a 字段到表 t2 里去查找；\n取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；\n重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。\n\n这个过程是先遍历表 t1，然后根据从表 t1 中取出的每行数据中的 a 值，去表 t2 中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称 NLJ。\n可以看到，在这条语句里，被驱动表 t2 的字段 a 上有索引，join 过程用上了这个索引，因此这个语句的执行流程是这样的：\n\n从表 t1 中读入一行数据 R；\n从数据行 R 中，取出 a 字段到表 t2 里去查找；\n取出表 t2 中满足条件的行，跟 R 组成一行，作为结果集的一部分；\n重复执行步骤 1 到 3，直到表 t1 的末尾循环结束。\n\n这个过程是先遍历表 t1，然后根据从表 t1 中取出的每行数据中的 a 值，去表 t2 中查找满足条件的记录。在形式上，这个过程就跟我们写程序时的嵌套查询类似，并且可以用上被驱动表的索引，所以我们称之为“Index Nested-Loop Join”，简称 NLJ。\n它对应的流程图如下所示：\n\n\n\n\n在这个流程里：\n\n对驱动表 t1 做了全表扫描，这个过程需要扫描 100 行；\n而对于每一行 R，根据 a 字段去表 t2 查找，走的是树搜索过程。由于我们构造的数据都是一一对应的，因此每次的搜索过程都只扫描一行，也是总共扫描 100 行；\n所以，整个执行流程，总扫描行数是 200。\n\n到这里小结一下，通过上面的分析我们得到了两个结论：\n\n使用 join 语句，性能比强行拆成多个单表执行 SQL 语句的性能要好；\n如果使用 join 语句的话，需要让小表做驱动表。\n\n但是，你需要注意，这个结论的前提是“可以使用被驱动表的索引”。\nBlock Nested-Loop Join（BNL）这时候，被驱动表上没有可用的索引，算法的流程是这样的：\n\n把表 t1 的数据读入线程内存 join_buffer 中，由于我们这个语句中写的是 select *，因此是把整个表 t1 放入了内存；\n扫描表 t2，把表 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回。\n\n\n\n\n\n可以看到，在这个过程中，对表 t1 和 t2 都做了一次全表扫描，因此总的扫描行数是 1100。由于 join_buffer 是以无序数组的方式组织的，因此对表 t2 中的每一行，都要做 100 次判断，总共需要在内存中做的判断次数是：100*1000&#x3D;10 万次。\n前面我们说过，如果使用 Simple Nested-Loop Join 算法进行查询，扫描行数也是 10 万行。因此，从时间复杂度上来说，这两个算法是一样的。但是，Block Nested-Loop Join 算法的这 10 万次判断是内存操作，速度上会快很多，性能也更好。\n接下来，我们来看一下，在这种情况下，应该选择哪个表做驱动表。\n假设小表的行数是 N，大表的行数是 M，那么在这个算法里：\n\n两个表都做一次全表扫描，所以总的扫描行数是 M+N；\n内存中的判断次数是 M*N。\n\n可以看到，调换这两个算式中的 M 和 N 没差别，因此这时候选择大表还是小表做驱动表，执行耗时是一样的。\n然后，你可能马上就会问了，这个例子里表 t1 才 100 行，要是表 t1 是一个大表，join_buffer 放不下怎么办呢？\njoin_buffer 的大小是由参数 join_buffer_size 设定的，默认值是 256k。如果放不下表 t1 的所有数据话，策略很简单，就是分段放。\n执行过程就变成了：\n\n扫描表 t1，顺序读取数据行放入 join_buffer 中，放完第 88 行 join_buffer 满了，继续第 2 步；\n扫描表 t2，把 t2 中的每一行取出来，跟 join_buffer 中的数据做对比，满足 join 条件的，作为结果集的一部分返回；\n清空 join_buffer；\n继续扫描表 t1，顺序读取最后的 12 行数据放入 join_buffer 中，继续执行第 2 步。\n\n执行流程图也就变成这样：\n\n\n\n\n图中的步骤 4 和 5，表示清空 join_buffer 再复用。\n这个流程才体现出了这个算法名字中“Block”的由来，表示“分块去 join”。\n可以看到，这时候由于表 t1 被分成了两次放入 join_buffer 中，导致表 t2 会被扫描两次。虽然分成两次放入 join_buffer，但是判断等值条件的次数还是不变的，依然是 (88+12)*1000&#x3D;10 万次。\n我们再来看下，在这种情况下驱动表的选择问题。\n假设，驱动表的数据行数是 N，需要分 K 段才能完成算法流程，被驱动表的数据行数是 M。\n注意，这里的 K 不是常数，N 越大 K 就会越大，因此把 K 表示为λ*N，显然λ的取值范围是 (0,1)。\n所以，在这个算法的执行过程中：\n\n扫描行数是 N+λNM；\n内存判断 N*M 次。\n\nMulti-Range Read 优化（MRR）\n\n\n\n\n\n\n\n\nMulti-Range Read 优化 (MRR)。这个优化的主要目的是尽量使用顺序读盘。\n如果随着 a 的值递增顺序查询的话，id 的值就变成随机的，那么就会出现随机访问，性能相对较差。虽然“按行查”这个机制不能改，但是调整查询的顺序，还是能够加速的。\n因为大多数的数据都是按照主键递增顺序插入得到的，所以我们可以认为，如果按照主键的递增顺序查询的话，对磁盘的读比较接近顺序读，能够提升读性能。\n这，就是 MRR 优化的设计思路。此时，语句的执行流程变成了这样：\n\n根据索引 a，定位到满足条件的记录，将 id 值放入 read_rnd_buffer 中 ;\n将 read_rnd_buffer 中的 id 进行递增排序；\n排序后的 id 数组，依次到主键 id 索引中查记录，并作为结果返回。\n\n这里，read_rnd_buffer 的大小是由 read_rnd_buffer_size 参数控制的。如果步骤 1 中，read_rnd_buffer 放满了，就会先执行完步骤 2 和 3，然后清空 read_rnd_buffer。之后继续找索引 a 的下个记录，并继续循环。\nBatched Key Access在 join_buffer 中放入的数据是 P1P100，表示的是只会取查询需要的字段。当然，如果 join buffer 放不下 P1P100 的所有数据，就会把这 100 行数据分成多段执行上图的流程。\n\n\n\n\n扩展 -hash join看到这里你可能发现了，其实上面计算 10 亿次那个操作，看上去有点儿傻。如果 join_buffer 里面维护的不是一个无序数组，而是一个哈希表的话，那么就不是 10 亿次判断，而是 100 万次 hash 查找。这样的话，整条语句的执行速度就快多了吧？\n确实如此。\n这，也正是 MySQL 的优化器和执行器一直被诟病的一个原因：不支持哈希 join。并且，MySQL 官方的 roadmap，也是迟迟没有把这个优化排上议程。\n实际上，这个优化思路，我们可以自己实现在业务端。实现流程大致如下：\n\nselect * from t1;取得表 t1 的全部 1000 行数据，在业务端存入一个 hash 结构，比如 C++ 里的 set、PHP 的数组这样的数据结构。\nselect * from t2 where b&gt;=1 and b&lt;=2000; 获取表 t2 中满足条件的 2000 行数据。\n把这 2000 行数据，一行一行地取到业务端，到 hash 结构的数据表中寻找匹配的数据。满足匹配的条件的这行数据，就作为结果集的一行。\n\n小结\n\n\n\n\n\n提示\n\nBKA 优化是 MySQL 已经内置支持的，建议你默认使用；\nBNL 算法效率低，建议你都尽量转成 BKA 算法。优化的方向就是给被驱动表的关联字段加上索引；\n基于临时表的改进方案，对于能够提前过滤出小数据的 join 语句来说，效果还是很好的；\nMySQL 目前的版本还不支持 hash join，但你可以配合应用端自己模拟出来，理论上效果要好于临时表的方案。\n\n\n\n临时表\n\n\n\n\n\n\n\n\n有的人可能会认为，临时表就是内存表。但是，这两个概念可是完全不同的。\n\n内存表，指的是使用 Memory 引擎的表，建表语法是 create table … engine&#x3D;memory。这种表的数据都保存在内存里，系统重启的时候会被清空，但是表结构还在。除了这两个特性看上去比较“奇怪”外，从其他的特征上看，它就是一个正常的表。\n而临时表，可以使用各种引擎类型 。如果是使用 InnoDB 引擎或者 MyISAM 引擎的临时表，写数据的时候是写到磁盘上的。当然，临时表也可以使用 Memory 引擎。\n\n\n\n\n\n\n\n提示\n可以看到，临时表在使用上有以下几个特点：\n\n建表语法是 create temporary table …。\n一个临时表只能被创建它的 session 访问，对其他线程不可见。所以，图中 session A 创建的临时表 t，对于 session B 就是不可见的。\n临时表可以与普通表同名。\nsession A 内有同名的临时表和普通表的时候，show create 语句，以及增删改查语句访问的是临时表。\nshow tables 命令不显示临时表。\n\n\n\n也正是由于这个特性，临时表就特别适合我们文章开头的 join 优化这种场景。为什么呢？\n原因主要包括以下两个方面：\n\n不同 session 的临时表是可以重名的，如果有多个 session 同时执行 join 优化，不需要担心表名重复导致建表失败的问题。\n不需要担心数据删除问题。如果使用普通表，在流程执行过程中客户端发生了异常断开，或者数据库发生异常重启，还需要专门来清理中间过程中生成的数据表。而临时表由于会自动回收，所以不需要这个额外的操作。\n\n","slug":"MySQL功能机制","date":"2022-09-22T15:12:15.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"},{"id":"88440a5b541fa0a94c29d4531936445a","title":"MySQL锁设计","content":"\n\n\n\n\n\n\n\n\n根据加锁的范围，MySQL 里面的锁大致可以分成全局锁、表级锁和行锁三类。\n全局锁顾名思义，全局锁就是对整个数据库实例加锁。MySQL 提供了一个加全局读锁的方法，命令是 Flush tables with read lock (FTWRL)。\n当你需要让整个库处于只读状态的时候，可以使用这个命令，之后其他线程的以下语句会被阻塞：\n\n数据更新语句（数据的增删改）\n数据定义语句（包括建表、修改表结构等）\n更新类事务的提交语句。\n\n全局锁的典型使用场景是，做全库逻辑备份。也就是把整库每个表都 select 出来存成文本。\n\n\n\n\n\n\n\n特别注意\n但是让整库都只读，听上去就很危险：\n\n如果你在主库上备份，那么在备份期间都不能执行更新，业务基本上就得停摆；\n如果你在从库上备份，那么备份期间从库不能执行主库同步过来的 binlog，会导致主从延迟。\n\n\n\n在可重复读隔离级别下开启一个事务。也可以解决这个问题。\n官方自带的逻辑备份工具是 mysqldump。当 mysqldump 使用参数–single-transaction 的时候，导数据之前就会启动一个事务，来确保拿到一致性视图。而由于 MVCC 的支持，这个过程中数据是可以正常更新的。\n为什么还需要 FTWRL 呢？一致性读是好，但前提是引擎要支持这个隔离级别。比如，对于 MyISAM 这种不支持事务的引擎，如果备份过程中有更新，总是只能取到最新的数据，那么就破坏了备份的一致性。这时，我们就需要使用 FTWRL 命令了。\n所以，single-transaction 方法只适用于所有的表使用事务引擎的库。如果有的表使用了不支持事务的引擎，那么备份就只能通过 FTWRL 方法。这往往是 DBA 要求业务开发人员使用 InnoDB 替代 MyISAM 的原因之一。\n既然要全库只读，为什么不使用 set global readonly&#x3D;true 的方式呢？确实 readonly 方式也可以让全库进入只读状态，但我还是会建议你用 FTWRL 方式，主要有两个原因：\n\n一是，在有些系统中，readonly 的值会被用来做其他逻辑，比如用来判断一个库是主库还是备库。因此，修改 global 变量的方式影响面更大，我不建议你使用。\n二是，在异常处理机制上有差异。如果执行 FTWRL 命令之后由于客户端发生异常断开，那么 MySQL 会自动释放这个全局锁，整个库回到可以正常更新的状态。而将整个库设置为 readonly 之后，如果客户端发生异常，则数据库就会一直保持 readonly 状态，这样会导致整个库长时间处于不可写状态，风险较高。\n\n表级锁\n\n\n\n\n\n\n\n\nMySQL 里面表级别的锁有两种：一种是表锁，一种是元数据锁（meta data lock，MDL)。\n表锁的语法是 lock tables … read&#x2F;write。与 FTWRL 类似，可以用 unlock tables 主动释放锁，也可以在客户端断开的时候自动释放。需要注意，lock tables 语法除了会限制别的线程的读写外，也限定了本线程接下来的操作对象。\n举个例子, 如果在某个线程 A 中执行 lock tables t1 read, t2 write; 这个语句，则其他线程写 t1、读写 t2 的语句都会被阻塞。同时，线程 A 在执行 unlock tables 之前，也只能执行读 t1、读写 t2 的操作。连写 t1 都不允许，自然也不能访问其他表。\n而对于 InnoDB 这种支持行锁的引擎，一般不使用 lock tables 命令来控制并发，毕竟锁住整个表的影响面还是太大。\n另一类表级的锁是 MDL（metadata lock)。MDL 不需要显式使用，在访问一个表的时候会被自动加上。MDL 的作用是，保证读写的正确性。你可以想象一下，如果一个查询正在遍历一个表中的数据，而执行期间另一个线程对这个表结构做变更，删了一列，那么查询线程拿到的结果跟表结构对不上，肯定是不行的。\n因此，在 MySQL 5.5 版本中引入了 MDL，当对一个表做增删改查操作的时候，加 MDL 读锁；当要对表做结构变更操作的时候，加 MDL 写锁。\n\n读锁之间不互斥，因此你可以有多个线程同时对一张表增删改查。\n读写锁之间、写锁之间是互斥的，用来保证变更表结构操作的安全性。因此，如果有两个线程要同时给一个表加字段，其中一个要等另一个执行完才能开始执行。\n\n行锁\n\n\n\n\n\n\n\n\nMySQL 的行锁是在引擎层由各个引擎自己实现的。但并不是所有的引擎都支持行锁，比如 MyISAM 引擎就不支持行锁。不支持行锁意味着并发控制只能使用表锁，对于这种引擎的表，同一张表上任何时刻只能有一个更新在执行，这就会影响到业务并发度。InnoDB 是支持行锁的，这也是 MyISAM 被 InnoDB 替代的重要原因之一。\n在 InnoDB 事务中，行锁是在需要的时候才加上的，但并不是不需要了就立刻释放，而是要等到事务结束时才释放。这个就是两阶段锁协议。\n知道了这个设定，对我们使用事务有什么帮助呢？那就是，如果你的事务中需要锁多个行，要把最可能造成锁冲突、最可能影响并发度的锁尽量往后放。\n死锁和死锁检测当并发系统中不同线程出现循环资源依赖，涉及的线程都在等待别的线程释放资源时，就会导致这几个线程都进入无限等待的状态，称为死锁。\n\n\n\n\n这时候，事务 A 在等待事务 B 释放 id&#x3D;2 的行锁，而事务 B 在等待事务 A 释放 id&#x3D;1 的行锁。 事务 A 和事务 B 在互相等待对方的资源释放，就是进入了死锁状态。当出现死锁以后，有两种策略：\n\n一种策略是，直接进入等待，直到超时。这个超时时间可以通过参数 innodb_lock_wait_timeout 来设置。\n另一种策略是，发起死锁检测，发现死锁后，主动回滚死锁链条中的某一个事务，让其他事务得以继续执行。将参数 innodb_deadlock_detect 设置为 on，表示开启这个逻辑。\n\n\n\n\n\n\n\n提示\n在 InnoDB 中，innodb_lock_wait_timeout 的默认值是 50s，意味着如果采用第一个策略，当出现死锁以后，第一个被锁住的线程要过 50s 才会超时退出，然后其他线程才有可能继续执行。对于在线服务来说，这个等待时间往往是无法接受的。\n但是，我们又不可能直接把这个时间设置成一个很小的值，比如 1s。这样当出现死锁的时候，确实很快就可以解开，但如果不是死锁，而是简单的锁等待呢？所以，超时时间设置太短的话，会出现很多误伤。\n\n\n所以，正常情况下我们还是要采用第二种策略，即：主动死锁检测，而且 innodb_deadlock_detect 的默认值本身就是 on。主动死锁检测在发生死锁的时候，是能够快速发现并进行处理的，但是它也是有额外负担的。\n每个新来的被堵住的线程，都要判断会不会由于自己的加入导致了死锁，这是一个时间复杂度是 O(n) 的操作。假设有 1000 个并发线程要同时更新同一行，那么死锁检测操作就是 100 万这个量级的。虽然最终检测的结果是没有死锁，但是这期间要消耗大量的 CPU 资源。因此，你就会看到 CPU 利用率很高，但是每秒却执行不了几个事务。\n怎么解决由这种热点行更新导致的性能问题呢？\n\n一种头痛医头的方法，就是如果你能确保这个业务一定不会出现死锁，可以临时把死锁检测关掉。但是这种操作本身带有一定的风险，因为业务设计的时候一般不会把死锁当做一个严重错误，毕竟出现死锁了，就回滚，然后通过业务重试一般就没问题了，这是业务无损的。而关掉死锁检测意味着可能会出现大量的超时，这是业务有损的。\n\n另一个思路是控制并发度。根据上面的分析，你会发现如果并发能够控制住，比如同一行同时最多只有 10 个线程在更新，那么死锁检测的成本很低，就不会出现这个问题。一个直接的想法就是，在客户端做并发控制。但是，你会很快发现这个方法不太可行，因为客户端很多。我见过一个应用，有 600 个客户端，这样即使每个客户端控制到只有 5 个并发线程，汇总到数据库服务端以后，峰值并发数也可能要达到 3000。\n\n\n\n如果团队里暂时没有数据库方面的专家，不能实现这样的方案，能不能从设计上优化这个问题呢？\n你可以考虑通过将一行改成逻辑上的多行来减少锁冲突。还是以影院账户为例，可以考虑放在多条记录上，比如 10 个记录，影院的账户总额等于这 10 个记录的值的总和。这样每次要给影院账户加金额的时候，随机选其中一条记录来加。这样每次冲突概率变成原来的 1&#x2F;10，可以减少锁等待个数，也就减少了死锁检测的 CPU 消耗。\n这个方案看上去是无损的，但其实这类方案需要根据业务逻辑做详细设计。如果账户余额可能会减少，比如退票逻辑，那么这时候就需要考虑当一部分行记录变成 0 的时候，代码要有特殊处理。\n\n\n“快照”在 MVCC 里是怎么工作的？\n\n\n\n\n\n\n\n\n在可重复读隔离级别下，事务在启动的时候就“拍了个快照”。注意，这个快照是基于整库的。\nInnoDB 里面每个事务有一个唯一的事务 ID，叫作 transaction id。它是在事务开始的时候向 InnoDB 的事务系统申请的，是按申请顺序严格递增的。\n而每行数据也都是有多个版本的。每次事务更新数据的时候，都会生成一个新的数据版本，并且把 transaction id 赋值给这个数据版本的事务 ID，记为 row trx_id。同时，旧的数据版本要保留，并且在新的数据版本中，能够有信息可以直接拿到它。\n也就是说，数据表中的一行记录，其实可能有多个版本 (row)，每个版本有自己的 row trx_id。\n\n\n\n\n\n\n提示\n更新数据都是先读后写的，而这个读，只能读当前的值，称为“当前读”（current read）。\n\n\n而读提交的逻辑和可重复读的逻辑类似，它们最主要的区别是：\n\n在可重复读隔离级别下，只需要在事务开始的时候创建一致性视图，之后事务里的其他查询都共用这个一致性视图；\n在读提交隔离级别下，每一个语句执行前都会重新算出一个新的视图。\n\nMySQL实战45讲_8_从一个问题来加深对 mysql\n加锁规则这个规则中，包含了两个“原则”、两个“优化”和一个“bug”：\n\n原则 1：加锁的基本单位是 next-key lock。希望你还记得，next-key lock 是前开后闭区间。\n原则 2：查找过程中访问到的对象才会加锁。\n优化 1：索引上的等值查询，给唯一索引加锁的时候，next-key lock 退化为行锁。\n优化 2：索引上的等值查询，向右遍历时且最后一个值不满足等值条件的时候，next-key lock 退化为间隙锁。\n一个 bug：唯一索引上的范围查询会访问到不满足条件的第一个值为止。\n\n","slug":"全局锁","date":"2022-09-17T12:22:15.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"},{"id":"464acd4e6150cb107fc5e6d33892ffb1","title":"友链留言","content":"\n\n\n\n\n\n\n\n\n本文章主要用于友链留言和水贴用，非常抱歉由于是框架bug再加上学艺不精，只能用这种方法曲线救国了，给您磕头了！！！\n","slug":"友链留言","date":"2022-09-06T12:22:15.000Z","categories_index":"留言板","tags_index":"友链,留言板","author_index":"依水何安"},{"id":"76d4212e70fc90d13d8dd3025d415413","title":"事务隔离&数据库索引","content":"\n\n\n\n\n\n\n\n\n之前在字节青训营因为大作业的相关内容也接触过一些数据库方向的知识，但一直苦于没有系统性的学习和整理，所以这系列文章来总结和记录一些，个人觉得比较重要的内容，以便以后复习使用。主要参考文章是极客时间的MySQL45讲：MySQL 实战 45 讲 这次主要是事务和索引方面的内容，感觉写在一起太长了也不方便记录所以分成几个部分来写，如果后续觉得不方便查阅可能会合并。\n事务隔离\n\n\n\n\n\n\n\n\n简单来说，事务是由一条SQL语句，或者一组SQL语句组成的程序执行单元，事务就是要保证一组数据库操作，要么全部成功，要么全部失败。在 MySQL 中，事务支持是在引擎层实现的。\n\n支付举例\n最经典的例子就是转账，你要给朋友小王转 100 块钱，而此时你的银行卡只有 100 块钱。转账过程具体到程序里会有一系列的操作，比如查询余额、做加减法、更新余额等，这些操作必须保证是一体的，不然等程序查完之后，还没做减法之前，你这 100 块钱，完全可以借着这个时间差再查一次，然后再给另外一个朋友转账。因此事务的作用就是保证一组数据库操作保持一致。\n\n\n隔离性\n\n\n\n\n\n\n\n\nACDI事务四大特性\n1.原子性（Atomicity）：指事务内所有操作要么一起执行成功，要么都一起失败(或者说是回滚)；如事务经典转账案例：A给B转账，A把钱扣了，但B没有收到；可见这种错误是不能接受的，最终会回滚，这也是原子性的重要性。\n2.一致性（Consistency）：指事务执行前后的状态一致，如事务经典转账案例：A给B互相转账，不管怎么转，最终两者钱的总和还是不变。\n3.持久性（Durability）：事务一旦提交，数据就已经永久保存了，不能再回滚。\n4.隔离性（Isolation）：指多个并发事务之间的操作互不干扰，但是事务的并发可能会导致数据脏读、不可重复读、幻读问题，根据业务情况，采用事务隔离级别进行对应数据读问题处理。\n隔离级别\n\n\n\n\n\n\n\n\nSQL 标准定义了四种隔离级别，MySQL 全都支持。这4种隔离级别，并行性能依次降低，安全性依次提高：\n\n读未提交（READ UNCOMMITTED）一个事务还没提交时，它做的变更就能被别的事务看到.\n读已提交 （READ COMMITTED）一个事务提交之后，它做的变更才会被其他事务看到。\n可重复读 （REPEATABLE READ）一个事务执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。当然在可重复读隔离级别下，未提交变更对其他事务也是不可见的。\n串行化 （SERIALIZABLE）顾名思义是对于同一行记录，“写”会加“写锁”，“读”会加“读锁”。当出现读写锁冲突的时候，后访问的事务必须等前一个事务执行完成，才能继续执行。\n\n\n视图实现\n在实现上，数据库里面会创建一个视图，访问的时候以视图的逻辑结果为准。\n\n在“可重复读”隔离级别下，这个视图是在事务启动时创建的，整个事务存在期间都用这个视图。\n\n在“读提交”隔离级别下，这个视图是在每个 SQL 语句开始执行的时候创建的。\n\n“读未提交”隔离级别下直接返回记录上的最新值，没有视图概念；\n\n“串行化”隔离级别下直接用加锁的方式来避免并行访问。\n\n\n\n\n\n可重复读场景\n假设你在管理一个个人银行账户表。一个表存了每个月月底的余额，一个表存了账单明细。这时候你要做数据校对，也就是判断上个月的余额和当前余额的差额，是否与本月的账单明细一致。你一定希望在校对过程中，即使有用户发生了一笔新的交易，也不影响你的校对结果。\n这时候使用“可重复读”隔离级别就很方便。事务启动时的视图可以认为是静态的，不受其他事务更新的影响。\n\n\n事务隔离实现\n\n\n\n\n\n\n\n\n在 MySQL 中，实际上每条记录在更新的时候都会同时记录一条回滚操作。记录上的最新值，通过回滚操作，都可以得到前一个状态的值。当系统里没有比这个回滚日志更早的 read-view 的时候，系统会判断没有事务再需要用到这些回滚日志，此时回滚日志会被删除。\n\n\n\n\n\n\n提示\n尽量不要使用长业务\n\n\n长事务意味着系统里面会存在很老的事务视图。由于这些事务随时可能访问数据库里面的任何数据，所以这个事务提交之前，数据库里面它可能用到的回滚记录都必须保留，这就会导致大量占用存储空间。\n在 MySQL 5.5 及以前的版本，回滚日志是跟数据字典一起放在 ibdata 文件里的，即使长事务最终提交，回滚段被清理，文件也不会变小。除了对回滚段的影响，长事务还占用锁资源，也可能拖垮整个库。\n事物的启动方式MySQL 的事务启动方式有以下几种：\n\n显式启动事务语句， begin 或 start transaction。配套的提交语句是 commit，回滚语句是 rollback。\nset autocommit&#x3D;0，这个命令会将这个线程的自动提交关掉。意味着如果你只执行一个 select 语句，这个事务就启动了，而且并不会自动提交。这个事务持续存在直到你主动执行 commit 或 rollback 语句，或者断开连接。\n\n\n\n\n\n\n\n\n注意\n有些客户端连接框架会默认连接成功后先执行一个 set autocommit&#x3D;0 的命令。这就导致接下来的查询都在事务中，如果是长连接，就导致了意外的长事务。\n因此，建议总是使用 set autocommit&#x3D;1, 通过显式语句的方式来启动事务。\n\n\n\n\n\n\n\n\nQuestion\n现在知道了系统里面应该避免长事务，如果你是业务开发负责人同时也是数据库负责人，你会有什么方案来避免出现或者处理这种情况呢？\n\n\n\nAnswer\n首先，从应用开发端来看：\n\n确认是否使用了 set autocommit&#x3D;0。这个确认工作可以在测试环境中开展，把 MySQL 的 general_log 开起来，然后随便跑一个业务逻辑，通过 general_log 的日志来确认。一般框架如果会设置这个值，也就会提供参数来控制行为，你的目标就是把它改成 1。\n确认是否有不必要的只读事务。有些框架会习惯不管什么语句先用 begin&#x2F;commit 框起来。我见过有些是业务并没有这个需要，但是也把好几个 select 语句放到了事务中。这种只读事务可以去掉。\n业务连接数据库的时候，根据业务本身的预估，通过 SET MAX_EXECUTION_TIME 命令，来控制每个语句执行的最长时间，避免单个语句意外执行太长时间。（为什么会意外？在后续的文章中会提到这类案例）\n\n其次，从数据库端来看：\n\n监控 information_schema.Innodb_trx 表，设置长事务阈值，超过就报警 &#x2F; 或者 kill；\nPercona 的 pt-kill 这个工具不错，推荐使用；\n在业务功能测试阶段要求输出所有的 general_log，分析日志行为提前发现问题；\n如果使用的是 MySQL 5.6 或者更新版本，把 innodb_undo_tablespaces 设置成 2（或更大的值）。如果真的出现大事务导致回滚段过大，这样设置后清理起来更方便。\n\n\n\n数据库索引\n\n\n\n\n\n\n\n\n一句话简单来说，索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。\n\n\n\n\n\n\n\n特别注意\n对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。\n\n\n常见模型1.哈希表（K-V）存储哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的值即 key，就可以找到其对应的值即 Value。结构如下图所示：\n\n需要注意的是，图中哈希表的的值并不是递增的，这样做的好处是增加新的 User 时速度会很快，只需要往后追加。但缺点是，因为不是有序的，所以哈希索引做区间查询的速度是很慢的。所以，哈希表这种结构适用于只有等值查询的场景。\n2.有序数组有序数组在等值查询和范围查询场景中的性能就都非常优秀。因为每个数组都可以保证递增，所以可以使用二分法就可以快速得到，这个时间复杂度是 O(log(N))。\n如果仅仅看查询效率，有序数组就是最好的数据结构了。但是，在需要更新数据的时候就麻烦了，你往中间插入一个记录就必须得挪动后面所有的记录，成本太高。所以，有序数组索引只适用于静态存储引擎\n3.二叉搜索树\n\n\n\n\n\n\n\n\n二叉搜索树，它或者是一棵空树，或者是具有下列性质的二叉树： 若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值； 若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值； 它的左、右子树也分别为二叉搜索树。\n\n这个树的查询时间复杂度当然是O(log(N))，当然为了维持 O(log(N)) 的查询复杂度，你就需要保持这棵树是平衡二叉树。为了做这个保证，更新的时间复杂度也是 O(log(N))。\n\n\n\n\n\n\n提示\n树可以有二叉，也可以有多叉。多叉树就是每个节点有多个儿子，儿子之间的大小保证从左到右递增。二叉树是搜索效率最高的，但是实际上大多数的数据库存储却并不使用二叉树。其原因是，索引不止存在内存中，还要写到磁盘上。为了让一个查询尽量少地读磁盘，就必须让查询过程访问尽量少的数据块。那么，我们就不应该使用二叉树，而是要使用“N 叉”树。这里，“N 叉”树中的“N”取决于数据块的大小。\n\n\n以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。\nN 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。\nInnoDB 的索引模型在 InnoDB 中，表都是根据主键顺序以索引的形式存放的，这种存储方式的表称为索引组织表。又因为前面我们提到的，InnoDB 使用了 B+ 树索引模型，所以数据都是存储在 B+ 树中的。\n每一个索引在 InnoDB 里面对应一棵 B+ 树。\n假设，我们有一个主键列为 ID 的表，表中有字段 k，并且在 k 上有索引。\n这个表的建表语句是：\nmysql&gt; create table T(\nid int primary key, \nk int not null, \nname varchar(16),\nindex (k))engine&#x3D;InnoDB;\n\n表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下。\n\n\n\n\n从图中不难看出，根据叶子节点的内容，索引类型分为主键索引和非主键索引。\n\n主键索引的叶子节点存的是整行数据。在 InnoDB 里，主键索引也被称为聚簇索引（clustered index）。\n\n非主键索引的叶子节点内容是主键的值。在 InnoDB 里，非主键索引也被称为二级索引（secondary index）。\n\n\n基于主键索引和普通索引的查询有什么区别？\n\n如果语句是 select * from T where ID&#x3D;500，即主键查询方式，则只需要搜索 ID 这棵 B+ 树；\n如果语句是 select * from T where k&#x3D;5，即普通索引查询方式，则需要先搜索 k 索引树，得到 ID 的值为 500，再到 ID 索引树搜索一次。这个过程称为回表。\n\n也就是说，基于非主键索引的查询需要多扫描一棵索引树。因此，我们在应用中应该尽量使用主键查询。\n索引维护插入新记录的时候可以不指定 ID 的值，系统会获取当前 ID 最大值加 1 作为下一条记录的 ID 值。\n也就是说，自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。\n而有业务逻辑的字段做主键，则往往不容易保证有序插入，这样写数据成本相对较高。\n最左前缀原则B+ 树这种索引结构，可以利用索引的“最左前缀”，来定位记录。\n如果你要查的是所有名字第一个字是“张”的人，你的 SQL 语句的条件是”where name like ‘张 %’”。这时，你也能够用上这个索引，查找到第一个符合条件的记录是 ID3，然后向后遍历，直到不满足条件为止。\n可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。\n那么，如果既有联合查询，又有基于 a、b 各自的查询呢？查询条件里面只有 b 的语句，是无法使用 (a,b) 这个联合索引的，这时候你不得不维护另外一个索引，也就是说你需要同时维护 (a,b)、(b) 这两个索引。\n\n\n\n\n\n\n提示\n这时候，我们要考虑的原则就是空间了。比如上面这个市民表的情况，name 字段是比 age 字段大的 ，那我就建议你创建一个（name,age) 的联合索引和一个 (age) 的单字段索引。\n\n\n索引下推我们还是以市民表的联合索引（name, age）为例。如果现在有一个需求：检索出表中“名字第一个字是张，而且年龄是 10 岁的所有男孩”。那么，SQL 语句是这么写的：\nmysql&gt; select * from tuser where name like &#39;张 %&#39; and age&#x3D;10 and ismale&#x3D;1;\n\n你已经知道了前缀索引规则，所以这个语句在搜索索引树的时候，只能用 “张”，找到第一个满足条件的记录 ID3。当然，这还不错，总比全表扫描要好。\n\n在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。\n\n而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。\n\n\n普通索引与唯一索引\n\n\n\n\n\n\n\n\n1、普通索引\n　　普通索引（由关键字KEY或INDEX定义的索引）的唯一任务是加快对数据的访问速度。因此，应该只为那些最经常出现在查询条件（WHEREcolumn&#x3D;）或排序条件（ORDERBYcolumn）中的数据列创建索引。只要有可能，就应该选择一个数据最整齐、最紧凑的数据列（如一个整数类型的数据列）来创建索引。\n2、唯一索引\n　　普通索引允许被索引的数据列包含重复的值。比如说，因为人有可能同名，所以同一个姓名在同一个“员工个人资料”数据表里可能出现两次或更多次。\nchange buffer当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。\n需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。\n将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。\n显然，如果能够将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式还能够避免占用内存，提高内存利用率。\n:::deatils 什么条件下可以使用 change buffer \n对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。比如，要插入 (4,400) 这个记录，就要先判断现在表中是否已经存在 k&#x3D;4 的记录，而这必须要将数据页读入内存才能判断。如果都已经读入到内存了，那直接更新内存会更快，就没必要使用 change buffer 了。\n因此，唯一索引的更新就不能使用 change buffer，实际上也只有普通索引可以使用。\nchange buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innodb_change_buffer_max_size 来动态设置。这个参数设置为 50 的时候，表示 change buffer 的大小最多只能占用 buffer pool 的 50%。\n:::\n优化器逻辑\n\n\n\n\n\n\n\n\n优化器选择索引的目的，是找到一个最优的执行方案，并用最小的代价去执行语句。在数据库里面，扫描行数是影响执行代价的因素之一。扫描的行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少。\n扫描行数是怎么判断的？\nMySQL 在真正开始执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。\n这个统计信息就是索引的“区分度”。显然，一个索引上不同的值越多，这个索引的区分度就越好。而一个索引上不同的值的个数，我们称之为“基数”（cardinality）。也就是说，这个基数越大，索引的区分度越好。\nMySQL 是怎样得到索引的基数的呢？\nMySQL 采样统计的方法。\n因为把整张表取出来一行行统计，虽然可以得到精确的结果，但是代价太高了，所以只能选择“采样统计”。\n采样统计的时候，InnoDB 默认会选择 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以这个索引的页面数，就得到了这个索引的基数。\n在 MySQL 中，有两种存储索引统计的方式，可以通过设置参数 innodb_stats_persistent 的值来选择：\n\n设置为 on 的时候，表示统计信息会持久化存储。这时，默认的 N 是 20，M 是 10。\n设置为 off 的时候，表示统计信息只存储在内存中。这时，默认的 N 是 8，M 是 16。\n\n索引选择异常和处理\n采用 force index 强行选择一个索引。\n\n修改语句，引导 MySQL 使用我们期望的索引。\n\n在有些场景下，我们可以新建一个更合适的索引，来提供给优化器做选择，或删掉误用的索引。\n\n\n前缀索引与覆盖索引\n\n\n\n\n\n\n\n\n使用前缀索引就用不上覆盖索引对查询性能的优化了\n但是使用前缀索引通常效果不错，如何提高前缀索引的区分度：\n\n第一种方式是使用倒序存储。由于身份证号的最后 6 位没有地址码这样的重复逻辑，所以最后这 6 位很可能就提供了足够的区分度。\n\n第二种方式是使用 hash 字段。然后每次插入新记录的时候，都同时用 crc32() 这个函数得到校验码填到这个新字段。\n\n\n这两种方法的异同点：\n\n\n\n\n\n\n相同点\n\n它们的相同点是，都不支持范围查询。\n\n倒序存储的字段上创建的索引是按照倒序字符串的方式排序的，已经没有办法利用索引方式查出身份证号码在 [ID_X, ID_Y] 的所有市民了。同样地，hash 字段的方式也只能支持等值查询。\n\n\n\n\n\n\n\n\n不同点\n\n从占用的额外空间来看，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。当然，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了。\n\n在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些。\n\n从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数。\n\n\n\n\n字符串索引小结\n直接创建完整索引，这样可能比较占用空间；\n创建前缀索引，节省空间，但会增加查询扫描次数，并且不能使用覆盖索引；\n倒序存储，再创建前缀索引，用于绕过字符串本身前缀的区分度不够的问题；\n创建 hash 字段索引，查询性能稳定，有额外的存储和计算消耗，跟第三种方式一样，都不支持范围扫描。\n\n","slug":"事务隔离","date":"2022-08-31T12:22:15.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"},{"id":"77b268d8a20b2f9b34be681cdfe52894","title":"MySQL框架&日志系统","content":"\n\n\n\n\n\n\n\n\n之前在字节青训营因为大作业的相关内容也接触过一些数据库方向的知识，但一直苦于没有系统性的学习和整理，所以这系列文章来总结和记录一些，个人觉得比较重要的内容，以便以后复习使用。主要参考文章是极客时间的MySQL45讲：MySQL 实战 45 讲 \nMySQL框架\n\n\n\n连接器\n\n\n\n\n\n\n\n\n连接器负责跟客户端建立链接、获取权限、维持和管理链接。常见的连接命令为：\n&gt;mysql -h$ip -P$port -u$user -p\n连接器在完成连接操作之后会进入Sleep状态表示空闲连接，而wait_timeout参数可以控制连接器自动断开的时间，一般默认为8小时。\n\n解决占用内存过多\n\n定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。\n如果你用的是 MySQL 5.7 或更新版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_connection 来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。\n\n\n\n查询缓存\n\n\n\n\n\n\n\n\nMySQL 拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句及其结果可能会以 key-value 对的形式，被直接缓存在内存中。\n查询缓存往往弊大于利，因为查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲地把结果存起来，还没使用呢，就被一个更新全清空了。\n分析器\n\n\n\n\n\n\n\n\n分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条 SQL 语句，MySQL 需要识别出里面的字符串分别是什么，代表什么。\nMySQL 从你输入的”select”这个关键字识别出来，这是一个查询语句。它也要把字符串“T”识别成“表名 T”，把字符串“ID”识别成“列 ID”。\n做完了这些识别以后，就要做“语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个 SQL 语句是否满足 MySQL 语法。\n优化器\n\n\n\n\n\n\n\n\n优化器是在表里面有多个索引的时候，决定使用哪个索引；或者在一个语句有多表关联（join）的时候，决定各个表的连接顺序。\n执行器\n\n\n\n\n\n\n\n\nMySQL 通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。\n执行器的业务逻辑一般为：\n\n验证权限\n调用引擎接口执行逻辑\n重复逻辑知道表的最后一行\n返回满足条件的的行记录作为结果返回给客户端\n\n\n查询日志\n你会在数据库的慢查询日志中看到一个 rows_examined 的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。\n在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟 rows_examined 并不是完全相同的。\n\n\n日志系统mysql&gt; create table T(ID int primary key, c int);\n\n这是一条最常见的更新语句，例如我们现在要将ID&#x3D;2 这一行的值加 1，SQL 语句就会这么写：\nmysql&gt; update T set c&#x3D;c+1 where ID&#x3D;2;\n\n在上文中我们已经介绍了查询语句的流程,那么我们来整理一下更新语句的流程：\n\n连接连接器，验证权限\n分析器分析更新语句\n清空缓存结果\n优化器决定ID索引\n执行器执行更新\nredo log（重做日志）&amp; binlog（归档日志）\n\nredo log 重做日志\n\n\n\n\n\n\n\n\n在 MySQL 里也有这个问题，如果每一次的更新操作都需要写进磁盘，然后磁盘也要找到对应的那条记录，然后再更新，整个过程 IO 成本、查找成本都很高。为了解决这个问题，MySQL 的设计者就用了redo log来提升更新效率。\nMySQL 里经常说到的 WAL 技术，WAL 的全称是 Write-Ahead Logging，它的关键点就是先写日志，再写磁盘。具体来说，当有一条记录需要更新的时候，InnoDB 引擎就会先把记录写到 redo log（粉板）里面，并更新内存，这个时候更新就算完成了。同时，InnoDB 引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统比较空闲的时候做。下图为 redo log的示意图。\n\n\n\n\nnnoDB 的 redo log 是固定大小的，比如可以配置为一组 4 个文件，每个文件的大小是 1GB。从头开始写，写到末尾就又回到开头循环写。\n\nredo log示意图详解\nwrite pos 是当前记录的位置，一边写一边后移，写到第 3 号文件末尾后就回到 0 号文件开头。checkpoint 是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据文件。\nwrite pos 和 checkpoint 之间的是“粉板”上还空着的部分，可以用来记录新的操作。如果 write pos 追上 checkpoint，表示“粉板”满了，这时候不能再执行新的更新，得停下来先擦掉一些记录，把 checkpoint 推进一下。\n\n\nflush机制由于这个机制的存在，当内存数据页跟磁盘数据页内容不一致的时候，我们称这个内存页为“脏页”。内存数据写入到磁盘后，内存和磁盘上的数据页的内容就一致了，称为“干净页”。\n一下这些情况就会发生数据库的flush（刷脏页，也就是将脏页恢复为一直内容）:\n\nInnoDB 的 redo log 写满了。这时候系统会停止所有更新操作，把 checkpoint 往前推进，redo log 留出空间可以继续写。\n系统内存不足。当需要新的内存页，而内存不够用的时候，就要淘汰一些数据页，空出内存给别的数据页使用。如果淘汰的是“脏页”，就要先将脏页写到磁盘。\nMySQL 认为系统“空闲”的时候。\nMySQL 正常关闭的情况。这时候，MySQL 会把内存的脏页都 flush 到磁盘上，这样下次 MySQL 启动的时候，就可以直接从磁盘上读数据，启动速度会很快。\n\n分析一下分析一下上面四种场景对性能的影响。\n其中，第三种情况是属于 MySQL 空闲时的操作，这时系统没什么压力，而第四种场景是数据库本来就要关闭了。这两种情况下，你不会太关注“性能”问题。\n第一种是“redo log 写满了，要 flush 脏页”，这种情况是 InnoDB 要尽量避免的。因为出现这种情况的时候，整个系统就不能再接受更新了，所有的更新都必须堵住。如果你从监控上看，这时候更新数会跌为 0。\n第二种是“内存不够用了，要先将脏页写到磁盘”，这种情况其实是常态。InnoDB 用缓冲池（buffer pool）管理内存，缓冲池中的内存页有三种状态：\n\n第一种是，还没有使用的；\n第二种是，使用了并且是干净页；\n第三种是，使用了并且是脏页。\n\n\n\n\n\n\n\n提示\nInnoDB 的策略是尽量使用内存，因此对于一个长时间运行的库来说，未被使用的页面很少。\n而当要读入的数据页没有在内存的时候，就必须到缓冲池中申请一个数据页。这时候只能把最久不使用的数据页从内存中淘汰掉：如果要淘汰的是一个干净页，就直接释放出来复用；但如果是脏页呢，就必须将脏页先刷到磁盘，变成干净页后才能复用。\n\n\n刷脏页虽然是常态，但是出现以下这两种情况，都是会明显影响性能的：\n\n一个查询要淘汰的脏页个数太多，会导致查询的响应时间明显变长；\n日志写满，更新全部堵住，写性能跌为 0，这种情况对敏感业务来说，是不能接受的。\n\n所以，InnoDB 需要有控制脏页比例的机制，来尽量避免上面的这两种情况。\nInnoDB 刷脏页的控制策略首先，你要正确地告诉 InnoDB 所在主机的 IO 能力，这样 InnoDB 才能知道需要全力刷脏页的时候，可以刷多快。\n这就要用到 innodb_io_capacity 这个参数了，它会告诉 InnoDB 你的磁盘能力。这个值我建议你设置成磁盘的 IOPS。磁盘的 IOPS 可以通过 fio 这个工具来测试，下面的语句是我用来测试磁盘随机读写的命令：\nfio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest \n\n其实，因为没能正确地设置 innodb_io_capacity 参数，而导致的性能问题也比比皆是。\nInnoDB 的刷盘速度就是要参考这两个因素：\n\n一个是脏页比例。参数 innodb_max_dirty_pages_pct 是脏页比例上限，默认值是 75%。InnoDB 会根据当前的脏页比例（假设为 M），算出一个范围在 0 到 100 之间的数字。InnoDB 每次写入的日志都有一个序号，当前写入的序号跟 checkpoint 对应的序号之间的差值，我们假设为 N。InnoDB 会根据这个 N 算出一个范围在 0 到 100 之间的数字，这个计算公式可以记为 F2(N)。根据上述算得的 F1(M) 和 F2(N) 两个值，取其中较大的值记为 R，之后引擎就可以按照 innodb_io_capacity 定义的能力乘以 R% 来控制刷脏页的速度。如图所示：\n\n\n\n\n\n\n\n一个是 redo log 写盘速度。\n\n\n\n\n\n\n\n\n注意\n一旦一个查询请求需要在执行过程中先 flush 掉一个脏页时，这个查询就可能要比平时慢了。而 MySQL 中的一个机制，可能让你的查询会更慢：在准备刷一个脏页的时候，如果这个数据页旁边的数据页刚好是脏页，就会把这个“邻居”也带着一起刷掉；而且这个把“邻居”拖下水的逻辑还可以继续蔓延，也就是对于每个邻居数据页，如果跟它相邻的数据页也还是脏页的话，也会被放到一起刷。\n在 InnoDB 中，innodb_flush_neighbors 参数就是用来控制这个行为的，值为 1 的时候会有上述的“连坐”机制，值为 0 时表示不找邻居，自己刷自己的。\n找“邻居”这个优化在机械硬盘时代是很有意义的，可以减少很多随机 IO。机械硬盘的随机 IOPS 一般只有几百，相同的逻辑操作减少随机 IO 就意味着系统性能的大幅度提升。\n而如果使用的是 SSD 这类 IOPS 比较高的设备的话，我就建议你把 innodb_flush_neighbors 的值设置成 0。因为这时候 IOPS 往往不是瓶颈，而“只刷自己”，就能更快地执行完必要的刷脏页操作，减少 SQL 语句响应时间。\n在 MySQL 8.0 中，innodb_flush_neighbors 参数的默认值已经是 0 了。\n\n\ncrash-safe\n\n\n\n\n\n\n\n\n有了 redo log，InnoDB 就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为crash-safe。\nbinlog（归档日志）\n\n\n\n\n\n\n\n\n实际上，在框架中我们不难发现MySQL有一块是 Server 层，它主要做的是 MySQL 功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。如果说redo log是 InnoDB 引擎特有的日志，而 Server 层也有自己的日志，称为 binlog（归档日志）。\n仅仅依靠binlog只能完成归档服务而不能实现crash-safe 能力，因此 MySQL为了实现存储引擎的crash-safe 能力带来了另一套日志系统也就是redo log。这两种日志主要有以下三点不同：\n\nredo log 是 InnoDB 引擎特有的；binlog 是 MySQL 的 Server 层实现的，所有引擎都可以使用。\nredo log 是物理日志，记录的是“在某个数据页上做了什么修改”；binlog 是逻辑日志，记录的是这个语句的原始逻辑，比如“给 ID&#x3D;2 这一行的 c 字段加 1 ”。\nredo log 是循环写的，空间固定会用完；binlog 是可以追加写入的。“追加写”是指 binlog 文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。\n\n此时我们就可以总结执行器和 InnoDB 引擎在执行这个简单的 update 语句时的内部流程：\n\n执行器先找引擎取 ID&#x3D;2 这一行。ID 是主键，引擎直接用树搜索找到这一行。如果 ID&#x3D;2 这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。\n执行器拿到引擎给的行数据，把这个值加上 1，比如原来是 N，现在就是 N+1，得到新的一行数据，再调用引擎接口写入这行新数据。\n引擎将这行新数据更新到内存中，同时将这个更新操作记录到 redo log 里面，此时 redo log 处于 prepare 状态。然后告知执行器执行完成了，随时可以提交事务。\n执行器生成这个操作的 binlog，并把 binlog 写入磁盘。\n执行器调用引擎的提交事务接口，引擎把刚刚写入的 redo log 改成提交（commit）状态，更新完成。\n\n两阶段提交\n\n\n\n\n\n\n\n\n仍然用前面的 update 语句来做例子。假设当前 ID&#x3D;2 的行，字段 c 的值是 0，再假设执行 update 语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了 crash，会出现什么情况呢？\n\n先写 redo log 后写 binlog。假设在 redo log 写完，binlog 还没有写完的时候，MySQL 进程异常重启。由于我们前面说过的，redo log 写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行 c 的值是 1。但是由于 binlog 没写完就 crash 了，这时候 binlog 里面就没有记录这个语句。因此，之后备份日志的时候，存起来的 binlog 里面就没有这条语句。然后你会发现，如果需要用这个 binlog 来恢复临时库的话，由于这个语句的 binlog 丢失，这个临时库就会少了这一次更新，恢复出来的这一行 c 的值就是 0，与原库的值不同。\n先写 binlog 后写 redo log。如果在 binlog 写完之后 crash，由于 redo log 还没写，崩溃恢复以后这个事务无效，所以这一行 c 的值是 0。但是 binlog 里面已经记录了“把 c 从 0 改成 1”这个日志。所以，在之后用 binlog 来恢复的时候就多了一个事务出来，恢复出来的这一行 c 的值就是 1，与原库的值不同。\n\n虽然表面上看起来，发生宕机的概率不高，但是在需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用 binlog 来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。\nredo log 用于保证 crash-safe 能力。innodb_flush_log_at_trx_commit 这个参数设置成 1 的时候，表示每次事务的 redo log 都直接持久化到磁盘。\nsync_binlog 这个参数设置成 1 的时候，表示每次事务的 binlog 都持久化到磁盘。只有持久化的存储才能保证数据一场重启之后不会丢失。\n\n\n\n\n\n\nQuestion\n定期全量备份的周期“取决于系统重要性，有的是一天一备，有的是一周一备”。那么在什么场景下，一天一备会比一周一备更有优势呢？或者说，它影响了这个数据库系统的哪个指标？\n\n\n\nAnswer\n该问题主要取决于binlog的规模，一天一备的binlog规模较小，那么恢复到误删时刻的时间和成本自然也就越短，而一周一备虽然恢复时间较长，但是如果发现问题时距离误操作已经过去了好几天，那么也仍然可以恢复，也就是后悔的容错时间更长。因此可以一天一备或者短周期备份后，再额外全库备份一次，以防止意外的发生也比较兼顾。\n\n\n异常重启\n\n\n\n如果在图中时刻 A 的地方，也就是写入 redo log 处于 prepare 阶段之后、写 binlog 之前，发生了崩溃（crash），由于此时 binlog 还没写，redo log 也还没提交，所以崩溃恢复的时候，这个事务会回滚。这时候，binlog 还没写，所以也不会传到备库。到这里，大家都可以理解。\n大家出现问题的地方，主要集中在时刻 B，也就是 binlog 写完，redo log 还没 commit 前发生 crash，那崩溃恢复的时候 MySQL 会怎么处理？\nMySQL崩溃恢复时的判断规则。\n\n如果 redo log 里面的事务是完整的，也就是已经有了 commit 标识，则直接提交；\n如果 redo log 里面的事务只有完整的 prepare，则判断对应的事务 binlog 是否存在并完整：a. 如果是，则提交事务；b. 否则，回滚事务。\n\n这里，时刻 B 发生 crash 对应的就是 2(a) 的情况，崩溃恢复过程中事务会被提交。\n\n\n\n\n\n\nQuestion\nMySQL 怎么知道 binlog 是完整的?\n\n\n一个事务的 binlog 是有完整格式的：\n\nstatement 格式的 binlog，最后会有 COMMIT；\nrow 格式的 binlog，最后会有一个 XID event。\n\n另外，在 MySQL 5.6.2 版本以后，还引入了 binlog-checksum 参数，用来验证 binlog 内容的正确性。对于 binlog 日志由于磁盘原因，可能会在日志中间出错的情况，MySQL 可以通过校验 checksum 的结果来发现。所以，MySQL 还是有办法验证事务 binlog 的完整性的。\n\n\n\n\n\n\nQuestion\nredo log 和 binlog 是怎么关联起来的?\n\n\n它们有一个共同的数据字段，叫 XID。崩溃恢复的时候，会按顺序扫描 redo log：\n\n如果碰到既有 prepare、又有 commit 的 redo log，就直接提交；\n如果碰到只有 parepare、而没有 commit 的 redo log，就拿着 XID 去 binlog 找对应的事务。\n\n\n\n\n\n\n\nQuestion\n处于 prepare 阶段的 redo log 加上完整 binlog，重启就能恢复，MySQL 为什么要这么设计?\n\n\n在时刻 B，也就是 binlog 写完以后 MySQL 发生崩溃，这时候 binlog 已经写入了，之后就会被从库（或者用这个 binlog 恢复出来的库）使用。\n所以，在主库上也要提交这个事务。采用这个策略，主库和备库的数据就保证了一致性。\n\n\n\n\n\n\nQuestion\n不引入两个日志，也就没有两阶段提交的必要了。只用 binlog 来支持崩溃恢复，又能支持归档，不就可以了？\n\n\nmysql 为什么不能用binlog来做数据恢复？_JackMa_的博客-CSDN博客_binlog为什么不支持崩溃恢复\n\n\n\n\n\n\nQuestion\n能不能反过来，只用 redo log，不要 binlog\n\n\n如果只从崩溃恢复的角度来讲是可以的。你可以把 binlog 关掉，这样就没有两阶段提交了，但系统依然是 crash-safe 的。\n但是，如果你了解一下业界各个公司的使用场景的话，就会发现在正式的生产库上，binlog 都是开着的。因为 binlog 有着 redo log 无法替代的功能。\n一个是归档。redo log 是循环写，写到末尾是要回到开头继续写的。这样历史日志没法保留，redo log 也就起不到归档的作用。\n一个就是 MySQL 系统依赖于 binlog。binlog 作为 MySQL 一开始就有的功能，被用在了很多地方。其中，MySQL 系统高可用的基础，就是 binlog 复制。\n还有很多公司有异构系统（比如一些数据分析系统），这些系统就靠消费 MySQL 的 binlog 来更新自己的数据。关掉 binlog 的话，这些下游系统就没法输入了。\n总之，由于现在包括 MySQL 高可用在内的很多系统机制都依赖于 binlog，所以“鸠占鹊巢”redo log 还做不到。你看，发展生态是多么重要。\n\n\n\n\n\n\nQuestion\nredo log buffer 是什么？是先修改内存，还是先写 redo log 文件？\n\n\n在一个事务的更新过程中，日志是要写多次的。比如下面这个事务：\nbegin;\ninsert into t1 ...\ninsert into t2 ...\ncommit;\n\n这个事务要往两个表中插入记录，插入数据的过程中，生成的日志都得先保存起来，但又不能在还没 commit 的时候就直接写到 redo log 文件里。\n所以，redo log buffer 就是一块内存，用来先存 redo 日志的。也就是说，在执行第一个 insert 的时候，数据的内存被修改了，redo log buffer 也写入了日志。\n但是，真正把日志写到 redo log 文件（文件名是 ib_logfile+ 数字），是在执行 commit 语句的时候做的。\n","slug":"MySQL框架","date":"2022-08-29T10:22:15.000Z","categories_index":"数据库","tags_index":"MySQL,框架学习,基础概念","author_index":"依水何安"}]